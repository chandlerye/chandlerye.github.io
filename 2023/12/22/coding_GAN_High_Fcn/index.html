<!DOCTYPE html>
<html lang=zh>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="renderer" content="webkit">
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="format-detection" content="telephone=no,email=no,adress=no">
  <!-- Color theme for statusbar -->
  <meta name="theme-color" content="#000000" />
  <!-- 强制页面在当前窗口以独立页面显示,防止别人在框架里调用页面 -->
  <meta http-equiv="window-target" content="_top" />
  
  
  <title>Coding-CGAN-条件生成对抗网络-基于高阶FCN数据 | Chandler&#39;s blog</title>
  <meta name="description" content="摘要 main.py generate.py    摘要 main.py包括高阶FCN的处理，生成对抗网络的训练 generate.py使用生成器生成样本   1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636">
<meta property="og:type" content="article">
<meta property="og:title" content="Coding-CGAN-条件生成对抗网络-基于高阶FCN数据">
<meta property="og:url" content="http://example.com/2023/12/22/coding_GAN_High_Fcn/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="摘要 main.py generate.py    摘要 main.py包括高阶FCN的处理，生成对抗网络的训练 generate.py使用生成器生成样本   1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2023-12-21T16:09:25.314Z">
<meta property="article:modified_time" content="2024-05-21T12:15:06.554Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="Code-生成">
<meta name="twitter:card" content="summary">
  <!-- Canonical links -->
  <link rel="canonical" href="http://example.com/2023/12/22/coding_GAN_High_Fcn/index.html">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
  
  
<link rel="stylesheet" href="/css/style.css">

  
  
  
  
<meta name="generator" content="Hexo 6.3.0"></head>


<body class="main-center" itemscope itemtype="http://schema.org/WebPage">
  <header class="header" itemscope itemtype="http://schema.org/WPHeader">
  <div class="slimContent">
    <div class="navbar-header">
      
      
      <div class="profile-block text-center">
        <a id="avatar" href="https://github.com/chandlerye" target="_blank">
          <img class="img-circle img-rotate" src="/images/favicon.ico" width="200" height="200">
        </a>
        <h2 id="name" class="hidden-xs hidden-sm">Chandler</h2>
        <h3 id="title" class="hidden-xs hidden-sm hidden-md">一头牛马</h3>
        <small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i> YanTai, China</small>
      </div>
      
      <div class="search" id="search-form-wrap">

    <form class="search-form sidebar-form">
        <div class="input-group">
            <input type="text" class="search-form-input form-control" placeholder="搜索" />
            <span class="input-group-btn">
                <button type="submit" class="search-form-submit btn btn-flat" onclick="return false;"><i class="icon icon-search"></i></button>
            </span>
        </div>
    </form>
    <div class="ins-search">
  <div class="ins-search-mask"></div>
  <div class="ins-search-container">
    <div class="ins-input-wrapper">
      <input type="text" class="ins-search-input" placeholder="想要查找什么..." x-webkit-speech />
      <button type="button" class="close ins-close ins-selectable" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
    </div>
    <div class="ins-section-wrapper">
      <div class="ins-section-container"></div>
    </div>
  </div>
</div>


</div>
      <button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation">
      <ul class="nav navbar-nav main-nav ">
        
        
        <li class="menu-item menu-item-home">
          <a href="/.">
            
            <i class="icon icon-home-fill"></i>
            
            <span class="menu-title">首页</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-archives">
          <a href="/archives">
            
            <i class="icon icon-archives-fill"></i>
            
            <span class="menu-title">归档</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-categories">
          <a href="/categories">
            
            <i class="icon icon-folder"></i>
            
            <span class="menu-title">分类</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-tags">
          <a href="/tags">
            
            <i class="icon icon-tags"></i>
            
            <span class="menu-title">标签</span>
          </a>
        </li>
        
      </ul>
      
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/chandlerye" target="_blank" title="Github" data-toggle=tooltip data-placement=top><i class="icon icon-github"></i></a></li>
        
    </ul>

    </nav>
  </div>
</header>

  
    <aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    
      <div class="widget">
    <h3 class="widget-title">公告</h3>
    <div class="widget-body">
        <div id="board">
            <div class="content">
                <p>记录学习历程!</p>
            </div>
        </div>
    </div>
</div>

    
      
  <div class="widget">
    <h3 class="widget-title">分类</h3>
    <div class="widget-body">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Paper/">Paper</a><span class="category-list-count">10</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AC%94%E8%AE%B0/">笔记</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E7%A8%8B/">编程</a><span class="category-list-count">23</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">标签云</h3>
    <div class="widget-body tagcloud">
      <a href="/tags/Code-%E5%88%86%E7%B1%BB/" style="font-size: 13.6px;">Code-分类</a> <a href="/tags/Code-%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" style="font-size: 13.6px;">Code-图像处理</a> <a href="/tags/Code-%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B/" style="font-size: 13.8px;">Code-基础模型</a> <a href="/tags/Code-%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/" style="font-size: 13.2px;">Code-文件操作</a> <a href="/tags/Code-%E7%94%9F%E6%88%90/" style="font-size: 13.4px;">Code-生成</a> <a href="/tags/Paper-%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F/" style="font-size: 14px;">Paper-医学影像</a> <a href="/tags/Paper-%E7%BB%BC%E8%BF%B0%E6%96%87%E7%AB%A0/" style="font-size: 13.4px;">Paper-综述文章</a> <a href="/tags/Qt/" style="font-size: 13px;">Qt</a> <a href="/tags/%E5%8C%BB%E5%AD%A6/" style="font-size: 13.2px;">医学</a> <a href="/tags/%E6%B3%95%E5%BE%8B/" style="font-size: 13px;">法律</a> <a href="/tags/%E7%BB%BC%E8%BF%B0%E6%96%87%E7%AB%A0/" style="font-size: 13px;">综述文章</a> <a href="/tags/%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" style="font-size: 13.4px;">编程基础知识</a>
    </div>
  </div>

    
      
  <div class="widget">
    <h3 class="widget-title">归档</h3>
    <div class="widget-body">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/05/">五月 2024</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/02/">二月 2024</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/01/">一月 2024</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/12/">十二月 2023</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">十月 2023</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">九月 2023</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">八月 2023</a><span class="archive-list-count">7</span></li></ul>
    </div>
  </div>


    
  </div>
</aside>

  
  
<main class="main" role="main">
  <div class="content">
  <article id="post-coding_GAN_High_Fcn" class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting">
    
    <div class="article-header">
      
        
  
    <h1 class="article-title" itemprop="name">
      Coding-CGAN-条件生成对抗网络-基于高阶FCN数据
    </h1>
  

      
      <div class="article-meta">
        <span class="article-date">
    <i class="icon icon-calendar-check"></i>
	<a href="/2023/12/22/coding_GAN_High_Fcn/" class="article-date">
	  <time datetime="2023-12-21T16:09:25.314Z" itemprop="datePublished">2023-12-22</time>
	</a>
</span>
        
  <span class="article-category">
    <i class="icon icon-folder"></i>
    <a class="article-category-link" href="/categories/%E7%BC%96%E7%A8%8B/">编程</a>
  </span>

        
  <span class="article-tag">
    <i class="icon icon-tags"></i>
	<a class="article-tag-link-link" href="/tags/Code-%E7%94%9F%E6%88%90/" rel="tag">Code-生成</a>
  </span>


        

        <span class="post-comment"><i class="icon icon-comment"></i> <a href="/2023/12/22/coding_GAN_High_Fcn/#comments" class="article-comment-link">评论</a></span>
        
      </div>
    </div>
    <div class="article-entry marked-body" itemprop="articleBody">
      
        <!-- toc -->
<ul>
<li><a href="#%E6%91%98%E8%A6%81">摘要</a></li>
<li><a href="#mainpy">main.py</a></li>
<li><a href="#generatepy">generate.py</a></li>
</ul>
<!-- tocstop -->
<h3><span id="摘要"> 摘要</span></h3>
<p>main.py包括高阶FCN的处理，生成对抗网络的训练<br>
generate.py使用生成器生成样本</p>
<h3><span id="mainpy"> </span></h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision.utils <span class="keyword">import</span> save_image</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scipy.io <span class="keyword">import</span> loadmat</span><br><span class="line"><span class="keyword">from</span> torch.utils <span class="keyword">import</span> data  <span class="comment"># 导入PyTorch数据工具模块</span></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">os.makedirs(<span class="string">&quot;train_images&quot;</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">os.makedirs(<span class="string">&quot;test_images&quot;</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">os.makedirs(<span class="string">&quot;save_model&quot;</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">&quot;--n_epochs&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">200</span>, <span class="built_in">help</span>=<span class="string">&quot;number of epochs of training&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--batch_size&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">4</span>, <span class="built_in">help</span>=<span class="string">&quot;size of the batches&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--lr&quot;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.0002</span>, <span class="built_in">help</span>=<span class="string">&quot;adam: learning rate&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--b1&quot;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.5</span>, <span class="built_in">help</span>=<span class="string">&quot;adam: decay of first order momentum of gradient&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--b2&quot;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.999</span>, <span class="built_in">help</span>=<span class="string">&quot;adam: decay of first order momentum of gradient&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--n_cpu&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">8</span>, <span class="built_in">help</span>=<span class="string">&quot;number of cpu threads to use during batch generation&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--latent_dim&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">100</span>, <span class="built_in">help</span>=<span class="string">&quot;噪声的维度&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--n_classes&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">2</span>, <span class="built_in">help</span>=<span class="string">&quot;类别数量&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--img_size&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">116</span>, <span class="built_in">help</span>=<span class="string">&quot;功能连接矩阵的维度&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--channels&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">1</span>, <span class="built_in">help</span>=<span class="string">&quot;矩阵通道&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--sample_interval&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">400</span>, <span class="built_in">help</span>=<span class="string">&quot;interval between image sampling&quot;</span>)</span><br><span class="line">opt = parser.parse_args()</span><br><span class="line"><span class="built_in">print</span>(opt)</span><br><span class="line"></span><br><span class="line">img_shape = (opt.channels, opt.img_size, opt.img_size)</span><br><span class="line"></span><br><span class="line">cuda = <span class="literal">True</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">my_dataset</span>(data.Dataset):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, Hig_X,label_</span>):</span><br><span class="line">        self.Hig_X = np.expand_dims(Hig_X,<span class="number">1</span>)    <span class="comment"># 加上通道数</span></span><br><span class="line">        self.label = label_</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        X = self.Hig_X[index]  <span class="comment"># 获取高阶FCN</span></span><br><span class="line">        label = self.label[index]</span><br><span class="line">        <span class="keyword">return</span> X,label</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.Hig_X.shape[<span class="number">0</span>]  <span class="comment"># 返回数据集的长度</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_similarity</span>(<span class="params">matrix1, matrix2</span>):</span><br><span class="line">    correlation, _ = pearsonr(matrix1.flatten(), matrix2.flatten())</span><br><span class="line">    <span class="keyword">return</span> correlation</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 精度判断，即计算两个矩阵的相关系数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_accuracy</span>(<span class="params">generator, dataloader, device, val_subjects=<span class="literal">None</span></span>):</span><br><span class="line">    generator.<span class="built_in">eval</span>()</span><br><span class="line">    correct_predictions = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> batch_idx, (batch_matrix) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">        matrix = batch_matrix.to(device)</span><br><span class="line">        size = matrix.size(<span class="number">0</span>)</span><br><span class="line">        random_noise = torch.randn(size, <span class="number">100</span>).to(device=device)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            gen_matrix = generator(random_noise)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(size):</span><br><span class="line">            similarity = calculate_similarity(gen_matrix[i].cpu().numpy(), matrix[i].cpu().numpy())</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 阈值是一个经验值，根据实际情况调整</span></span><br><span class="line">            <span class="keyword">if</span> similarity &gt; <span class="number">0.6</span> <span class="keyword">and</span> (val_subjects <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> batch_idx <span class="keyword">in</span> val_subjects):</span><br><span class="line">                correct_predictions += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    accuracy = correct_predictions / <span class="built_in">len</span>(dataloader.dataset)</span><br><span class="line">    <span class="keyword">return</span> accuracy</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Generator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Generator, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.label_emb = nn.Embedding(opt.n_classes, opt.n_classes)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">block</span>(<span class="params">in_feat, out_feat, normalize=<span class="literal">True</span></span>):</span><br><span class="line">            layers = [nn.Linear(in_feat, out_feat)]</span><br><span class="line">            <span class="keyword">if</span> normalize:</span><br><span class="line">                layers.append(nn.BatchNorm1d(out_feat, <span class="number">0.8</span>))</span><br><span class="line">            layers.append(nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>))</span><br><span class="line">            <span class="keyword">return</span> layers</span><br><span class="line"></span><br><span class="line">        self.model = nn.Sequential(</span><br><span class="line">            *block(opt.latent_dim + opt.n_classes, <span class="number">128</span>, normalize=<span class="literal">False</span>),</span><br><span class="line">            *block(<span class="number">128</span>, <span class="number">256</span>),</span><br><span class="line">            *block(<span class="number">256</span>, <span class="number">512</span>),</span><br><span class="line">            *block(<span class="number">512</span>, <span class="number">1024</span>),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, <span class="built_in">int</span>(np.prod(img_shape))),</span><br><span class="line">            nn.Tanh()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, noise, labels</span>):</span><br><span class="line">        <span class="comment"># Concatenate label embedding and image to produce input</span></span><br><span class="line">        gen_input = torch.cat((self.label_emb(labels), noise), -<span class="number">1</span>)</span><br><span class="line">        img = self.model(gen_input)</span><br><span class="line">        img = img.view(img.size(<span class="number">0</span>), *img_shape)</span><br><span class="line">        <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Discriminator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Discriminator, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.label_embedding = nn.Embedding(opt.n_classes, opt.n_classes)</span><br><span class="line"></span><br><span class="line">        self.model = nn.Sequential(</span><br><span class="line">            nn.Linear(opt.n_classes + <span class="built_in">int</span>(np.prod(img_shape)), <span class="number">512</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">512</span>),</span><br><span class="line">            nn.Dropout(<span class="number">0.4</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">512</span>),</span><br><span class="line">            nn.Dropout(<span class="number">0.4</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">1</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, img, labels</span>):</span><br><span class="line">        <span class="comment"># Concatenate label embedding and image to produce input</span></span><br><span class="line">        d_in = torch.cat((img.view(img.size(<span class="number">0</span>), -<span class="number">1</span>), self.label_embedding(labels)), -<span class="number">1</span>)</span><br><span class="line">        validity = self.model(d_in)</span><br><span class="line">        <span class="keyword">return</span> validity</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Loss functions</span></span><br><span class="line">adversarial_loss = torch.nn.MSELoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize generator and discriminator</span></span><br><span class="line">generator = Generator()</span><br><span class="line">discriminator = Discriminator()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> cuda:</span><br><span class="line">    generator.cuda()</span><br><span class="line">    discriminator.cuda()</span><br><span class="line">    adversarial_loss.cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Configure data loader</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># 原始文件路径</span></span><br><span class="line">fMRI_file_path = <span class="string">&#x27;.//ROISignals_insomnia_aal116.mat&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line">fMRI_data = loadmat(fMRI_file_path)[<span class="string">&#x27;ROISignals&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 正常人为1,病人为0</span></span><br><span class="line">fMRI_label = torch.cat((torch.ones(<span class="number">32</span>,<span class="number">1</span>),torch.zeros(<span class="number">30</span>,<span class="number">1</span>)),dim=<span class="number">0</span>).squeeze()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 低阶矩阵计算</span></span><br><span class="line">Low_X_ = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(fMRI_data.shape[<span class="number">2</span>]):  </span><br><span class="line">    temp = np.corrcoef(fMRI_data[:,:,i],rowvar=<span class="literal">False</span>)</span><br><span class="line">    Low_X_.append(temp)</span><br><span class="line">Low_X = np.array(Low_X_) <span class="comment">#(62,116,116)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 高阶矩阵计算</span></span><br><span class="line">Hig_X_ = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Low_X.shape[<span class="number">0</span>]):  </span><br><span class="line">    temp = np.corrcoef(Low_X[:,:,i],rowvar=<span class="literal">False</span>)</span><br><span class="line">    Hig_X_.append(temp)</span><br><span class="line">Hig_X = np.array(Hig_X_)  <span class="comment">#(62,116,116)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">random_index = np.random.permutation(<span class="built_in">len</span>(fMRI_label))</span><br><span class="line">Hig_X = Hig_X[random_index]</span><br><span class="line">fMRI_label = fMRI_label[random_index]</span><br><span class="line"></span><br><span class="line">train_data = Hig_X[:<span class="number">50</span>]</span><br><span class="line">train_label = fMRI_label[:<span class="number">50</span>]</span><br><span class="line">test_data = Hig_X[<span class="number">50</span>:]</span><br><span class="line">test_label = fMRI_label[:<span class="number">50</span>]</span><br><span class="line"></span><br><span class="line">train_dataset = my_dataset(train_data,train_label)</span><br><span class="line">test_dataset = my_dataset(test_data,test_label)</span><br><span class="line"></span><br><span class="line">train_loader =  data.DataLoader(train_dataset,batch_size=opt.batch_size,shuffle=<span class="literal">True</span>)</span><br><span class="line">test_loader = data.DataLoader(test_dataset,batch_size=opt.batch_size,shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Optimizers</span></span><br><span class="line">optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))</span><br><span class="line">optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))</span><br><span class="line"></span><br><span class="line">FloatTensor = torch.cuda.FloatTensor <span class="keyword">if</span> cuda <span class="keyword">else</span> torch.FloatTensor</span><br><span class="line">LongTensor = torch.cuda.LongTensor <span class="keyword">if</span> cuda <span class="keyword">else</span> torch.LongTensor</span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------</span></span><br><span class="line"><span class="comment">#  Training</span></span><br><span class="line"><span class="comment"># ----------</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(opt.n_epochs):</span><br><span class="line">    <span class="keyword">for</span> i, (imgs, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line"></span><br><span class="line">        batch_size = imgs.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Adversarial ground truths</span></span><br><span class="line">        valid = Variable(FloatTensor(batch_size, <span class="number">1</span>).fill_(<span class="number">1.0</span>), requires_grad=<span class="literal">False</span>)</span><br><span class="line">        fake = Variable(FloatTensor(batch_size, <span class="number">1</span>).fill_(<span class="number">0.0</span>), requires_grad=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Configure input</span></span><br><span class="line">        real_imgs = Variable(imgs.<span class="built_in">type</span>(FloatTensor))</span><br><span class="line">        labels = Variable(labels.<span class="built_in">type</span>(LongTensor))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># -----------------</span></span><br><span class="line">        <span class="comment">#  Train Generator</span></span><br><span class="line">        <span class="comment"># -----------------</span></span><br><span class="line"></span><br><span class="line">        optimizer_G.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Sample noise and labels as generator input</span></span><br><span class="line">        z = Variable(FloatTensor(np.random.normal(<span class="number">0</span>, <span class="number">1</span>, (batch_size, opt.latent_dim))))</span><br><span class="line">        gen_labels = Variable(LongTensor(np.random.randint(<span class="number">0</span>, opt.n_classes, batch_size)))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Generate a batch of images</span></span><br><span class="line">        gen_imgs = generator(z, gen_labels)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Loss measures generator&#x27;s ability to fool the discriminator</span></span><br><span class="line">        validity = discriminator(gen_imgs, gen_labels)</span><br><span class="line">        g_loss = adversarial_loss(validity, valid)</span><br><span class="line"></span><br><span class="line">        g_loss.backward()</span><br><span class="line">        optimizer_G.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ---------------------</span></span><br><span class="line">        <span class="comment">#  Train Discriminator</span></span><br><span class="line">        <span class="comment"># ---------------------</span></span><br><span class="line"></span><br><span class="line">        optimizer_D.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Loss for real images</span></span><br><span class="line">        validity_real = discriminator(real_imgs, labels)</span><br><span class="line">        d_real_loss = adversarial_loss(validity_real, valid)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Loss for fake images</span></span><br><span class="line">        validity_fake = discriminator(gen_imgs.detach(), gen_labels)</span><br><span class="line">        d_fake_loss = adversarial_loss(validity_fake, fake)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Total discriminator loss</span></span><br><span class="line">        d_loss = (d_real_loss + d_fake_loss) / <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        d_loss.backward()</span><br><span class="line">        optimizer_D.step()</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(</span><br><span class="line">            <span class="string">&quot;[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]&quot;</span></span><br><span class="line">            % (epoch, opt.n_epochs, i, <span class="built_in">len</span>(train_loader), d_loss.item(), g_loss.item())</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        batches_done = epoch * <span class="built_in">len</span>(train_loader) + i</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 存储训练过程的结果</span></span><br><span class="line">        <span class="keyword">if</span> batches_done % opt.sample_interval == <span class="number">0</span>:  <span class="comment">#一个epoch中每隔多少间隔保存一次</span></span><br><span class="line">            gen_imgs_normalized = (gen_imgs - gen_imgs.<span class="built_in">min</span>()) / (gen_imgs.<span class="built_in">max</span>() - gen_imgs.<span class="built_in">min</span>()) </span><br><span class="line">            save_image(gen_imgs_normalized.data[:<span class="number">25</span>], <span class="string">&quot;train_images/%d.png&quot;</span> % batches_done, nrow=<span class="number">5</span>, normalize=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 测试过程</span></span><br><span class="line">     </span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        best_acc = <span class="number">0</span></span><br><span class="line">        generator.<span class="built_in">eval</span>()</span><br><span class="line">        correct_predictions = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> imgs, label <span class="keyword">in</span> test_loader:</span><br><span class="line">            z = Variable(FloatTensor(np.random.normal(<span class="number">0</span>, <span class="number">1</span>, (imgs.shape[<span class="number">0</span>], opt.latent_dim))))</span><br><span class="line">            gen_labels = Variable(LongTensor(np.random.randint(<span class="number">0</span>, opt.n_classes, imgs.shape[<span class="number">0</span>])))</span><br><span class="line">            gen_imgs = generator(z, gen_labels)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(imgs.shape[<span class="number">0</span>]):</span><br><span class="line">                similarity = calculate_similarity(gen_imgs[i].cpu().numpy(), imgs[i].cpu().numpy())</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 阈值是一个经验值，根据实际情况调整</span></span><br><span class="line">                <span class="keyword">if</span> similarity &gt; <span class="number">0.6</span>:</span><br><span class="line">                    correct_predictions += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        accuracy = correct_predictions / <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line">        <span class="comment"># 保存epoch中精度最好的模型</span></span><br><span class="line">        <span class="keyword">if</span> best_acc &lt; accuracy:</span><br><span class="line">            best_acc = accuracy</span><br><span class="line">            <span class="comment">#保存模型</span></span><br><span class="line">            torch.save(generator.state_dict(), <span class="string">&quot;save_model/best_model.pth&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;epoch:&#x27;</span>+<span class="built_in">str</span>(epoch)+<span class="string">&#x27; 测试集acc:&#x27;</span>+<span class="built_in">str</span>(accuracy)+<span class="string">&quot; best_acc:&quot;</span>+<span class="built_in">str</span>(best_acc))</span><br><span class="line">        gen_imgs_normalized = (gen_imgs - gen_imgs.<span class="built_in">min</span>()) / (gen_imgs.<span class="built_in">max</span>() - gen_imgs.<span class="built_in">min</span>()) </span><br><span class="line">        save_image(gen_imgs_normalized.data[:<span class="number">25</span>], <span class="string">&quot;test_images/acc_&#123;&#125;epoch_&#123;&#125;.png&quot;</span>.<span class="built_in">format</span>(accuracy,epoch), nrow=<span class="number">5</span>, normalize=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<h3><span id="generatepy"> </span></h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">from</span> torchvision.utils <span class="keyword">import</span> save_image</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">&quot;--n_epochs&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">200</span>, <span class="built_in">help</span>=<span class="string">&quot;number of epochs of training&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--batch_size&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">4</span>, <span class="built_in">help</span>=<span class="string">&quot;size of the batches&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--lr&quot;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.0002</span>, <span class="built_in">help</span>=<span class="string">&quot;adam: learning rate&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--b1&quot;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.5</span>, <span class="built_in">help</span>=<span class="string">&quot;adam: decay of first order momentum of gradient&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--b2&quot;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.999</span>, <span class="built_in">help</span>=<span class="string">&quot;adam: decay of first order momentum of gradient&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--n_cpu&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">8</span>, <span class="built_in">help</span>=<span class="string">&quot;number of cpu threads to use during batch generation&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--latent_dim&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">100</span>, <span class="built_in">help</span>=<span class="string">&quot;噪声的维度&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--n_classes&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">2</span>, <span class="built_in">help</span>=<span class="string">&quot;类别数量&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--img_size&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">116</span>, <span class="built_in">help</span>=<span class="string">&quot;功能连接矩阵的维度&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--channels&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">1</span>, <span class="built_in">help</span>=<span class="string">&quot;矩阵通道&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--sample_interval&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">400</span>, <span class="built_in">help</span>=<span class="string">&quot;interval between image sampling&quot;</span>)</span><br><span class="line">opt = parser.parse_args()</span><br><span class="line"><span class="built_in">print</span>(opt)</span><br><span class="line">img_shape = (opt.channels, opt.img_size, opt.img_size)</span><br><span class="line">cuda = <span class="literal">True</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="literal">False</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Generator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Generator, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.label_emb = nn.Embedding(opt.n_classes, opt.n_classes)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">block</span>(<span class="params">in_feat, out_feat, normalize=<span class="literal">True</span></span>):</span><br><span class="line">            layers = [nn.Linear(in_feat, out_feat)]</span><br><span class="line">            <span class="keyword">if</span> normalize:</span><br><span class="line">                layers.append(nn.BatchNorm1d(out_feat, <span class="number">0.8</span>))</span><br><span class="line">            layers.append(nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>))</span><br><span class="line">            <span class="keyword">return</span> layers</span><br><span class="line"></span><br><span class="line">        self.model = nn.Sequential(</span><br><span class="line">            *block(opt.latent_dim + opt.n_classes, <span class="number">128</span>, normalize=<span class="literal">False</span>),</span><br><span class="line">            *block(<span class="number">128</span>, <span class="number">256</span>),</span><br><span class="line">            *block(<span class="number">256</span>, <span class="number">512</span>),</span><br><span class="line">            *block(<span class="number">512</span>, <span class="number">1024</span>),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, <span class="built_in">int</span>(np.prod(img_shape))),</span><br><span class="line">            nn.Tanh()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, noise, labels</span>):</span><br><span class="line">        <span class="comment"># Concatenate label embedding and image to produce input</span></span><br><span class="line">        gen_input = torch.cat((self.label_emb(labels), noise), -<span class="number">1</span>)</span><br><span class="line">        img = self.model(gen_input)</span><br><span class="line">        img = img.view(img.size(<span class="number">0</span>), *img_shape)</span><br><span class="line">        <span class="keyword">return</span> img</span><br><span class="line">    </span><br><span class="line">FloatTensor = torch.cuda.FloatTensor <span class="keyword">if</span> cuda <span class="keyword">else</span> torch.FloatTensor</span><br><span class="line">LongTensor = torch.cuda.LongTensor <span class="keyword">if</span> cuda <span class="keyword">else</span> torch.LongTensor</span><br><span class="line"></span><br><span class="line">os.makedirs(<span class="string">&quot;Generated_samples&quot;</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">generator = Generator()</span><br><span class="line">generator.cuda()</span><br><span class="line"><span class="comment"># 指定保存的模型文件路径</span></span><br><span class="line">model_path = <span class="string">&#x27;save_model\\best_model.pth&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载保存的模型状态字典</span></span><br><span class="line">generator.load_state_dict(torch.load(model_path))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将模型设置为评估模式</span></span><br><span class="line">generator.<span class="built_in">eval</span>()</span><br><span class="line"><span class="comment"># 设置生成样本数</span></span><br><span class="line">batch_size = <span class="number">25</span></span><br><span class="line"></span><br><span class="line">z = Variable(FloatTensor(np.random.normal(<span class="number">0</span>, <span class="number">1</span>, (batch_size, opt.latent_dim))))</span><br><span class="line">gen_labels = Variable(LongTensor(np.random.randint(<span class="number">0</span>, opt.n_classes, batch_size)))</span><br><span class="line">gen_imgs = generator(z , gen_labels)</span><br><span class="line"><span class="comment"># 标准化</span></span><br><span class="line">gen_imgs_normalized = (gen_imgs - gen_imgs.<span class="built_in">min</span>()) / (gen_imgs.<span class="built_in">max</span>() - gen_imgs.<span class="built_in">min</span>()) </span><br><span class="line"><span class="comment"># 存储样本和标签</span></span><br><span class="line">np.savez(<span class="string">&#x27;Generated_samples/Generated_samples.npz&#x27;</span>, array1=gen_imgs.detach().cpu(), array2=gen_labels.detach().cpu())</span><br><span class="line"><span class="comment">#存储图片</span></span><br><span class="line">save_image(gen_imgs_normalized.data[:<span class="number">25</span>], <span class="string">&quot;Generated_samples/acc_epoch_.png&quot;</span>, nrow=<span class="number">25</span>, normalize=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

      
    </div>
    <div class="article-footer">
      <!-- <blockquote class="mt-2x">
  <ul class="post-copyright list-unstyled">
    
    <li class="post-copyright-link hidden-xs">
      <strong>本文链接：</strong>
      <a href="http://example.com/2023/12/22/coding_GAN_High_Fcn/" title="Coding-CGAN-条件生成对抗网络-基于高阶FCN数据" target="_blank" rel="external">http://example.com/2023/12/22/coding_GAN_High_Fcn/</a>
    </li>
    
    <li class="post-copyright-license">
      <strong>版权声明： </strong> 本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by/4.0/deed.zh" target="_blank" rel="external">CC BY 4.0 CN协议</a> 许可协议。转载请注明出处！
    </li>
  </ul>
</blockquote> -->


<div class="panel panel-default panel-badger">
  <div class="panel-body">
    <figure class="media">
      <div class="media-left">
        <a href="https://github.com/chandlerye" target="_blank" class="img-burn thumb-sm visible-lg">
          <img src="/images/favicon.ico" class="img-rounded w-full" alt="">
        </a>
      </div>
      <div class="media-body">
        <h3 class="media-heading"><a href="https://github.com/chandlerye" target="_blank"><span class="text-dark">Chandler</span><small class="ml-1x">一头牛马</small></a></h3>
        <div>江上两条红船，寒风斜雨摇摆</div>
      </div>
    </figure>
  </div>
</div>


    </div>
  </article>
  
    
  <section id="comments">
  	
  </section>


  
</div>

  <nav class="bar bar-footer clearfix" data-stick-bottom>
  <div class="bar-inner">
  
  <ul class="pager pull-left">
    
    <li class="prev">
      <a href="/2023/12/26/coding_medical_network_example/" title="Coding-3D医学图像分类-基于3D-Resnet"><i class="icon icon-angle-left" aria-hidden="true"></i><span>&nbsp;&nbsp;上一篇</span></a>
    </li>
    
    
    <li class="next">
      <a href="/2023/10/28/paper_%E5%9F%BA%E4%BA%8E%E5%AF%B9%E6%8A%97%E8%AE%AD%E7%BB%83%E5%92%8C%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E6%A0%A1%E6%AD%A3%E7%9A%84%E4%B8%80%E6%AC%A1%E6%80%A7%E5%88%9B%E4%BC%A4%E8%84%91%E5%88%86%E5%89%B2/" title="PaperReading-基于对抗训练和不确定性校正的一次性创伤脑分割"><span>下一篇&nbsp;&nbsp;</span><i class="icon icon-angle-right" aria-hidden="true"></i></a>
    </li>
    
    
  </ul>
  
  
  
  <div class="bar-right">
    
  </div>
  </div>
</nav>
  


</main>

  <footer class="footer" itemscope itemtype="http://schema.org/WPFooter">
	
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/chandlerye" target="_blank" title="Github" data-toggle=tooltip data-placement=top><i class="icon icon-github"></i></a></li>
        
    </ul>

    <div class="copyright">
    	
        <div class="publishby">
        	Theme by <a href="https://github.com/cofess" target="_blank"> cofess </a>base on <a href="https://github.com/cofess/hexo-theme-pure" target="_blank">pure</a>.
        </div>
    </div>
</footer>



  <script src="//cdn.jsdelivr.net/npm/jquery@1.12.4/dist/jquery.min.js"></script>
<script>
window.jQuery || document.write('<script src="js/jquery.min.js"><\/script>')
</script>

<script src="/js/plugin.min.js"></script>


<script src="/js/application.js"></script>


    <script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>






   




   






</body>
</html>