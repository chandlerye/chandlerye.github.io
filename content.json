{"meta":{"title":"Hexo","subtitle":"","description":"","author":"John Doe","url":"http://example.com","root":"/"},"pages":[{"title":"åˆ†ç±»","date":"2023-08-30T09:13:13.000Z","updated":"2023-08-30T09:26:25.168Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"æ ‡ç­¾","date":"2023-08-30T09:14:13.000Z","updated":"2023-08-30T09:27:18.175Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""},{"title":"Sylaré¡¹ç›®-æ—¥å¿—ç³»ç»Ÿ","date":"2024-01-30T02:57:51.676Z","updated":"2024-01-02T07:43:16.629Z","comments":true,"path":"draft/coding_sylar_data_system.html","permalink":"http://example.com/draft/coding_sylar_data_system.html","excerpt":"","text":"A Review on Cross-modality Synthesis from MRI to PET 1.æ‘˜è¦ 2.å¼•è¨€ 3.è®ºæ–‡ç»“æ„ 4.æ€»ç»“"},{"title":"Note-ALL","date":"2024-01-30T09:21:20.595Z","updated":"2024-01-30T09:21:20.595Z","comments":true,"path":"draft/note-all.html","permalink":"http://example.com/draft/note-all.html","excerpt":"","text":"JSæ•£åº¦ ä¸€èˆ¬åœ°ï¼ŒJSæ•£åº¦æ˜¯å¯¹ç§°çš„ï¼Œå…¶å–å€¼æ˜¯ 0 åˆ° 1 ä¹‹é—´ã€‚å¦‚æœä¸¤ä¸ªåˆ†å¸ƒ P,Q ç¦»å¾—å¾ˆè¿œï¼Œå®Œå…¨æ²¡æœ‰é‡å çš„æ—¶å€™ï¼Œå³ä½¿ä¸¤ä¸ªåˆ†å¸ƒçš„ä¸­å¿ƒç¦»çš„å¾ˆè¿‘ï¼Œè€ŒJSæ•£åº¦å€¼æ˜¯ä¸€ä¸ªå¸¸æ•°ã€‚è¿™åœ¨å­¦ä¹ ç®—æ³•ä¸­æ˜¯æ¯”è¾ƒè‡´å‘½çš„ï¼Œè¿™å°±æ„å‘³è¿™è¿™ä¸€ç‚¹çš„æ¢¯åº¦ä¸º 0ã€‚æ¢¯åº¦æ¶ˆå¤±äº†ã€‚"},{"title":"è¡¡é‡åˆ†å¸ƒå·®å¼‚æ€§çš„æŸå¤±å‡½æ•°","date":"2024-01-30T10:00:11.726Z","updated":"2024-01-30T10:00:11.726Z","comments":true,"path":"draft/note-distant.html","permalink":"http://example.com/draft/note-distant.html","excerpt":"","text":"EMD å¯¹äºç¦»æ•£çš„æ¦‚ç‡åˆ†å¸ƒï¼ŒWassersteinè·ç¦»ä¹Ÿè¢«æè¿°ä¸ºæ¨åœŸè·ç¦»(EMD)ã€‚å¦‚æœæˆ‘ä»¬å°†åˆ†å¸ƒæƒ³è±¡ä¸ºä¸¤ä¸ªæœ‰ä¸€å®šå­˜åœŸé‡çš„åœŸå †ï¼Œé‚£ä¹ˆEMDå°±æ˜¯å°†ä¸€ä¸ªåœŸå †è½¬æ¢ä¸ºå¦ä¸€ä¸ªåœŸå †æ‰€éœ€çš„æœ€å°æ€»å·¥ä½œé‡ã€‚"},{"title":"Note-ç‰¹å¾èåˆä»£ç ","date":"2024-02-04T01:47:09.506Z","updated":"2024-02-04T01:47:09.506Z","comments":true,"path":"draft/note-feature_fusion.html","permalink":"http://example.com/draft/note-feature_fusion.html","excerpt":"","text":"ç‰¹å¾ä¸èåˆ Featureä¸èåˆï¼Œå¤šå°ºåº¦çš„fetureåˆ†åˆ«è¿›è¡Œé¢„æµ‹ï¼Œç„¶åå¯¹é¢„æµ‹ç»“æœè¿›è¡Œç»¼åˆï¼Œå¦‚Single Shot MultiBox Detector (SSD) , Multi-scale CNN(MS-CNN) å¤šå°ºåº¦ç‰¹å¾èåˆï¼ˆMulti-scale Feature Fusionï¼‰ é‡‘å­—å¡”æ± åŒ–ï¼ˆPyramid Poolingï¼‰ è®ºæ–‡ï¼šSpatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition ç‰¹å¾é‡‘å­—å¡”ç½‘ç»œï¼ˆFeature Pyramid Networksï¼‰ è®ºæ–‡ï¼šFeature Pyramid Networks for Object Detection çŸ­è¿æ¥ï¼ˆShort Connectionsï¼‰ è®ºæ–‡ï¼šDeeply Supervised Salient Object Detection with Short Connections å¯†é›†è¿æ¥çš„å·ç§¯ç½‘ç»œï¼ˆDensely Connected Convolutional Networksï¼‰ è®ºæ–‡ï¼šDensely Connected Convolutional Networks åŒè·¯å¾„ç½‘ç»œï¼ˆDual Path Networksï¼‰ è®ºæ–‡ï¼šDual Path Networks æ®‹å·®è¿æ¥ï¼ˆResidual Connectionsï¼‰ è®ºæ–‡ï¼šDeep Residual Learning for Image Recognition æ³¨æ„åŠ›æœºåˆ¶ï¼ˆAttention Mechanismï¼‰ è®ºæ–‡ï¼šShow, Attend and Tell: Neural Image Caption Generation with Visual Attention Non-local Neural Networks CBAM: Convolutional Block Attention Module èƒ¶å›Šç½‘ç»œï¼ˆCapsule Networksï¼‰ Dynamic Routing Between Capsules å›¾å·ç§¯ç½‘ç»œï¼ˆGraph Convolutional Networksï¼‰ Semi-Supervised Classification with Graph Convolutional Networks Graph Convolutional Networks"}],"posts":[{"title":"Coding-python-éé˜»å¡è¾“å…¥å®ç°","slug":"coding_python_inputnotstock","date":"2024-06-28T12:56:42.673Z","updated":"2024-06-28T12:58:28.968Z","comments":true,"path":"2024/06/28/coding_python_inputnotstock/","link":"","permalink":"http://example.com/2024/06/28/coding_python_inputnotstock/","excerpt":"","text":"ä»£ç  12345678910111213141516171819202122232425262728293031323334353637383940#!/usr/bin/python# å¯¼å…¥å¿…è¦çš„åº“import sysimport ttyimport termiosimport atexittry: # ä¸»å¾ªç¯å¼€å§‹ while True: # æç¤ºç”¨æˆ·è¾“å…¥ï¼Œå¹¶å…è®¸å³æ—¶å“åº”æŒ‰é”®ï¼ˆæ— éœ€æŒ‰å›è½¦ï¼‰ print(&quot;è¯·è¾“å…¥ &#x27;1&#x27; æ‰“å°1, &#x27;2&#x27; æ‰“å°2, æˆ–è¾“å…¥ &#x27;q&#x27; é€€å‡ºç¨‹åºï¼š&quot;) # è·å–æ ‡å‡†è¾“å…¥è®¾å¤‡çš„æ–‡ä»¶æè¿°ç¬¦ fd = sys.stdin.fileno() # ä¿å­˜å½“å‰çš„ç»ˆç«¯è®¾ç½®ï¼Œä»¥ä¾¿ç¨åæ¢å¤ old_settings = termios.tcgetattr(fd) try: # æ”¹å˜è¾“å…¥æ¨¡å¼ï¼Œä½¿å¾—å¯ä»¥ç«‹å³è¯»å–æŒ‰é”® tty.setraw(sys.stdin.fileno()) # è¯»å–ç”¨æˆ·è¾“å…¥çš„ç¬¬ä¸€ä¸ªå­—ç¬¦ ch = sys.stdin.read(1) finally: # æ¢å¤ç»ˆç«¯çš„åŸå§‹è®¾ç½® termios.tcsetattr(fd, termios.TCSADRAIN, old_settings) # æ ¹æ®ç”¨æˆ·è¾“å…¥æ‰§è¡Œç›¸åº”æ“ä½œ if ch == &#x27;1&#x27;: print(&quot;1&quot;) elif ch == &#x27;2&#x27;: print(&quot;2&quot;) elif ch.lower() == &#x27;q&#x27;: # å…¼å®¹å¤§å°å†™è¾“å…¥çš„é€€å‡ºæŒ‡ä»¤ print(&quot;ç¨‹åºå³å°†é€€å‡º...&quot;) break # é€€å‡ºå¾ªç¯ else: print(&quot;æ— æ•ˆçš„è¾“å…¥ï¼Œè¯·è¾“å…¥ &#x27;1&#x27;, &#x27;2&#x27;, æˆ– &#x27;q&#x27;ã€‚&quot;)except KeyboardInterrupt: # æ•è·Ctrl+Cä¸­æ–­ print(&quot;\\nç¨‹åºå› é”®ç›˜ä¸­æ–­è€Œé€€å‡ºã€‚&quot;)finally: # ç¡®ä¿åœ¨ä»»ä½•æƒ…å†µä¸‹ç”µæœºéƒ½èƒ½å®‰å…¨å…³é—­ print(&quot;é€€å‡º&quot;)","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Code-å›¾åƒå¤„ç†","slug":"Code-å›¾åƒå¤„ç†","permalink":"http://example.com/tags/Code-%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}]},{"title":"Coding-python-atexitåŒ…-åº”ç”¨äºç¨‹åºç»“æŸæ—¶","slug":"coding_python_atexit","date":"2024-06-28T12:54:26.815Z","updated":"2024-06-28T12:57:32.794Z","comments":true,"path":"2024/06/28/coding_python_atexit/","link":"","permalink":"http://example.com/2024/06/28/coding_python_atexit/","excerpt":"","text":"ä»£ç  1234567891011121314151617181920import atexitimport time# å®šä¹‰ä¸€ä¸ªå°†åœ¨ç¨‹åºé€€å‡ºæ—¶è¢«è°ƒç”¨çš„å‡½æ•°def cleanup(): print(&quot;ç¨‹åºå·²é€€å‡ºï¼Œæ­£åœ¨è¿›è¡Œæ¸…ç†å·¥ä½œ...&quot;) # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šçš„æ¸…ç†ä»£ç ï¼Œä¾‹å¦‚å…³é—­æ–‡ä»¶ã€æ•°æ®åº“è¿æ¥ç­‰# ä½¿ç”¨atexitæ¨¡å—æ³¨å†Œæ¸…ç†å‡½æ•°atexit.register(cleanup)# ç¨‹åºçš„ä¸»è¦é€»è¾‘print(&quot;ç¨‹åºå¼€å§‹è¿è¡Œ...&quot;)# æ¨¡æ‹Ÿä¸€äº›æ“ä½œfor i in range(5): print(f&quot;æ­£åœ¨å¤„ç†ä»»åŠ¡ &#123;i+1&#125;...&quot;) time.sleep(1) # æ¨¡æ‹Ÿè€—æ—¶æ“ä½œï¼Œè¿™é‡Œå¼•å…¥timeæ¨¡å—æ¥æ¨¡æ‹Ÿå»¶æ—¶print(&quot;æ‰€æœ‰ä»»åŠ¡å¤„ç†å®Œæ¯•ã€‚&quot;)# æ³¨æ„ï¼šè¿™é‡Œæ²¡æœ‰æ‰‹åŠ¨è°ƒç”¨cleanup()ï¼Œå®ƒä¼šåœ¨è„šæœ¬è‡ªç„¶ç»“æŸæ—¶ç”±atexitæ¨¡å—è‡ªåŠ¨è°ƒç”¨","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Code-å›¾åƒå¤„ç†","slug":"Code-å›¾åƒå¤„ç†","permalink":"http://example.com/tags/Code-%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}]},{"title":"Coding-å›¾åƒä¸‹é‡‡æ ·","slug":"coding_python_image_downsample","date":"2024-06-28T12:49:52.833Z","updated":"2024-06-28T12:53:17.532Z","comments":true,"path":"2024/06/28/coding_python_image_downsample/","link":"","permalink":"http://example.com/2024/06/28/coding_python_image_downsample/","excerpt":"","text":"æ ¹æ®ç¼©æ”¾å› å­ä¸‹é‡‡æ ·å›¾åƒ,å¤„ç†æ–‡ä»¶å¤¹ æ ¹æ®ç¼©æ”¾å› å­ä¸‹é‡‡æ ·å›¾åƒ,å¤„ç†æ–‡ä»¶å¤¹åŠå­æ–‡ä»¶å¤¹ æ ¹æ®ç¼©æ”¾å› å­ä¸‹é‡‡æ ·å›¾åƒ,å¤„ç†æ–‡ä»¶å¤¹ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748from PIL import Imageimport osdef resize_images(input_folder, output_folder, scale_factor=0.6): &quot;&quot;&quot; å°†æŒ‡å®šæ–‡ä»¶å¤¹å†…çš„æ‰€æœ‰å›¾ç‰‡åˆ†è¾¨ç‡é™ä½ä¸€å€å¹¶ä¿å­˜åˆ°å¦ä¸€ä¸ªæ–‡ä»¶å¤¹ã€‚ å‚æ•°: input_folder (str): åŒ…å«å›¾ç‰‡çš„è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„ã€‚ output_folder (str): ç”¨äºä¿å­˜ç¼©å°åå›¾ç‰‡çš„è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„ã€‚ scale_factor (float): å›¾ç‰‡å°ºå¯¸ç¼©å°çš„æ¯”ä¾‹ï¼Œé»˜è®¤ä¸º0.5ï¼ˆå³åˆ†è¾¨ç‡é™ä½ä¸€åŠï¼‰ã€‚ &quot;&quot;&quot; # ç¡®ä¿è¾“å‡ºæ–‡ä»¶å¤¹å­˜åœ¨ os.makedirs(output_folder, exist_ok=True) # éå†è¾“å…¥æ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶ for filename in os.listdir(input_folder): input_path = os.path.join(input_folder, filename) # æ£€æŸ¥æ˜¯å¦ä¸ºå›¾ç‰‡æ–‡ä»¶ if os.path.isfile(input_path) and (filename.lower().endswith(&#x27;.jpg&#x27;) or filename.lower().endswith(&#x27;.jpeg&#x27;) or filename.lower().endswith(&#x27;.png&#x27;)): try: # æ‰“å¼€å›¾ç‰‡ with Image.open(input_path) as img: # è®¡ç®—æ–°çš„å®½åº¦å’Œé«˜åº¦ width, height = img.size new_width = int(width * scale_factor) new_height = int(height * scale_factor) # è°ƒæ•´å›¾ç‰‡å¤§å° resized_img = img.resize((new_width, new_height), Image.ANTIALIAS) # æ„å»ºè¾“å‡ºè·¯å¾„å¹¶ä¿å­˜å›¾ç‰‡ output_path = os.path.join(output_folder, filename) resized_img.save(output_path) print(f&quot;Resized and saved &#123;filename&#125; to &#123;output_folder&#125;&quot;) except IOError as e: print(f&quot;Error processing &#123;filename&#125;: &#123;e&#125;&quot;)# æŒ‡å®šè¾“å…¥å’Œè¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„input_folder = &#x27;data&#x27;output_folder = &#x27;data2&#x27;# è°ƒç”¨å‡½æ•°resize_images(input_folder, output_folder) æ ¹æ®ç¼©æ”¾å› å­ä¸‹é‡‡æ ·å›¾åƒ,å¤„ç†æ–‡ä»¶å¤¹åŠå­æ–‡ä»¶å¤¹ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950from PIL import Imageimport osdef downsample_images(source_folder, target_folder, scale_factor=0.6): &quot;&quot;&quot; éå†source_folderä¸­çš„æ‰€æœ‰å­æ–‡ä»¶å¤¹å’Œmaskå›¾ç‰‡ï¼Œå°†å›¾ç‰‡ä¸‹é‡‡æ ·åä¿å­˜åˆ°target_folderä¸­ï¼Œ ä¿æŒåŸæœ‰çš„ç›®å½•ç»“æ„ã€‚ å‚æ•°: source_folder (str): åŒ…å«å­æ–‡ä»¶å¤¹å’Œmaskå›¾ç‰‡çš„æºæ–‡ä»¶å¤¹è·¯å¾„ã€‚ target_folder (str): ç”¨äºä¿å­˜ä¸‹é‡‡æ ·åå›¾ç‰‡çš„ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„ã€‚ scale_factor (float): å›¾ç‰‡å°ºå¯¸ç¼©å°çš„æ¯”ä¾‹ï¼Œé»˜è®¤ä¸º0.5ã€‚ &quot;&quot;&quot; # ç¡®ä¿ç›®æ ‡æ–‡ä»¶å¤¹å­˜åœ¨ os.makedirs(target_folder, exist_ok=True) # éå†æºæ–‡ä»¶å¤¹åŠå…¶å­ç›®å½• for root, dirs, files in os.walk(source_folder): # è®¡ç®—å½“å‰ç›®å½•ç›¸å¯¹äºæºç›®å½•çš„ç›¸å¯¹è·¯å¾„ relative_path = os.path.relpath(root, source_folder) target_subdir = os.path.join(target_folder, relative_path) # ç¡®ä¿ç›®æ ‡å­ç›®å½•å­˜åœ¨ os.makedirs(target_subdir, exist_ok=True) for filename in files: # åªå¤„ç†å›¾ç‰‡æ–‡ä»¶ if filename.lower().endswith((&#x27;.jpg&#x27;, &#x27;.jpeg&#x27;, &#x27;.png&#x27;)): src_path = os.path.join(root, filename) dst_path = os.path.join(target_subdir, filename) try: # æ‰“å¼€å›¾ç‰‡å¹¶è¿›è¡Œä¸‹é‡‡æ · with Image.open(src_path) as img: width, height = img.size new_width = int(width * scale_factor) new_height = int(height * scale_factor) resized_img = img.resize((new_width, new_height), Image.ANTIALIAS) # ä¿å­˜ä¸‹é‡‡æ ·åçš„å›¾ç‰‡ resized_img.save(dst_path) except IOError as e: print(f&quot;Error processing &#123;src_path&#125;: &#123;e&#125;&quot;)# æŒ‡å®šæºæ–‡ä»¶å¤¹å’Œç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„source_folder = &#x27;r1&#x27;target_folder = &#x27;r2&#x27;# è°ƒç”¨å‡½æ•°downsample_images(source_folder, target_folder)","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Code-å›¾åƒå¤„ç†","slug":"Code-å›¾åƒå¤„ç†","permalink":"http://example.com/tags/Code-%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}]},{"title":"Coding-é‡å‘½åæ–‡ä»¶å¤¹ä¸‹å›¾åƒ","slug":"coding_python_image_rename","date":"2024-06-28T12:46:54.104Z","updated":"2024-06-28T12:49:48.720Z","comments":true,"path":"2024/06/28/coding_python_image_rename/","link":"","permalink":"http://example.com/2024/06/28/coding_python_image_rename/","excerpt":"","text":"æŒ‰é¡ºåºé‡å‘½åpicæ–‡ä»¶å¤¹ä¸‹çš„å›¾åƒ 1234567891011121314151617181920212223242526import osimport shutildef rename_files_in_folder(folder_path, extension=&quot;.jpg&quot;): &quot;&quot;&quot; é‡å‘½åæŒ‡å®šæ–‡ä»¶å¤¹å†…çš„æ‰€æœ‰æŒ‡å®šæ‰©å±•åçš„æ–‡ä»¶ï¼ŒæŒ‰ç…§åºåˆ—1, 2, 3...è¿›è¡Œå‘½åã€‚ &quot;&quot;&quot; # è·å–æ–‡ä»¶å¤¹å†…æ‰€æœ‰æŒ‡å®šæ‰©å±•åçš„æ–‡ä»¶åˆ—è¡¨ files = [f for f in os.listdir(folder_path) if f.endswith(extension)] files.sort() # ç¡®ä¿æŒ‰æ–‡ä»¶åæ’åºï¼Œå¦‚æœéœ€è¦çš„è¯ # åœ¨åŒä¸€æ–‡ä»¶å¤¹å†…é‡å‘½åæ–‡ä»¶ for index, filename in enumerate(files, start=1): old_path = os.path.join(folder_path, filename) new_filename = f&quot;&#123;index&#125;&#123;extension&#125;&quot; new_path = os.path.join(folder_path, new_filename) # é‡å‘½åæ–‡ä»¶ shutil.move(old_path, new_path) print(f&quot;Renamed &#x27;&#123;filename&#125;&#x27; to &#x27;&#123;new_filename&#125;&#x27;&quot;)# æŒ‡å®šæ–‡ä»¶å¤¹è·¯å¾„pic_folder = &quot;pic&quot;# è°ƒç”¨å‡½æ•°rename_files_in_folder(pic_folder)","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Code-å›¾åƒå¤„ç†","slug":"Code-å›¾åƒå¤„ç†","permalink":"http://example.com/tags/Code-%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}]},{"title":"Coding-opencv-äººè„¸è¯†åˆ«","slug":"coding_face_recongnition","date":"2024-06-12T15:38:35.041Z","updated":"2024-06-12T15:53:31.618Z","comments":true,"path":"2024/06/12/coding_face_recongnition/","link":"","permalink":"http://example.com/2024/06/12/coding_face_recongnition/","excerpt":"","text":"æ‘˜è¦ ç¨‹åºä¸€ï¼šäººè„¸è¯†åˆ«ä¸æ¯”è¾ƒ ç¨‹åºäºŒï¼šæ‰©å¤§çŸ©å½¢æ¡†èŒƒå›´å‡½æ•°å°è£… æ‘˜è¦ åŸºäºOpenCVä¸face_recognitionçš„äººè„¸è¯†åˆ«ã€‚ï¼ˆæ€ä¹ˆä¼šæœ‰è¿™ä¹ˆæ–¹ä¾¿çš„äººè„¸è¯†åˆ«åº“ï¼‰ ç¨‹åºä¸€ï¼šäººè„¸è¯†åˆ«ä¸æ¯”è¾ƒ æ­¥éª¤ï¼š åŠ è½½ä¸è½¬æ¢å›¾åƒï¼š ä½¿ç”¨face_recognition.load_image_fileåŠ è½½å›¾ç‰‡img/11.jpgå’Œimg/22.jpgï¼Œå¹¶é€šè¿‡cv2.cvtColorå°†å…¶ä»BGRæ ¼å¼è½¬æ¢ä¸ºRGBã€‚ äººè„¸å®šä½ä¸ç‰¹å¾ç¼–ç ï¼š åˆ©ç”¨face_recognition.face_locationså®šä½å›¾ç‰‡ä¸­çš„äººè„¸ä½ç½®ï¼Œå¹¶ä½¿ç”¨face_recognition.face_encodingsæå–è¿™äº›åŒºåŸŸçš„ç‰¹å¾ç¼–ç ã€‚ ç»˜åˆ¶äººè„¸çŸ©å½¢æ¡†ï¼š åœ¨åŸå›¾ä¸Šä¸ºæ£€æµ‹åˆ°çš„äººè„¸ç»˜åˆ¶çŸ©å½¢æ¡†ï¼Œä½¿ç”¨cv2.rectangleå‡½æ•°å®ç°ã€‚ ç›¸ä¼¼åº¦æ¯”è¾ƒä¸æ˜¾ç¤ºï¼š é€šè¿‡face_recognition.compare_facesæ¯”è¾ƒä¸¤ä¸ªäººè„¸ç¼–ç çš„ç›¸ä¼¼åº¦ï¼Œå¹¶åˆ©ç”¨face_recognition.face_distanceè®¡ç®—æ¬§æ°è·ç¦»ï¼Œå±•ç¤ºæ¯”è¾ƒç»“æœåŠè·ç¦»å€¼äºå›¾åƒä¸Šã€‚ 1234567891011121314151617181920212223242526272829303132333435363738394041424344import cv2import numpy as npimport face_recognitionimgElon = face_recognition.load_image_file(&#x27;img/11.jpg&#x27;) # åŠ è½½å›¾ç‰‡imgElon = cv2.cvtColor(imgElon, cv2.COLOR_BGR2RGB) # å°†BGRå½©è‰²å›¾åƒè½¬åŒ–ä¸ºRGBå½©è‰²å›¾åƒfaceLoc = face_recognition.face_locations(imgElon)[0] # å®šä½äººè„¸ä½ç½®encodeElon = face_recognition.face_encodings(imgElon)[0] # æå–äººè„¸çš„é¢éƒ¨ç‰¹å¾cv2.rectangle(imgElon, (faceLoc[3], faceLoc[0]), (faceLoc[1], faceLoc[2]), (255, 0, 255), 2) # æ¡†å‡ºäººè„¸imgTest = face_recognition.load_image_file(&#x27;img/22.jpg&#x27;)imgTest = cv2.cvtColor(imgTest, cv2.COLOR_BGR2RGB)# åŸå§‹çš„äººè„¸ä½ç½®faceLocTest = face_recognition.face_locations(imgTest)[0]# è®¡ç®—çŸ©å½¢æ¡†çš„å®½åº¦å’Œé«˜åº¦width = faceLocTest[1] - faceLocTest[3]height = faceLocTest[2] - faceLocTest[0]# ç¡®ä¿æ‰©å±•çš„å¤§å°ä¸ä¼šè®©çŸ©å½¢è¶…å‡ºå›¾åƒè¾¹ç•Œexpand_width = min(width, imgTest.shape[1] - faceLocTest[1])expand_height = min(height, imgTest.shape[0] - faceLocTest[2])# è°ƒæ•´çŸ©å½¢æ¡†çš„åæ ‡ä»¥æ‰©å¤§è¾¹ç•Œï¼ŒåŒæ—¶ç¡®ä¿ä¸è¶…å‡ºå›¾åƒè¾¹ç•Œtop_left = (max(0, faceLocTest[3] - expand_width), max(0, faceLocTest[0] - expand_height))bottom_right = (min(imgTest.shape[1], faceLocTest[1] + expand_width), min(imgTest.shape[0], faceLocTest[2] + expand_height))# ç»˜åˆ¶è°ƒæ•´åçš„çŸ©å½¢æ¡†encodeTest = face_recognition.face_encodings(imgTest)[0]cv2.rectangle(imgTest, top_left, bottom_right, (255, 0, 255), 2)result = face_recognition.compare_faces([encodeElon], encodeTest) # æ¯”è¾ƒäººè„¸ç¼–ç çš„ç›¸ä¼¼åº¦faceDis = face_recognition.face_distance([encodeElon], encodeTest) # è®¡ç®—ä¸¤ä¸ªäººè„¸çš„æ¬§æ°è·ç¦»ï¼ˆæ¬§æ°è·ç¦»ç”¨äºè®¡ç®—æ ·æœ¬ä¹‹é—´çš„ç›¸ä¼¼åº¦æˆ–è·ç¦»ï¼‰print(result, faceDis)cv2.putText(imgTest, f&#x27;&#123;result&#125;&#123;round(faceDis[0], 2)&#125;&#x27;, (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2) # æ˜¾ç¤ºæ¯”å¯¹ç»“æœ cv2.imshow(&#x27;Elon Musk&#x27;, imgElon)cv2.imshow(&#x27;Elon Test&#x27;, imgTest)key = cv2.waitKey(0)if key == 27: # æŒ‰ESCé”®é€€å‡º cv2.destroyAllWindows() ç¨‹åºäºŒï¼šæ‰©å¤§çŸ©å½¢æ¡†èŒƒå›´å‡½æ•°å°è£… expand_and_draw_face_boxå‡½æ•°ï¼š æ‰©å±•çŸ©å½¢æ¡†ï¼š å¯¹ç»™å®šçš„æµ‹è¯•å›¾åƒï¼Œè¯¥å‡½æ•°ä¸ä»…å®šä½äººè„¸ï¼Œè¿˜æ™ºèƒ½åœ°æ‰©å¤§æ£€æµ‹æ¡†ï¼Œä¿è¯æ‰©å±•åä¸ä¼šè¶…å‡ºå›¾åƒè¾¹ç•Œã€‚ è‡ªå®šä¹‰é€»è¾‘ï¼š å®ç°äº†æ›´ç²¾ç»†çš„æ§åˆ¶ï¼Œé€šè¿‡è®¡ç®—å®‰å…¨çš„æ‰©å±•å°ºå¯¸ï¼Œé¿å…çŸ©å½¢æ¡†è¶Šç•Œé—®é¢˜ã€‚ ç»“æœè¾“å‡ºï¼š å‡½æ•°ç›´æ¥åœ¨å›¾åƒä¸Šç»˜åˆ¶äº†è°ƒæ•´åçš„çŸ©å½¢æ¡†ï¼Œå¹¶å¯é€šè¿‡æ‰“å°è¿”å›çš„çŸ©å½¢é¡¶ç‚¹åæ ‡æ¥éªŒè¯æ•ˆæœã€‚ 1234567891011121314151617181920212223242526272829303132333435363738394041import cv2import numpy as npimport face_recognitiondef expand_and_draw_face_box(imgTest): try: # æ£€æµ‹äººè„¸ä½ç½® faceLocTest = face_recognition.face_locations(imgTest)[0] # è®¡ç®—çŸ©å½¢æ¡†çš„å®½åº¦å’Œé«˜åº¦ width = faceLocTest[1] - faceLocTest[3] height = faceLocTest[2] - faceLocTest[0] # ç¡®ä¿æ‰©å±•çš„å¤§å°ä¸ä¼šè¶…å‡ºå›¾åƒè¾¹ç•Œ expand_width = min(width, imgTest.shape[1] - faceLocTest[1]) expand_height = min(height, imgTest.shape[0] - faceLocTest[2]) # ç»˜åˆ¶è°ƒæ•´åçš„çŸ©å½¢æ¡† top_left = (max(0, faceLocTest[3] - expand_width), max(0, faceLocTest[0] - expand_height)) bottom_right = (min(imgTest.shape[1], faceLocTest[1] + expand_width), min(imgTest.shape[0], faceLocTest[2] + expand_height)) # è¿”å›ä¿®æ”¹åçš„å›¾åƒ cv2.rectangle(imgTest, top_left, bottom_right, (255, 0, 255), 2) return (top_left, bottom_right) except IndexError: print(&quot;No face was detected in the image.&quot;) return None # åŠ è½½å›¾åƒå¹¶è½¬æ¢ä¸ºRGBæ ¼å¼imgTest = face_recognition.load_image_file(&#x27;img/11.jpg&#x27;)imgTest = cv2.cvtColor(imgTest, cv2.COLOR_BGR2RGB)a,b = expand_and_draw_face_box(imgTest)print(a,b)cv2.imshow(&#x27;Image with Expanded Face Box&#x27;, imgTest)cv2.waitKey(0)cv2.destroyAllWindows()","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Code-å›¾åƒå¤„ç†","slug":"Code-å›¾åƒå¤„ç†","permalink":"http://example.com/tags/Code-%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}]},{"title":"MyNote","slug":"MyNote","date":"2024-06-09T08:27:36.687Z","updated":"2024-06-09T09:42:57.612Z","comments":true,"path":"2024/06/09/MyNote/","link":"","permalink":"http://example.com/2024/06/09/MyNote/","excerpt":"","text":"MyNote v2.0 ä¸€ä¸ªè½»é‡çº§çš„ç¬”è®°è½¯ä»¶ğŸ“” Githubé¡¹ç›®åœ°å€: https://github.com/chandlerye/MyNote/tree/main åº”ç”¨ç®€ä»‹ MyNote v2.0 æ˜¯ä¸€æ¬¾ä¸ªäººç¬”è®°ç®¡ç†è½¯ä»¶ï¼Œæ²¡æœ‰å¤æ‚çš„åŠŸèƒ½ï¼Œæ—¨åœ¨æä¾›ä¾¿æ·çš„ç¬”è®°è®°å½•ã€ç®¡ç†ä»¥åŠäº‘åŒæ­¥åŠŸèƒ½ã€‚åŸºäºQt 6.6.3 å¼€å‘ï¼Œæœ¬è½¯ä»¶æ”¯æŒæœ¬åœ°æ¨¡å¼ï¼ˆSQLiteæ•°æ®åº“ï¼‰å’Œäº‘æ¨¡å¼ï¼ˆå¦‚MySQLï¼‰ï¼Œæ—¢å¯ä»¥æœ¬åœ°ä½¿ç”¨ï¼Œä¹Ÿå¯ä»¥è”ç½‘åŒæ­¥ä½¿ç”¨ã€‚(è”ç½‘éœ€æä¾›è‡ªå·±çš„äº‘æ•°æ®åº“) ä¸‹è½½ ä¸‹è½½é“¾æ¥: https://github.com/chandlerye/MyNote/releases ä½¿ç”¨è¯´æ˜ æ•°æ®åº“é…ç½® æœ¬åœ°æ¨¡å¼ï¼šé»˜è®¤é…ç½®ï¼Œæ•°æ®å­˜å‚¨åœ¨æœ¬åœ°SQLiteæ•°æ®åº“ï¼Œæ— éœ€ç‰¹æ®Šè®¾ç½®ã€‚ äº‘æ¨¡å¼é…ç½®ï¼šæ”¯æŒMySQLç­‰è¿œç¨‹æ•°æ®åº“ï¼Œéœ€è¾“å…¥æœåŠ¡å™¨IPã€ç«¯å£ã€æ•°æ®åº“åã€ç”¨æˆ·åå’Œå¯†ç è¿›è¡Œé…ç½®ã€‚ ç¬”è®°ç®¡ç† æ–°å¢ç¬”è®°ï¼šå·¦ä¸‹æ–¹æä¾›å¿«æ·æŒ‰é’®ã€‚ ç¼–è¾‘ç¬”è®°ï¼šåŒå‡»åˆ—è¡¨é¡¹æ ‡é¢˜è¿›å…¥ç¼–è¾‘çŠ¶æ€ï¼Œå³ä¾§æ–‡æœ¬æ¡†å®æ—¶ç¼–è¾‘å†…å®¹ã€‚ ç¬”è®°æ’åºï¼šæ”¯æŒç½®é¡¶æ“ä½œï¼Œè°ƒæ•´æ˜¾ç¤ºé¡ºåºã€‚ å¯¼å‡ºåŠŸèƒ½ï¼šç¬”è®°å¯å¯¼å‡ºä¸ºtxtæ ¼å¼ã€‚ å­—ä½“è°ƒæ•´ï¼šåœ¨é…ç½®èœå•ä¸­è‡ªå®šä¹‰æ–‡æœ¬ç¼–è¾‘å™¨çš„å­—ä½“å¤§å°ã€‚ æ³¨æ„äº‹é¡¹ è¯·ç¡®ä¿æ­£ç¡®é…ç½®äº‘æ•°æ®åº“ä¿¡æ¯ï¼Œé¿å…è¿æ¥é”™è¯¯ã€‚ åœ¨è¿›è¡Œæ¨¡å¼åˆ‡æ¢å‰ï¼Œå»ºè®®å¤‡ä»½é‡è¦æ•°æ®ã€‚ ä½¿ç”¨è¿‡ç¨‹ä¸­é‡åˆ°ä»»ä½•é—®é¢˜ï¼Œå¯é€šè¿‡æä¾›çš„è”ç³»æ–¹å¼å¯»æ±‚å¸®åŠ©ã€‚ æèµ  æ”¯æŒä¸€ä¸‹å§â¤ï¸","categories":[],"tags":[]},{"title":"Coding-QT-ç¼–ç¨‹çŸ¥è¯†ç‚¹","slug":"coding_qt_learn","date":"2024-06-09T06:27:47.520Z","updated":"2024-06-13T02:37:22.801Z","comments":true,"path":"2024/06/09/coding_qt_learn/","link":"","permalink":"http://example.com/2024/06/09/coding_qt_learn/","excerpt":"","text":"æ•°æ®åº“ç›¸å…³ QLiteæ•°æ®åº“ MySQLæ•°æ®åº“ æ‰“å¼€ä¸æ£€æŸ¥æ•°æ®åº“è¿æ¥ SQLè¯­å¥æ‰§è¡Œä¸æŸ¥è¯¢ å¿ƒè·³æ£€æŸ¥ äº‹ä»¶ç›¸å…³ æ¦‚å¿µ é‡å†™eventFilteræ–¹æ³• æ•°æ®åº“ç›¸å…³ QLiteæ•°æ®åº“ 123456789db = QSqlDatabase::addDatabase(&quot;QSQLITE&quot;); //æ·»åŠ æ•°æ®åº“é©±åŠ¨// è·å–å½“å‰ç¨‹åºçš„å·¥ä½œç›®å½•QString currentDir = QDir::currentPath();// æ‹¼æ¥æ•°æ®åº“æ–‡ä»¶åï¼Œä¾‹å¦‚ &quot;mydatabase.db&quot;QString dbName = &quot;mydatabase.db&quot;;// æ„å»ºå®Œæ•´çš„æ•°æ®åº“æ–‡ä»¶è·¯å¾„QString dbFilePath = currentDir + &quot;/&quot; + dbName;db.setDatabaseName(dbFilePath); MySQLæ•°æ®åº“ 123456db = QSqlDatabase::addDatabase(&quot;QMYSQL&quot;);db.setDatabaseName(&quot;mydatabase&quot;);db.setHostName(&quot;localhost&quot;);db.setPort(3306);db.setUserName(&quot;username&quot;);db.setPassword(&quot;password&quot;); æ‰“å¼€ä¸æ£€æŸ¥æ•°æ®åº“è¿æ¥ 12345if (!db.open()) &#123; qDebug() &lt;&lt; &quot;æ•°æ®åº“è¿æ¥å¤±è´¥&quot;;&#125; else &#123; qDebug() &lt;&lt; &quot;æ•°æ®åº“è¿æ¥æˆåŠŸ&quot;;&#125; SQLè¯­å¥æ‰§è¡Œä¸æŸ¥è¯¢ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152 // æŸ¥è¯¢ç‰¹å®šidçš„ç¬”è®°å†…å®¹QSqlQuery query;query.prepare(&quot;SELECT note FROM notes WHERE id = :id&quot;);query.bindValue(&quot;:id&quot;, selectedId); // ç»‘å®šæŸ¥è¯¢ä¸­çš„idå ä½ç¬¦// åˆ›å»ºnotesè¡¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºquery.prepare(&quot;CREATE TABLE IF NOT EXISTS notes(&quot; &quot;date TIMESTAMP DEFAULT CURRENT_TIMESTAMP, &quot; &quot;title VARCHAR(255) NOT NULL, &quot; &quot;note TEXT, &quot; &quot;id INTEGER PRIMARY KEY AUTOINCREMENT, &quot; // å¢åŠ ä¸»é”®è‡ªåŠ¨å¢é•¿ &quot;sort_order INTEGER)&quot;);if (query.next()) &#123; // ç¡®ä¿æŸ¥è¯¢æœ‰ç»“æœå†å–å€¼ int idOrder = query.value(0).toInt(); // è·å–id QString title = query.value(1).toString(); // è·å–title QString note = query.value(2).toString(); // è·å–note int sortOrder = query.value(3).toInt(); // è·å–sort_orderåºå·&#125;// æŸ¥è¯¢æ‰€æœ‰ç¬”è®°å¹¶æŒ‰sort_orderé™åºæ’åˆ—QSqlQuery query2;query2.prepare(&quot;SELECT id, title, note, sort_order FROM notes ORDER BY sort_order DESC&quot;);// æ›´æ–°ç¬”è®°å†…å®¹QSqlQuery updateQuery;updateQuery.prepare(&quot;UPDATE notes SET note = :newContent WHERE id = :id&quot;);updateQuery.bindValue(&quot;:newContent&quot;, newText); // ç»‘å®šæ–°çš„æ–‡æœ¬å†…å®¹updateQuery.bindValue(&quot;:id&quot;, currentId); // åŸºäºå½“å‰é€‰ä¸­æ ‡é¢˜æ›´æ–°å¯¹åº”çš„ç¬”è®°å†…å®¹// æŸ¥è¯¢å½“å‰æœ€å¤§idï¼ˆä¿®æ­£ä¸ºæŸ¥è¯¢æœ€å¤§sort_orderï¼‰QSqlQuery maxSortOrderQuery;maxSortOrderQuery.prepare(&quot;SELECT MAX(sort_order) FROM notes&quot;);// æ’å…¥æ–°ç¬”è®°è®°å½•QSqlQuery insertQuery;insertQuery.prepare(&quot;INSERT INTO notes (title, note, sort_order,id) VALUES (:title, :note, :sortOrder,:id)&quot;);insertQuery.bindValue(&quot;:title&quot;, title);insertQuery.bindValue(&quot;:note&quot;, &quot;&quot;); // åˆå§‹åŒ–ç¬”è®°å†…å®¹ä¸ºç©ºå­—ç¬¦ä¸²insertQuery.bindValue(&quot;:sortOrder&quot;, newSortOrder); // ä½¿ç”¨æ–°æ’åºåºå·insertQuery.bindValue(&quot;:id&quot;, newIdOrder); // å¦‚æœidæ˜¯è‡ªå¢çš„ï¼Œè¿™è¡Œå¯ä»¥çœç•¥æˆ–æ³¨é‡Šæ‰// åˆ é™¤æŒ‡å®šidçš„ç¬”è®°è®°å½•QSqlQuery deleteQuery;deleteQuery.prepare(&quot;DELETE FROM notes WHERE id = :id&quot;);deleteQuery.bindValue(&quot;:id&quot;, idToDelete);// ç»Ÿè®¡è®°å½•æ•°é‡QSqlQuery checkEmptyQuery;checkEmptyQuery.exec(&quot;SELECT COUNT(*) FROM notes&quot;);checkEmptyQuery.next();int rowCount = checkEmptyQuery.value(0).toInt(); å¿ƒè·³æ£€æŸ¥ 12345678910111213141516171819void MainWindow::ask_check()&#123; // ä½¿ç”¨æˆå‘˜å˜é‡æˆ–å±€éƒ¨é™æ€å˜é‡æ¥å­˜å‚¨å®šæ—¶å™¨ï¼Œç¡®ä¿å…¶ç”Ÿå‘½å‘¨æœŸè¶³å¤Ÿé•¿ QTimer* heartbeatTimer = new QTimer(this); // æ³¨æ„ä½¿ç”¨thisæŒ‡é’ˆä½œä¸ºçˆ¶å¯¹è±¡ï¼Œä»¥ä¾¿äºç®¡ç†å®šæ—¶å™¨çš„ç”Ÿå‘½å‘¨æœŸ connect(heartbeatTimer, &amp;QTimer::timeout, this, [this]() &#123; QSqlQuery query(db); if (query.exec(&quot;SELECT 1&quot;)) &#123; if (query.next()) &#123; ui-&gt;info_label-&gt;setStyleSheet(&quot;color: blue;&quot;); qDebug() &lt;&lt; &quot;å¿ƒè·³æ£€æµ‹ - æ•°æ®åº“è¿æ¥æ­£å¸¸&quot;; &#125; &#125; else &#123; ui-&gt;info_label-&gt;setStyleSheet(&quot;color: red;&quot;); qDebug() &lt;&lt; &quot;å¿ƒè·³æ£€æµ‹å¤±è´¥ï¼š&quot; &lt;&lt; query.lastError().text(); &#125; &#125;); heartbeatTimer-&gt;start(60000); // æ¯60ç§’æ‰§è¡Œä¸€æ¬¡å¿ƒè·³æ£€æµ‹&#125; äº‹ä»¶ç›¸å…³ æ¦‚å¿µ é€šè¿‡é‡å†™eventFilteræ–¹æ³•ï¼Œè‡ªå®šä¹‰å¯¹ç‰¹å®šå¯¹è±¡å’Œäº‹ä»¶ç±»å‹çš„å“åº”é€»è¾‘ã€‚ä¾‹å­ï¼šå¤„ç†å³é”®èœå•å’Œæ–‡æœ¬ç¼–è¾‘å™¨ç„¦ç‚¹å˜åŒ–ï¼Œåœ¨åˆé€‚çš„ä½ç½®æ³¨å†Œäº‹ä»¶è¿‡æ»¤å™¨ã€‚é€šå¸¸åœ¨æ„é€ å‡½æ•°æˆ–åˆå§‹åŒ–æ–¹æ³•ä¸­å®Œæˆæ­¤æ“ä½œã€‚ 12ui-&gt;listWidget-&gt;installEventFilter(this);ui-&gt;textEdit-&gt;installEventFilter(this); é‡å†™eventFilteræ–¹æ³• 1234567891011121314151617181920212223242526272829303132333435363738bool MainWindow::eventFilter(QObject *watched, QEvent *event)&#123; // å³é”®èœå•å¤„ç† if (watched == ui-&gt;listWidget &amp;&amp; event-&gt;type() == QEvent::ContextMenu) &#123; QContextMenuEvent *contextEvent = static_cast&lt;QContextMenuEvent*&gt;(event); // è·å–é¼ æ ‡ç‚¹å‡»ä½ç½®å¹¶è½¬æ¢ä¸ºåˆ—è¡¨é¡¹ç´¢å¼• QModelIndex index = ui-&gt;listWidget-&gt;indexAt(contextEvent-&gt;pos()); // å¦‚æœç´¢å¼•æœ‰æ•ˆï¼Œåˆ™å¼¹å‡ºèœå• if (index.isValid()) &#123; rightClickMenu-&gt;exec(contextEvent-&gt;globalPos()); return true; // æ¶ˆè€—äº‹ä»¶ &#125; &#125; // æ–‡æœ¬ç¼–è¾‘å™¨ç„¦ç‚¹å˜åŒ–å¤„ç† if (watched == ui-&gt;textEdit) &#123; if (event-&gt;type() == QEvent::FocusIn) &#123; isTextEditFocused = true; // å½“textEditè·å¾—ç„¦ç‚¹æ—¶ï¼Œå»ºç«‹textChangedçš„ä¿¡å·æ§½è¿æ¥ connect(ui-&gt;textEdit, &amp;QTextEdit::textChanged, this, &amp;MainWindow::onTextEditContentChanged); &#125; else if (event-&gt;type() == QEvent::FocusOut) &#123; isTextEditFocused = false; // å½“textEditå¤±å»ç„¦ç‚¹æ—¶ï¼Œæ–­å¼€textChangedçš„ä¿¡å·æ§½è¿æ¥ disconnect(ui-&gt;textEdit, &amp;QTextEdit::textChanged, this, &amp;MainWindow::onTextEditContentChanged); &#125; else if (event-&gt;type() &amp; Qt::ControlModifier) &#123; &#125; &#125; return QMainWindow::eventFilter(watched, event);&#125;","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Qt","slug":"Qt","permalink":"http://example.com/tags/Qt/"}]},{"title":"Coding-å¯è§†åŒ–-tensorboardçš„ä½¿ç”¨","slug":"coding_use_tensorboard","date":"2024-05-25T04:12:26.731Z","updated":"2024-05-25T04:20:02.629Z","comments":true,"path":"2024/05/25/coding_use_tensorboard/","link":"","permalink":"http://example.com/2024/05/25/coding_use_tensorboard/","excerpt":"","text":"æ‘˜è¦ æ‘˜è¦ ä»£ç æ®µé…ç½®äº†åœ¨TensorBoardä¸­å±•ç¤ºçš„ç”Ÿæˆå›¾åƒæ•°é‡ï¼Œå¹¶é€šè¿‡å¾ªç¯é€‰å–æŒ‡å®šæ•°é‡çš„å›¾åƒï¼Œåˆ©ç”¨make_gridå‡½æ•°å°†è¿™äº›å›¾åƒæ•´ç†æˆç½‘æ ¼å½¢å¼ï¼Œåšå¥½å½’ä¸€åŒ–å¤„ç†ä»¥ä¼˜åŒ–æ˜¾ç¤ºæ•ˆæœã€‚éšåï¼Œä½¿ç”¨tb_writer.add_imageåŠŸèƒ½å°†æ•´ç†å¥½çš„å›¾åƒç½‘æ ¼æ·»åŠ è‡³TensorBoardçš„æ—¥å¿—ä¸­ï¼Œæ ‡ä»¥â€™Generated Imagesâ€™ï¼Œå¹¶å€ŸåŠ©global_stepå‚æ•°è®°å½•äº†è®­ç»ƒè¿›ç¨‹ä¸­çš„å…·ä½“æ­¥æ•°ï¼Œä»¥ä¾¿äºè§‚å¯Ÿæ¨¡å‹ç”Ÿæˆå›¾åƒéšè®­ç»ƒè¿›å±•çš„å˜åŒ–æƒ…å†µã€‚ ä»£ç å¯ä»¥å†™åœ¨forå¾ªç¯æœ€åã€‚ 1234567891011121314151617181920import torch.utils.tensorboard as tbfrom torchvision.utils import save_image,make_grid# è®¾ç½®è¦åœ¨TensorBoardä¸­å±•ç¤ºçš„å›¾åƒæ•°é‡num_images_to_log = 4 # ä½ å¸Œæœ›åœ¨TensorBoardå¯è§†åŒ–ç•Œé¢ä¸­å±•ç¤ºçš„ç”Ÿæˆå›¾åƒçš„æ•°é‡# éå†ç”Ÿæˆçš„å›¾åƒï¼Œæ³¨æ„é™åˆ¶èŒƒå›´ä»¥ä¸è¶…è¿‡ç”¨æˆ·å®šä¹‰çš„æ•°é‡æˆ–å½“å‰æ‰¹æ¬¡ç”Ÿæˆçš„å›¾åƒæ€»æ•°for i in range(min(num_images_to_log, gen_imgs.size(0))): # ç¡®ä¿ç´¢å¼•ä¸ä¼šè¶…å‡ºç”Ÿæˆå›¾åƒåˆ—è¡¨çš„è¾¹ç•Œ # ä½¿ç”¨make_gridå‡½æ•°å°†ä¸€æ‰¹å›¾åƒæ’åˆ—æˆç½‘æ ¼ä»¥ä¾¿å±•ç¤ºï¼Œè¿™é‡Œå–è¿ç»­çš„5å¼ å›¾åƒï¼ˆi:i+5ï¼‰ # nrowå‚æ•°æŒ‡å®šäº†ç½‘æ ¼çš„åˆ—æ•°ï¼Œè¿™é‡Œè®¾ç½®ä¸º5åˆ—ï¼Œå› æ­¤ä¼šå½¢æˆä¸€ä¸ªæ­£æ–¹å½¢çš„ç½‘æ ¼å¸ƒå±€ # normalizeå‚æ•°è®¾ä¸ºTrueæ„å‘³ç€å°†å›¾åƒåƒç´ å€¼å½’ä¸€åŒ–åˆ°[0,1]åŒºé—´ï¼Œè¿™å¯¹äºå±•ç¤ºæ›´æœ‰åˆ©ï¼Œé¿å…åƒç´ å€¼æº¢å‡º # scale_eachä¸ºTrueåˆ™ä¼šå¯¹æ¯å¼ å›¾åƒå•ç‹¬è¿›è¡Œç¼©æ”¾ï¼Œç¡®ä¿å¯¹æ¯”åº¦ä¸€è‡´ï¼Œå³ä½¿å›¾åƒé—´äº®åº¦æœ‰å·®å¼‚ img_grid = make_grid(gen_imgs[i:i+5], nrow=5, normalize=True, scale_each=True) # å‡è®¾gen_imgsä¸­çš„å›¾åƒæ•°æ®å·²ç»è¢«é€‚å½“å¤„ç†ï¼ˆå¦‚å½’ä¸€åŒ–ï¼‰ï¼Œåˆ™normalizeå’Œscale_eachçš„è®¾å®šå¯æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´æˆ–çœç•¥ # å°†ç”Ÿæˆçš„å›¾åƒç½‘æ ¼æ·»åŠ åˆ°TensorBoardä¸­ï¼Œ&#x27;Generated Images&#x27;æ˜¯è¯¥å›¾åƒç³»åˆ—åœ¨TensorBoardä¸­çš„æ—¥å¿—æ ‡ç­¾ # global_stepå‚æ•°ç”¨äºæ ‡è®°è¿™æ˜¯è®­ç»ƒè¿‡ç¨‹ä¸­çš„å“ªä¸€æ­¥ï¼ˆæ¯”å¦‚è¿­ä»£æ¬¡æ•°ï¼‰ï¼Œæœ‰åŠ©äºè·Ÿè¸ªéšæ—¶é—´çš„å˜åŒ– # è¿™è¡Œä»£ç åœ¨æ¯ä¸ªepochè®­ç»ƒç»“æŸæ—¶æ‰§è¡Œï¼ˆç”±å¤–éƒ¨å¾ªç¯æ§åˆ¶batches_doneè®¡æ•°ï¼‰ï¼Œå°†æœ€æ–°çš„ç”Ÿæˆå›¾åƒæ›´æ–°åˆ°TensorBoard tb_writer.add_image(&#x27;Generated Images&#x27;, img_grid, global_step=batches_done)","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Code-åŸºç¡€æ¨¡å‹","slug":"Code-åŸºç¡€æ¨¡å‹","permalink":"http://example.com/tags/Code-%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B/"}]},{"title":"Coding-é‡æ–°è®¾ç½®å›¾åƒå°ºå¯¸-è£å‰ª","slug":"coding_crop_image","date":"2024-05-24T06:39:59.576Z","updated":"2024-05-24T06:41:13.871Z","comments":true,"path":"2024/05/24/coding_crop_image/","link":"","permalink":"http://example.com/2024/05/24/coding_crop_image/","excerpt":"","text":"æ‘˜è¦ æ‘˜è¦ å°†å›¾ç‰‡è£å‰ªæˆé¢„å®šå°ºå¯¸ï¼Œå¦‚æœå›¾ç‰‡å°äºé¢„å®šå°ºå¯¸åˆ™ä¼šç”¨é»‘åº•å¡«å…… 123456789101112131415161718192021222324252627282930313233343536373839404142from PIL import Imageimport ossource_folder = &#x27;data&#x27;output_folder = &#x27;output1024&#x27;target_resolution = (1024, 1024)if not os.path.exists(output_folder): os.makedirs(output_folder)for filename in os.listdir(source_folder): if filename.endswith(&#x27;.jpg&#x27;) or filename.endswith(&#x27;.jpeg&#x27;): img_path = os.path.join(source_folder, filename) try: with Image.open(img_path) as img: # è·å–å½“å‰å›¾ç‰‡çš„å°ºå¯¸ current_size = img.size # è®¡ç®—è£å‰ªåŒºåŸŸä»¥ä¿æŒçºµæ¨ªæ¯”å¹¶ç¡®ä¿è£å‰ªå‡ºçš„ç›®æ ‡å°ºå¯¸ width_ratio = current_size[0] / target_resolution[0] height_ratio = current_size[1] / target_resolution[1] crop_ratio = max(width_ratio, height_ratio) cropped_size = (int(current_size[0] / crop_ratio), int(current_size[1] / crop_ratio)) # è°ƒæ•´å›¾ç‰‡å¤§å°ä»¥ä¾¿è£å‰ªï¼ˆè¿™æ­¥å¯é€‰ï¼Œå–å†³äºæ˜¯å¦éœ€è¦å…ˆæŒ‰è°ƒæ•´å¤§å°åçš„å›¾ç‰‡ä¸­å¿ƒè¿›è¡Œè£å‰ªï¼‰ # img = img.resize(cropped_size, resample=Image.LANCZOS) # è®¡ç®—è£å‰ªçš„èµ·å§‹åæ ‡ä»¥ä¸­å¿ƒå¯¹é½ left = (current_size[0] - cropped_size[0]) // 2 top = (current_size[1] - cropped_size[1]) // 2 # ç›´æ¥è¿›è¡Œä¸­å¿ƒè£å‰ªåˆ°ç›®æ ‡å°ºå¯¸ img = img.crop((left, top, left + target_resolution[0], top + target_resolution[1])) # ä¿å­˜å¤„ç†åçš„å›¾ç‰‡åˆ°ç›®æ ‡æ–‡ä»¶å¤¹ output_path = os.path.join(output_folder, filename) img.save(output_path, quality=95) except IOError as e: print(f&quot;Error processing &#123;img_path&#125;: &#123;e&#125;&quot;)print(&quot;Images have been processed and saved to&quot;, output_folder)","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Code-å›¾åƒå¤„ç†","slug":"Code-å›¾åƒå¤„ç†","permalink":"http://example.com/tags/Code-%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}]},{"title":"Coding-é‡æ–°è®¾ç½®å›¾åƒå°ºå¯¸-éè£å‰ª","slug":"coding_resize_image","date":"2024-05-22T12:10:04.536Z","updated":"2024-05-24T06:39:57.457Z","comments":true,"path":"2024/05/22/coding_resize_image/","link":"","permalink":"http://example.com/2024/05/22/coding_resize_image/","excerpt":"","text":"æ‘˜è¦ æ‘˜è¦ å°†å›¾ç‰‡è®¾ç½®æˆé¢„å®šå°ºå¯¸ï¼Œå¦‚æœå›¾ç‰‡å°ºå¯¸ä¸é¢„æœŸä¸ç¬¦åˆ™ä¼šè£å‰ªï¼Œå¦‚æœå›¾ç‰‡å°äºé¢„å®šå°ºå¯¸åˆ™ä¼šç”¨é»‘åº•å¡«å…… 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152from PIL import Imageimport os# æŒ‡å®šæºæ–‡ä»¶å¤¹å’Œç›®æ ‡æ–‡ä»¶å¤¹source_folder = &#x27;data&#x27;output_folder = &#x27;output28&#x27;# target_resolution = (1440, 1920)target_resolution = (28, 28)# ç¡®ä¿ç›®æ ‡æ–‡ä»¶å¤¹å­˜åœ¨if not os.path.exists(output_folder): os.makedirs(output_folder)# éå†æºæ–‡ä»¶å¤¹ä¸­çš„å›¾ç‰‡for filename in os.listdir(source_folder): if filename.endswith(&#x27;.jpg&#x27;) or filename.endswith(&#x27;.jpeg&#x27;): img_path = os.path.join(source_folder, filename) try: with Image.open(img_path) as img: # è·å–å½“å‰å›¾ç‰‡çš„å°ºå¯¸ current_size = img.size # å¦‚æœå›¾ç‰‡å°ºå¯¸å¤§äºæˆ–ç­‰äºç›®æ ‡å°ºå¯¸ï¼Œè¿›è¡Œä¸­å¿ƒè£å‰ª if current_size[0] &gt;= target_resolution[0] and current_size[1] &gt;= target_resolution[1]: width_ratio = target_resolution[0] / current_size[0] height_ratio = target_resolution[1] / current_size[1] crop_ratio = min(width_ratio, height_ratio) new_size = (int(current_size[0] * crop_ratio), int(current_size[1] * crop_ratio)) img = img.resize(new_size, resample=Image.LANCZOS) left = (new_size[0] - target_resolution[0]) // 2 top = (new_size[1] - target_resolution[1]) // 2 right = (new_size[0] + target_resolution[0]) // 2 bottom = (new_size[1] + target_resolution[1]) // 2 img = img.crop((left, top, right, bottom)) # å¦‚æœå›¾ç‰‡å°ºå¯¸å°äºç›®æ ‡å°ºå¯¸ï¼Œè¿›è¡Œé»‘è‰²å¡«å…… else: # åˆ›å»ºä¸€ä¸ªç›®æ ‡å°ºå¯¸çš„é»‘è‰²èƒŒæ™¯å›¾åƒ(æƒ³è¦ç™½è‰²å°±æ˜¯255,255,255) new_img = Image.new(&#x27;RGB&#x27;, target_resolution, (0, 0, 0)) # æ˜ç¡®æŒ‡å®šå¡«å……é¢œè‰²ä¸ºé»‘è‰² # è®¡ç®—ç²˜è´´ä½ç½®ä»¥å±…ä¸­ paste_position = ((target_resolution[0] - current_size[0]) // 2, (target_resolution[1] - current_size[1]) // 2) new_img.paste(img, paste_position) img = new_img # ä¿å­˜å¤„ç†åçš„å›¾ç‰‡åˆ°ç›®æ ‡æ–‡ä»¶å¤¹ output_path = os.path.join(output_folder, filename) img.save(output_path, quality=95) except IOError as e: print(f&quot;Error processing &#123;img_path&#125;: &#123;e&#125;&quot;)print(&quot;Images have been processed and saved to&quot;, output_folder)","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Code-å›¾åƒå¤„ç†","slug":"Code-å›¾åƒå¤„ç†","permalink":"http://example.com/tags/Code-%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}]},{"title":"Coding-SRGAN-è¶…åˆ†è¾¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ-åŸºäºRGBå›¾ç‰‡æ•°æ®","slug":"coding_hight_resolutions_GAN","date":"2024-05-21T12:01:12.975Z","updated":"2024-05-21T12:10:00.541Z","comments":true,"path":"2024/05/21/coding_hight_resolutions_GAN/","link":"","permalink":"http://example.com/2024/05/21/coding_hight_resolutions_GAN/","excerpt":"","text":"æ‘˜è¦ srgan.py inference.py æ‘˜è¦ srgan.pyç”¨äºè®­ç»ƒç½‘ç»œ inference.pyç”¨äºä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶æ¨ç† å›¾ç‰‡æ•°æ®æ”¾åœ¨/home/myself/work/work-generate/dataä¸‹,æ‰€æœ‰å›¾ç‰‡åœ¨ä¸€ä¸ªæ–‡ä»¶å¤¹é‡Œ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164import argparseimport osimport numpy as npimport mathimport itertoolsimport sysimport torchvision.transforms as transformsfrom torchvision.utils import save_image, make_gridfrom torch.utils.data import DataLoaderfrom torch.autograd import Variablefrom models import *from datasets import *import torch.nn as nnimport torch.nn.functional as Fimport torchos.makedirs(&quot;/home/myself/work/work-generate/srgan/images&quot;, exist_ok=True)os.makedirs(&quot;/home/myself/work/work-generate/srgan/saved_models&quot;, exist_ok=True)parser = argparse.ArgumentParser()parser.add_argument(&quot;--epoch&quot;, type=int, default=0, help=&quot;epoch to start training from&quot;)parser.add_argument(&quot;--n_epochs&quot;, type=int, default=200, help=&quot;number of epochs of training&quot;)parser.add_argument(&quot;--dataset_name&quot;, type=str, default=&quot;data&quot;, help=&quot;name of the dataset&quot;)parser.add_argument(&quot;--batch_size&quot;, type=int, default=4, help=&quot;size of the batches&quot;)parser.add_argument(&quot;--lr&quot;, type=float, default=0.0002, help=&quot;adam: learning rate&quot;)parser.add_argument(&quot;--b1&quot;, type=float, default=0.5, help=&quot;adam: decay of first order momentum of gradient&quot;)parser.add_argument(&quot;--b2&quot;, type=float, default=0.999, help=&quot;adam: decay of first order momentum of gradient&quot;)parser.add_argument(&quot;--decay_epoch&quot;, type=int, default=100, help=&quot;epoch from which to start lr decay&quot;)parser.add_argument(&quot;--n_cpu&quot;, type=int, default=8, help=&quot;number of cpu threads to use during batch generation&quot;)parser.add_argument(&quot;--hr_height&quot;, type=int, default=512, help=&quot;high res. image height&quot;)parser.add_argument(&quot;--hr_width&quot;, type=int, default=512, help=&quot;high res. image width&quot;)parser.add_argument(&quot;--channels&quot;, type=int, default=3, help=&quot;number of image channels&quot;)parser.add_argument(&quot;--sample_interval&quot;, type=int, default=100, help=&quot;interval between saving image samples&quot;)parser.add_argument(&quot;--checkpoint_interval&quot;, type=int, default=20, help=&quot;interval between model checkpoints&quot;)opt = parser.parse_args()print(opt)cuda = torch.cuda.is_available()hr_shape = (opt.hr_height, opt.hr_width)# Initialize generator and discriminatorgenerator = GeneratorResNet()discriminator = Discriminator(input_shape=(opt.channels, *hr_shape))feature_extractor = FeatureExtractor()# Set feature extractor to inference modefeature_extractor.eval()# Lossescriterion_GAN = torch.nn.MSELoss()criterion_content = torch.nn.L1Loss()if cuda: generator = generator.cuda() discriminator = discriminator.cuda() feature_extractor = feature_extractor.cuda() criterion_GAN = criterion_GAN.cuda() criterion_content = criterion_content.cuda()if opt.epoch != 0: # Load pretrained models generator.load_state_dict(torch.load(&quot;/home/myself/work/work-generate/srgan/saved_models/generator_%d.pth&quot;)) discriminator.load_state_dict(torch.load(&quot;/home/myself/work/work-generate/srgan/saved_models/discriminator_%d.pth&quot;))# Optimizersoptimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))Tensor = torch.cuda.FloatTensor if cuda else torch.Tensordataloader = DataLoader( ImageDataset(&quot;/home/myself/work/work-generate/%s&quot; % opt.dataset_name, hr_shape=hr_shape), batch_size=opt.batch_size, shuffle=True, num_workers=opt.n_cpu,)# ----------# Training# ----------def main(): for epoch in range(opt.epoch, opt.n_epochs): for i, imgs in enumerate(dataloader): # Configure model input imgs_lr = Variable(imgs[&quot;lr&quot;].type(Tensor)) imgs_hr = Variable(imgs[&quot;hr&quot;].type(Tensor)) # Adversarial ground truths valid = Variable(Tensor(np.ones((imgs_lr.size(0), *discriminator.output_shape))), requires_grad=False) fake = Variable(Tensor(np.zeros((imgs_lr.size(0), *discriminator.output_shape))), requires_grad=False) # ------------------ # Train Generators # ------------------ optimizer_G.zero_grad() # Generate a high resolution image from low resolution input gen_hr = generator(imgs_lr) # Adversarial loss loss_GAN = criterion_GAN(discriminator(gen_hr), valid) # Content loss gen_features = feature_extractor(gen_hr) real_features = feature_extractor(imgs_hr) loss_content = criterion_content(gen_features, real_features.detach()) # Total loss loss_G = loss_content + 1e-3 * loss_GAN loss_G.backward() optimizer_G.step() # --------------------- # Train Discriminator # --------------------- optimizer_D.zero_grad() # Loss of real and fake images loss_real = criterion_GAN(discriminator(imgs_hr), valid) loss_fake = criterion_GAN(discriminator(gen_hr.detach()), fake) # Total loss loss_D = (loss_real + loss_fake) / 2 loss_D.backward() optimizer_D.step() # -------------- # Log Progress # -------------- sys.stdout.write( &quot;[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]&quot; % (epoch, opt.n_epochs, i, len(dataloader), loss_D.item(), loss_G.item()) ) batches_done = epoch * len(dataloader) + i if batches_done % opt.sample_interval == 0: # Save image grid with upsampled inputs and SRGAN outputs imgs_lr = nn.functional.interpolate(imgs_lr, scale_factor=4) gen_hr = make_grid(gen_hr, nrow=1, normalize=True) imgs_lr = make_grid(imgs_lr, nrow=1, normalize=True) img_grid = torch.cat((imgs_lr, gen_hr), -1) save_image(img_grid, &quot;/home/myself/work/work-generate/srgan/images/%d.png&quot; % batches_done, normalize=False) if opt.checkpoint_interval != -1 and epoch % opt.checkpoint_interval == 0: # Save model checkpoints torch.save(generator.state_dict(), &quot;/home/myself/work/work-generate/srgan/saved_models/generator_%d.pth&quot; % epoch) torch.save(discriminator.state_dict(), &quot;/home/myself/work/work-generate/srgan/saved_models/discriminator_%d.pth&quot; % epoch)if __name__ == &#x27;__main__&#x27;: main() 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103# å¯¼å…¥æ‰€éœ€åº“å’Œæ¨¡å—import torch.nn as nn # PyTorchç¥ç»ç½‘ç»œæ¨¡å—import torch.nn.functional as F # é™„åŠ åŠŸèƒ½ï¼Œå¦‚æ¿€æ´»å‡½æ•°ç­‰import torch # ä¸»PyTorchåº“from torchvision.models import vgg19 # VGG19æ¨¡å‹ï¼Œè™½ç„¶æœªç›´æ¥ä½¿ç”¨ï¼Œä½†å¯èƒ½æ˜¯å‚è€ƒæˆ–é¢„ç•™import math # æ•°å­¦è¿ç®—åº“from PIL import Image # å¤„ç†å›¾åƒçš„åº“import torchvision.transforms as transforms # å›¾åƒè½¬æ¢å·¥å…·from torchvision.utils import save_image # ä¿å­˜å›¾åƒå·¥å…·import numpy as np # æ•°å€¼å¤„ç†åº“# å®šä¹‰æ®‹å·®å—ï¼Œç”¨äºæ„å»ºç”Ÿæˆå™¨ç½‘ç»œä¸­çš„æ®‹å·®ç½‘ç»œç»“æ„class ResidualBlock(nn.Module): def __init__(self, in_features): super(ResidualBlock, self).__init__() # å®šä¹‰ä¸€ç³»åˆ—å·ç§¯ã€æ‰¹å½’ä¸€åŒ–ã€æ¿€æ´»å‡½æ•°æ“ä½œ self.conv_block = nn.Sequential( nn.Conv2d(in_features, in_features, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(in_features, momentum=0.8), # åŠ¨é‡å‚æ•°è®¾ç½®ä¸º0.8 nn.PReLU(), # å‚æ•°ä¸ºé»˜è®¤å€¼çš„PReLUæ¿€æ´»å‡½æ•° nn.Conv2d(in_features, in_features, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(in_features, momentum=0.8), ) def forward(self, x): # å®ç°æ®‹å·®è¿æ¥ï¼Œè¾“å…¥xåŠ ä¸Šç»è¿‡å·ç§¯å—å¤„ç†åçš„x return x + self.conv_block(x)# å®šä¹‰ç”Ÿæˆå™¨ç½‘ç»œï¼ŒåŸºäºæ®‹å·®ç½‘ç»œç»“æ„class GeneratorResNet(nn.Module): def __init__(self, in_channels=3, out_channels=3, n_residual_blocks=16): super(GeneratorResNet, self).__init__() # ç¬¬ä¸€å±‚å·ç§¯å’ŒPReLUæ¿€æ´» self.conv1 = nn.Sequential(nn.Conv2d(in_channels, 64, kernel_size=9, stride=1, padding=4), nn.PReLU()) # é‡å¤å®šä¹‰n_residual_blocksæ¬¡æ•°çš„æ®‹å·®å— res_blocks = [ResidualBlock(64) for _ in range(n_residual_blocks)] self.res_blocks = nn.Sequential(*res_blocks) # å°†æ‰€æœ‰æ®‹å·®å—æ”¾å…¥ä¸€ä¸ªSequentialå®¹å™¨ä¸­ # æ®‹å·®å—ä¹‹åçš„ç¬¬äºŒä¸ªå·ç§¯å±‚å’Œæ‰¹å½’ä¸€åŒ– self.conv2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(64, momentum=0.8)) # ä¸Šé‡‡æ ·å±‚ï¼Œè¿™é‡Œä½¿ç”¨PixelShuffleè¿›è¡Œä¸Šé‡‡æ · upsampling = [ nn.Conv2d(64, 256, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(256), nn.PixelShuffle(upscale_factor=2), # ä½¿ç”¨PixelShuffleä¸Šé‡‡æ ·ï¼Œå› å­ä¸º2 nn.PReLU(), # æ¿€æ´»å‡½æ•° ] * 2 # é‡å¤ä¸¤æ¬¡ä¸Šè¿°æ“ä½œï¼Œè¿›è¡Œä¸¤è½®ä¸Šé‡‡æ · self.upsampling = nn.Sequential(*upsampling) # è¾“å‡ºå±‚ï¼Œæœ€ç»ˆçš„å·ç§¯å±‚å’ŒTanhæ¿€æ´» self.conv3 = nn.Sequential(nn.Conv2d(64, out_channels, kernel_size=9, stride=1, padding=4), nn.Tanh()) def forward(self, x): # å‰å‘ä¼ æ’­è¿‡ç¨‹ï¼ŒåŒ…æ‹¬æ®‹å·®ç»“æ„ã€ä¸Šé‡‡æ ·ç­‰ out1 = self.conv1(x) out = self.res_blocks(out1) out2 = self.conv2(out) out = torch.add(out1, out2) # è¿™é‡Œç›´æ¥ç›¸åŠ å¯èƒ½æœ‰è¯¯ï¼Œåº”æ˜¯æ®‹å·®ç»“æ„çš„æ­£ç¡®åº”ç”¨ out = self.upsampling(out) out = self.conv3(out) return out# åæ ‡å‡†åŒ–å‡½æ•°ï¼Œå°†æ¨¡å‹è¾“å‡ºè½¬æ¢ä¸ºå¯æ˜¾ç¤ºçš„æ ¼å¼def unnormalize(tensor, mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]): tensor = tensor.clone() # é˜²æ­¢åŸåœ°ä¿®æ”¹ï¼Œå…ˆå¤åˆ¶å¼ é‡ for i in range(tensor.size(1)): # éå†æ¯ä¸ªé€šé“ tensor[:, i, :, :] = tensor[:, i, :, :] * std[i] + mean[i] # åæ ‡å‡†åŒ–æ“ä½œ return tensor# ä¸»ç¨‹åºå…¥å£if __name__ == &#x27;__main__&#x27;: # è®¾ç½®å‡å€¼å’Œæ ‡å‡†å·®ï¼Œç”¨äºå›¾åƒæ ‡å‡†åŒ– mean = np.array([0.485, 0.456, 0.406]) std = np.array([0.229, 0.224, 0.225]) # å›¾åƒè½¬æ¢ç®¡é“ï¼ŒåŒ…å«è½¬Tensorå’Œæ ‡å‡†åŒ– transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean, std), ]) # åˆå§‹åŒ–å¹¶åŠ è½½é¢„è®­ç»ƒçš„ç”Ÿæˆå™¨æ¨¡å‹ g = GeneratorResNet() g.load_state_dict(torch.load(&#x27;generator_100.pth&#x27;)) # åŠ è½½å¹¶å¤„ç†å›¾åƒ input= Image.open(&quot;C:\\\\Users\\\\hahag\\\\OneDrive\\\\WORK\\\\work-generate\\\\6.jpg&quot;).convert(&quot;RGB&quot;) input = transform(input) # è½¬æ¢å›¾åƒ # æ·»åŠ batchç»´åº¦ input = input.unsqueeze(0) # é€šè¿‡ç”Ÿæˆå™¨ç”Ÿæˆè¾“å‡º output= g(input) # åæ ‡å‡†åŒ– output = unnormalize(output) # ä¿å­˜ç”Ÿæˆçš„å›¾åƒ save_image(output, &#x27;output.png&#x27;, normalize=False)","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Code-ç”Ÿæˆ","slug":"Code-ç”Ÿæˆ","permalink":"http://example.com/tags/Code-%E7%94%9F%E6%88%90/"}]},{"title":"Coding-GAN-ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ-åŸºäºRGBå›¾ç‰‡æ•°æ®","slug":"coding_image_GAN","date":"2024-05-21T11:55:09.914Z","updated":"2024-05-21T12:01:10.777Z","comments":true,"path":"2024/05/21/coding_image_GAN/","link":"","permalink":"http://example.com/2024/05/21/coding_image_GAN/","excerpt":"","text":"æ‘˜è¦ gan.py æ‘˜è¦ gan.pyç”¨äºè®­ç»ƒç½‘ç»œ å›¾ç‰‡æ•°æ®æ”¾åœ¨/home/myself/work/work-generate/data/dataä¸‹ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216import argparseimport osimport numpy as npimport mathimport torchvision.transforms as transformsfrom torchvision.utils import save_imagefrom torch.utils.data import Dataset,DataLoaderfrom torchvision import datasetsfrom torch.autograd import Variableimport torch.nn as nnimport torch.nn.functional as Fimport torchfrom torchvision.datasets import ImageFolderfrom PIL import Imageimport torchvision.models as models# åŠ è½½é¢„è®­ç»ƒçš„VGGæ¨¡å‹vgg = models.vgg16(pretrained=True)os.makedirs(&quot;/home/myself/work/work-generate/images&quot;, exist_ok=True)parser = argparse.ArgumentParser()parser.add_argument(&quot;--n_epochs&quot;, type=int, default=2000, help=&quot;number of epochs of training&quot;)parser.add_argument(&quot;--batch_size&quot;, type=int, default=32, help=&quot;size of the batches&quot;)parser.add_argument(&quot;--lr&quot;, type=float, default=0.0002, help=&quot;adam: learning rate&quot;)parser.add_argument(&quot;--b1&quot;, type=float, default=0.5, help=&quot;adam: decay of first order momentum of gradient&quot;)parser.add_argument(&quot;--b2&quot;, type=float, default=0.999, help=&quot;adam: decay of first order momentum of gradient&quot;)parser.add_argument(&quot;--n_cpu&quot;, type=int, default=8, help=&quot;number of cpu threads to use during batch generation&quot;)parser.add_argument(&quot;--latent_dim&quot;, type=int, default=1000, help=&quot;dimensionality of the latent space&quot;)parser.add_argument(&quot;--img_size&quot;, type=int, default=128, help=&quot;size of each image dimension&quot;)parser.add_argument(&quot;--channels&quot;, type=int, default=3, help=&quot;number of image channels&quot;)parser.add_argument(&quot;--sample_interval&quot;, type=int, default=400, help=&quot;interval betwen image samples&quot;)opt = parser.parse_args()print(opt)# è‡ªå®šä¹‰æ•°æ®é›†ç±»class CustomImageDataset(Dataset): def __init__(self, root_dir, transform=None): self.root_dir = root_dir self.transform = transform self.images = [f for f in os.listdir(root_dir) if f.endswith(&#x27;.jpg&#x27;)] def __len__(self): return len(self.images) def __getitem__(self, idx): img_path = os.path.join(self.root_dir, self.images[idx]) image = Image.open(img_path).convert(&quot;RGB&quot;) # ç¡®ä¿å›¾ç‰‡æ˜¯RGBæ¨¡å¼ if self.transform: image = self.transform(image) return imageclass Generator(nn.Module): def __init__(self): super(Generator, self).__init__() def block(in_feat, out_feat, normalize=True): layers = [nn.Linear(in_feat, out_feat)] if normalize: layers.append(nn.BatchNorm1d(out_feat, 0.8)) layers.append(nn.LeakyReLU(0.2, inplace=True)) return layers self.model = nn.Sequential( *block(opt.latent_dim, 128, normalize=False), *block(128, 256), *block(256, 512), *block(512, 1024), nn.Linear(1024, int(np.prod(img_shape))), nn.Tanh() ) def forward(self, z): img = self.model(z) img = img.view(img.size(0), *img_shape) return imgclass Discriminator(nn.Module): def __init__(self): super(Discriminator, self).__init__() self.model = nn.Sequential( nn.Linear(int(np.prod(img_shape)), 512), nn.LeakyReLU(0.2, inplace=True), nn.Linear(512, 256), nn.LeakyReLU(0.2, inplace=True), nn.Linear(256, 1), nn.Sigmoid(), ) def forward(self, img): img_flat = img.view(img.size(0), -1) validity = self.model(img_flat) return validityimg_shape = (opt.channels, opt.img_size, opt.img_size)cuda = True if torch.cuda.is_available() else False# Loss functionadversarial_loss = torch.nn.BCELoss()# Initialize generator and discriminatorgenerator = Generator()discriminator = Discriminator()if cuda: generator.cuda() discriminator.cuda() adversarial_loss.cuda()# Configure data loader# å›¾åƒé¢„å¤„ç†transform = transforms.Compose([ transforms.Resize((opt.img_size, opt.img_size)), # ç¡®ä¿è¿™ä¸æ¨¡å‹è¾“å…¥å°ºå¯¸åŒ¹é… transforms.ToTensor(), # å°†PIL Imageè½¬æ¢ä¸ºTensor transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) # å½’ä¸€åŒ–])# åˆ›å»ºæ•°æ®é›†å®ä¾‹dataset = CustomImageDataset(root_dir=&#x27;/home/myself/work/work-generate/data&#x27;, transform=transform)# åˆ›å»ºDataLoaderå®ä¾‹dataloader = DataLoader( dataset, batch_size=opt.batch_size, # ä½¿ç”¨æ‚¨ä¹‹å‰å®šä¹‰çš„æ‰¹å¤„ç†å¤§å° shuffle=True, # åœ¨æ¯ä¸ªepochå¼€å§‹æ—¶æ‰“ä¹±æ•°æ® num_workers=opt.n_cpu, # ä½¿ç”¨æŒ‡å®šæ•°é‡çš„CPUçº¿ç¨‹åŠ è½½æ•°æ®)# Optimizersoptimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensordef main(): # ---------- # Training # ---------- for epoch in range(opt.n_epochs): for i, imgs in enumerate(dataloader): # Adversarial ground truths valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False) fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False) # Configure input real_imgs = Variable(imgs.type(Tensor)) # ----------------- # Train Generator # ----------------- optimizer_G.zero_grad() # Sample noise as generator input z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim)))) # Generate a batch of images gen_imgs = generator(z) # Loss measures generator&#x27;s ability to fool the discriminator g_loss = adversarial_loss(discriminator(gen_imgs), valid) g_loss.backward() optimizer_G.step() # --------------------- # Train Discriminator # --------------------- optimizer_D.zero_grad() # Measure discriminator&#x27;s ability to classify real from generated samples real_loss = adversarial_loss(discriminator(real_imgs), valid) fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake) d_loss = (real_loss + fake_loss) / 2 d_loss.backward() optimizer_D.step() print( &quot;[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]&quot; % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item()) ) batches_done = epoch * len(dataloader) + i if batches_done % opt.sample_interval == 0: save_image(gen_imgs.data[:25], &quot;/home/myself/work/work-generate/images/%d.png&quot; % batches_done, nrow=5, normalize=True)if __name__ == &#x27;__main__&#x27;: main()","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Code-ç”Ÿæˆ","slug":"Code-ç”Ÿæˆ","permalink":"http://example.com/tags/Code-%E7%94%9F%E6%88%90/"}]},{"title":"Coding-QT-è¿æ¥äº‘ç«¯Mysqlé…ç½®","slug":"coding_qt_link_mysql","date":"2024-05-16T11:33:35.467Z","updated":"2024-05-21T12:22:40.975Z","comments":true,"path":"2024/05/16/coding_qt_link_mysql/","link":"","permalink":"http://example.com/2024/05/16/coding_qt_link_mysql/","excerpt":"","text":"è¿›å…¥æ•°æ®åº“ 1mysql -u root -p åˆ›å»ºæ–°ç”¨æˆ· 1CREATE USER &#x27;yyy&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;password&#x27;; æŸ¥çœ‹ç”¨æˆ· 1SELECT yyy,host FROM mysql.user; ä½¿ç”¨æ•°æ®åº“, ä¸ºç‰¹å®šç”¨æˆ·ï¼ˆyyyï¼‰ä¿®æ”¹host 123use mysql;update user set host=&#x27;%&#x27; where user=&#x27;yyy&#x27;; æ¥ç€è¿›è¡Œç”¨æˆ·èµ‹æƒ 12GRANT ALL PRIVILEGES ON test_db.* TO &#x27;yyy&#x27;@&#x27;%&#x27; WITH GRANT OPTION;# test_dbæ˜¯æ•°æ®åº“å æŸ¥çœ‹MySQLæ˜¯å¦å¯¹å¤–å¼€æ”¾ 1netstat -an | grep 3306 å¦‚æœæ²¡æœ‰è¦ä¿®æ”¹é…ç½®æ–‡ä»¶ 1234cd /etc/mysql/mysql.conf.d vim mysqld.cnf# æ³¨é‡Šæ‰ blind-address å’Œ myswlx-blind-adress ç„¶åé‡å¯ 1service mysql restart å¼€æ”¾3306ç«¯å£ 1sudo ufw allow 3306 QTè¿æ¥ä»£ç  12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &quot;mainwindow.h&quot;#include &lt;QApplication&gt;#include &lt;QLocale&gt;#include &lt;QTranslator&gt;#include &lt;QCoreApplication&gt;#include &lt;QDebug&gt;#include &lt;QPluginLoader&gt;#include &lt;QSql&gt;#include &lt;QSqlDatabase&gt;#include&lt;QSqlQuery&gt;int main(int argc, char *argv[])&#123; QApplication a(argc, argv);//æœ¬åœ° QSqlDatabase db=QSqlDatabase::addDatabase(&quot;QMYSQL&quot;); db.setHostName(&quot;localhost&quot;); // æœ¬åœ°æ•°æ®åº“ è¿œç¨‹DBæ˜¯ï¼šipaddress db.setPort(3306); // è®¾ç½®ç«¯å£å· db.setDatabaseName(&quot;test_db&quot;); // ä½¿ç”¨çš„æ•°æ®åº“ sql = use &#x27;æ•°æ®åº“å&#x27; db.setUserName(&quot;yyy&quot;); db.setPassword(&quot;passwd&quot;); if(db.open())&#123; qDebug()&lt;&lt;&quot;æˆåŠŸ&quot;; &#125;else&#123; qDebug()&lt;&lt;&quot;å¤±è´¥&quot;; &#125; QTranslator translator; const QStringList uiLanguages = QLocale::system().uiLanguages(); for (const QString &amp;locale : uiLanguages) &#123; const QString baseName = &quot;main_&quot; + QLocale(locale).name(); if (translator.load(&quot;:/i18n/&quot; + baseName)) &#123; a.installTranslator(&amp;translator); break; &#125; &#125; MainWindow w; w.show(); return a.exec();&#125;","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Qt","slug":"Qt","permalink":"http://example.com/tags/Qt/"}]},{"title":"Note-1922å¹´ã€ŠåŠ³åŠ¨æ³•å¤§çº²ã€‹","slug":"note-LaoDongFaDaGang","date":"2024-02-26T03:43:42.938Z","updated":"2024-02-26T03:53:59.359Z","comments":true,"path":"2024/02/26/note-LaoDongFaDaGang/","link":"","permalink":"http://example.com/2024/02/26/note-LaoDongFaDaGang/","excerpt":"","text":"ä¸­å›½åŠ³åŠ¨ç»„åˆä¹¦è®°éƒ¨æ‹Ÿå®šçš„åŠ³åŠ¨æ³•æ¡ˆå¤§çº² ï¼ˆä¸€ä¹äºŒäºŒå¹´å…«æœˆï¼‰ ï¼ˆä¸€ï¼‰æ‰¿è®¤åŠ³åŠ¨è€…ä¹‹é›†ä¼šç»“ç¤¾æƒã€‚ ï¼ˆäºŒï¼‰æ‰¿è®¤åŠ³åŠ¨è€…ä¹‹åŒç›Ÿç½¢å·¥æƒã€‚ ï¼ˆä¸‰ï¼‰æ‰¿è®¤åŠ³åŠ¨è€…ä¹‹å›¢ä½“çš„å¥‘çº¦ç¼”ç»“æƒã€‚ ï¼ˆå››ï¼‰æ‰¿è®¤åŠ³åŠ¨è€…ä¹‹å›½é™…çš„è”åˆã€‚ ï¼ˆäº”ï¼‰æ—¥å·¥ä¸å¾—è¿‡å…«å°æ—¶ï¼Œå¤œå·¥ä¸å¾—è¿‡å…­å°æ—¶ï¼Œæ¯æ˜ŸæœŸè¿ç»­å››åäºŒå°æ—¶ã€ˆä¼‘æ¯ã€‰ã€‚ ï¼ˆå…­ï¼‰åå…«å²ä»¥ä¸‹é’å¹´ç”·å¥³å·¥äººåŠåƒåŠ›çš„å·¥ä½œï¼Œä¸å¾—è¿‡å…­å°æ—¶ã€‚ ï¼ˆä¸ƒï¼‰ç¦æ­¢è¶…è¿‡æ³•å®šçš„å·¥ä½œæ—¶é—´ã€‚å¦‚åœ¨ç‰¹åˆ«æƒ…å½¢é¡»å¾—å·¥ä¼šåŒæ„æ‰å¾—å¢åŠ å·¥ä½œæ—¶é—´ã€‚ ï¼ˆå…«ï¼‰å†œå·¥çš„å·¥ä½œæ—¶é—´è™½å¯è¶…è¿‡å…«å°æ—¶ï¼Œä½†æ‰€è¶…è¿‡ä¹‹å·¥ä½œæ—¶é—´çš„å·¥å€¼ï¼Œé¡»æŒ‰ç…§å…«å°æ—¶åˆ¶çš„åŸºç¡€è®¡ç®—ã€‚ ï¼ˆä¹ï¼‰é¡»ä»¥æ³•å¾‹æ‹…ä¿ä¸€èˆ¬ä¸æ å¤ºåˆ«äººåŠ³åŠ¨ä¹‹å†œäººçš„å†œäº§å“ä»·æ ¼ï¼Œæ­¤é¡¹ä»·æ ¼ç”±å†œäººä»£è¡¨æå‡ºï¼Œä»¥æ³•å¾‹è§„å®šä¹‹ã€‚ ï¼ˆåï¼‰åƒåŠ›çš„å·¥ä½œåŠæœ‰ç¢å«ç”Ÿçš„å·¥ä½œï¼Œå¯¹äºåå…«å²ä»¥ä¸‹çš„ç”·å¥³å·¥äººï¼Œç»å¯¹ç¦æ­¢è¶…è¿‡æ³•å®šæ—¶é—´ã€‚ç»å¯¹ç¦æ­¢å¥³å·¥åŠåå…«å²ä»¥ä¸‹ç”·å·¥ä½œå¤œå·¥ã€‚ ï¼ˆåä¸€ï¼‰ä½“åŠ›çš„å¥³å·¥äº§å‰äº§åå„å…«æ˜ŸæœŸä¼‘å·¥ï¼›å…¶ä»–å·¥ä½œä¹‹å¥³å·¥ï¼Œäº§å‰äº§åå„å…­æ˜ŸæœŸä¼‘å·¥ï¼Œå‡ç…§å¸¸é¢†å–å·¥èµ„ã€‚ ï¼ˆåäºŒï¼‰ç¦æ­¢é›‡ç”¨åå…­å²ä»¥ä¸‹ä¹‹ç”·å¥³ç«¥å·¥ã€‚ ï¼ˆåä¸‰ï¼‰ä¸ºä¿éšœå·¥äººé€‚å½“ä»¥è‡³ä½é™åº¦çš„å·¥é’±ï¼Œå›½å®¶é¡»åˆ¶å®šè¿™ç§ä¿éšœæ³•å¾‹ã€‚å½“ç«‹æ­¤é¡¹æ³•å¾‹æ—¶ï¼Œé¡»å‡†å…¨å›½æ€»å·¥ä¼šä»£è¡¨å‡ºå¸­ã€‚æ— è®ºå…¬ç§ä¼ä¸šæˆ–æœºå…³çš„å·¥èµ„ï¼Œå‡ä¸å¾—ä½äºæ­¤é¡¹æ³•å¾‹ä¿éšœçš„è‡³ä½é™åº¦ã€‚ ï¼ˆåå››ï¼‰å„ç§å·¥äººï¼Œç”±ä»–ä»¬äº§ä¸šç»„åˆæˆ–èŒä¸šç»„åˆä¿éšœï¼Œå¯é€‰ä¸¾ä»£è¡¨å‚åŠ æ”¿åºœç»æµæœºå…³ï¼ŒåŠé€‰ä¸¾ä»£è¡¨å‚åŠ æ”¿åºœä¼ä¸šæœºå…³ï¼ŒåŠæ”¿åºœæ‰€ç®¡ç†çš„ç§äººä¼ä¸šæˆ–æœºå…³ä¹‹æƒã€‚ ï¼ˆåäº”ï¼‰å›½å®¶å¯¹äºå…¨å›½å…¬ç§å„ä¼ä¸šå‡é¡»è®¾ç«‹åŠ³åŠ¨æ£€æŸ¥å±€ã€‚ ï¼ˆåå…­ï¼‰å›½å®¶ä¿éšœå·¥äººæœ‰å®Œå…¨å‚åŠ å›½å®¶æ‰€è®¾åŠ³åŠ¨æ£€æŸ¥å±€ä¹‹æƒã€‚ ï¼ˆåä¸ƒï¼‰ä¸€åˆ‡ä¿é™©äº‹ä¸šï¼Œé¡»ç”±å·¥äººå‚åŠ è§„å®šä¹‹ï¼Œä»¥ä¿éšœæ‰€æœ‰åœ¨æ”¿åºœçš„ï¼Œå…¬å…±çš„ï¼Œç§äººçš„ä¼ä¸šå’Œæœºå…³å†…çš„å·¥äººä¹‹æŸå¤±æˆ–å±é™©ã€‚ä¿é™©è´¹å®Œå…¨ç”±é›‡ä¸»æˆ–å›½å®¶å‡ºä¹‹ï¼Œå—ä¿é™©è€…å†³ä¸åˆ†æ‹…ã€‚ ï¼ˆåå…«ï¼‰å„ç§å·¥äººå’Œé›‡ç”¨äººï¼Œä¸€å¹´å·¥ä½œä¸­æœ‰ä¸€æœˆä¹‹ä¼‘æ¯ï¼ŒåŠå¹´ä¸­æœ‰ä¸¤æ˜ŸæœŸä¹‹ä¼‘æ¯ï¼Œå¹¶é¢†è–ªä¹‹æƒã€‚ ï¼ˆåä¹ï¼‰å›½å®¶é¡»ä»¥æ³•å¾‹ä¿è¯ç”·å¥³å·¥äººæœ‰å—è¡¥ä¹ æ•™è‚²çš„æœºä¼šã€‚ ï¼ˆé™„ç™½ï¼‰å·¥å‹ä»¬ï¼è¿™æ˜¯æœ¬éƒ¨æ–Ÿé…Œå„å›½åŠ³åŠ¨æ³•æ‹Ÿå®šçš„ï¼Œæˆ‘ä»¬è®¤ä¸ºæ˜¯æœ€ä½çš„é™åº¦ï¼Œå¹¶ä¸è¿‡é«˜ï¼Œæˆ‘ä»¬æ˜¯éè¦å›½ä¼šéƒ½è¦é€šè¿‡ä¸å¯çš„ã€‚ä½†ä¸çŸ¥å„ä½å¯¹äºè¿™åä¹æ¡è®¤ä¸ºæ»¡è¶³ä¸æ»¡è¶³ï¼Ÿå®Œå¤‡ä¸å®Œå¤‡ï¼Ÿå¦‚æœ‰è®¤ä¸ºè¦å¢åŠ æˆ–æ›´æ”¹çš„è¯·å¿«å¿«æ¥å‡½ç¤ºçŸ¥ï¼Œä»¥ä¾¿ä¿®æ”¹ã€‚è¿™æ˜¯å…³äºæˆ‘ä»¬åŠ³åŠ¨é˜¶çº§åˆ‡èº«çš„åˆ©å®³ï¼Œæˆ‘ä»¬ä¸å¯å¿½è§†å‘€ï¼ æ ¹æ®ä¸€ä¹äºŒäºŒå¹´ä¹æœˆä¸‰æ—¥å‡ºç‰ˆçš„ã€Šå…ˆé©±ã€‹ç¬¬åä¸€æœŸåˆŠå° å¼•è‡ªï¼šä¸­å›½åŠ³åŠ¨ç»„åˆä¹¦è®°éƒ¨æ‹Ÿå®šçš„åŠ³åŠ¨æ³•æ¡ˆå¤§çº²","categories":[{"name":"ç¬”è®°","slug":"ç¬”è®°","permalink":"http://example.com/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"æ³•å¾‹","slug":"æ³•å¾‹","permalink":"http://example.com/tags/%E6%B3%95%E5%BE%8B/"}]},{"title":"Note-æ‚¬é›å‚","slug":"note-uvula","date":"2024-02-04T01:39:41.593Z","updated":"2024-02-04T01:45:36.209Z","comments":true,"path":"2024/02/04/note-uvula/","link":"","permalink":"http://example.com/2024/02/04/note-uvula/","excerpt":"","text":"æ‚¬é›å‚ï¼ˆuvule[ËˆjuËvjÊŠlÉ™]ï¼‰åˆåè…­å‚ï¼Œä¿—ç§°â€œå°èˆŒâ€ã€â€œåŠé’Ÿâ€ï¼Œæ˜¯äººä½“å£è…”å™¨å®˜ï¼Œæ‚¬æŒ‚äºè½¯è…­æ­£ä¸­é—´çš„æœ«ç«¯ã€‚æ‚¬é›å‚çš„åŠŸèƒ½æ˜¯åœ¨é¥®é£Ÿæ—¶ä¸Šå‡å µä½é£Ÿç‰©é€šè¿‡é¼»è…”è¿›å…¥æ°”ç®¡çš„é€šé“ï¼Œä»è€Œä½¿é£Ÿç‰©è¿›å…¥é£Ÿé“ã€‚åœ¨è¯­è¨€ä¸Šï¼Œéƒ¨åˆ†è¯­è¨€éœ€è¦åˆ©ç”¨å°èˆŒçš„æŒ¯åŠ¨å‘å‡ºå°èˆŒéŸ³ã€‚ æ‚¬é›å‚ä¸å…¶è¿æ¥çš„è½¯è…­ï¼Œä¸ç¡çœ å‘¼å¸ä¸­æ­¢ç—‡æœ‰ç›¸å½“ç¨‹åº¦çš„å…³è”ï¼Œç»å¸¸å¥½å‘äºä¸­å¹´ç”·æ€§ï¼Œå¯ä»¥é€è¿‡æ‰‹æœ¯æ²»ç–—ï¼šä¾‹å¦‚æ‚¬é›å‚è…­å’½æ•´å‹æ‰‹æœ¯ï¼ˆUPPPæ‰‹æœ¯ï¼‰ã€å¾®åˆ›è½¯è…­æ”¯æ¶æ‰‹æœ¯ï¼Œå¯ä»¥æœ‰æ•ˆè§£å†³å‘¼å¸ä¸­æ­¢ï¼Œä»¥åŠæ‰“é¼¾éŸ³é‡çš„é—®é¢˜ã€‚","categories":[{"name":"ç¬”è®°","slug":"ç¬”è®°","permalink":"http://example.com/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"åŒ»å­¦","slug":"åŒ»å­¦","permalink":"http://example.com/tags/%E5%8C%BB%E5%AD%A6/"}]},{"title":"Coding-CGAN","slug":"coding_cGAN","date":"2024-01-26T05:51:59.270Z","updated":"2024-05-22T02:17:49.750Z","comments":true,"path":"2024/01/26/coding_cGAN/","link":"","permalink":"http://example.com/2024/01/26/coding_cGAN/","excerpt":"","text":"æ‘˜è¦ cgan.py æ‘˜è¦ ç”Ÿæˆå™¨çš„è¾“å…¥ä¸ºå™ªå£° zzz å’Œæ ‡ç­¾ lll ï¼Œè¦æ±‚ç”Ÿæˆå™¨èƒ½ç”ŸæˆçœŸå›¾ç‰‡ï¼Œè¦æ±‚åˆ¤åˆ«å™¨èƒ½åˆ¤åˆ«ç”Ÿæˆçš„çœŸå›¾ç‰‡å’ŒçœŸæ­£çš„çœŸå›¾ç‰‡ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204import argparseimport osimport numpy as npimport mathimport torchvision.transforms as transformsfrom torchvision.utils import save_imagefrom torch.utils.data import DataLoaderfrom torchvision import datasetsfrom torch.autograd import Variableimport torch.nn as nnimport torch.nn.functional as Fimport torchos.makedirs(&quot;images&quot;, exist_ok=True)parser = argparse.ArgumentParser()parser.add_argument(&quot;--n_epochs&quot;, type=int, default=200, help=&quot;number of epochs of training&quot;)parser.add_argument(&quot;--batch_size&quot;, type=int, default=64, help=&quot;size of the batches&quot;)parser.add_argument(&quot;--lr&quot;, type=float, default=0.0002, help=&quot;adam: learning rate&quot;)parser.add_argument(&quot;--b1&quot;, type=float, default=0.5, help=&quot;adam: decay of first order momentum of gradient&quot;)parser.add_argument(&quot;--b2&quot;, type=float, default=0.999, help=&quot;adam: decay of first order momentum of gradient&quot;)parser.add_argument(&quot;--n_cpu&quot;, type=int, default=8, help=&quot;number of cpu threads to use during batch generation&quot;)parser.add_argument(&quot;--latent_dim&quot;, type=int, default=100, help=&quot;dimensionality of the latent space&quot;)parser.add_argument(&quot;--n_classes&quot;, type=int, default=10, help=&quot;number of classes for dataset&quot;)parser.add_argument(&quot;--img_size&quot;, type=int, default=32, help=&quot;size of each image dimension&quot;)parser.add_argument(&quot;--channels&quot;, type=int, default=1, help=&quot;number of image channels&quot;)parser.add_argument(&quot;--sample_interval&quot;, type=int, default=400, help=&quot;interval between image sampling&quot;)opt = parser.parse_args()print(opt)img_shape = (opt.channels, opt.img_size, opt.img_size)cuda = True if torch.cuda.is_available() else Falseclass Generator(nn.Module): def __init__(self): super(Generator, self).__init__() self.label_emb = nn.Embedding(opt.n_classes, opt.n_classes) def block(in_feat, out_feat, normalize=True): layers = [nn.Linear(in_feat, out_feat)] if normalize: layers.append(nn.BatchNorm1d(out_feat, 0.8)) layers.append(nn.LeakyReLU(0.2, inplace=True)) return layers self.model = nn.Sequential( *block(opt.latent_dim + opt.n_classes, 128, normalize=False), *block(128, 256), *block(256, 512), *block(512, 1024), nn.Linear(1024, int(np.prod(img_shape))), nn.Tanh() ) def forward(self, noise, labels): # Concatenate label embedding and image to produce input gen_input = torch.cat((self.label_emb(labels), noise), -1) img = self.model(gen_input) img = img.view(img.size(0), *img_shape) return imgclass Discriminator(nn.Module): def __init__(self): super(Discriminator, self).__init__() self.label_embedding = nn.Embedding(opt.n_classes, opt.n_classes) self.model = nn.Sequential( nn.Linear(opt.n_classes + int(np.prod(img_shape)), 512), nn.LeakyReLU(0.2, inplace=True), nn.Linear(512, 512), nn.Dropout(0.4), nn.LeakyReLU(0.2, inplace=True), nn.Linear(512, 512), nn.Dropout(0.4), nn.LeakyReLU(0.2, inplace=True), nn.Linear(512, 1), ) def forward(self, img, labels): # Concatenate label embedding and image to produce input d_in = torch.cat((img.view(img.size(0), -1), self.label_embedding(labels)), -1) validity = self.model(d_in) return validity# Loss functionsadversarial_loss = torch.nn.MSELoss()# Initialize generator and discriminatorgenerator = Generator()discriminator = Discriminator()if cuda: generator.cuda() discriminator.cuda() adversarial_loss.cuda()# Configure data loaderos.makedirs(&quot;../../data/mnist&quot;, exist_ok=True)dataloader = torch.utils.data.DataLoader( datasets.MNIST( &quot;../../data/mnist&quot;, train=True, download=True, transform=transforms.Compose( [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])] ), ), batch_size=opt.batch_size, shuffle=True,)# Optimizersoptimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensorLongTensor = torch.cuda.LongTensor if cuda else torch.LongTensordef sample_image(n_row, batches_done): &quot;&quot;&quot;Saves a grid of generated digits ranging from 0 to n_classes&quot;&quot;&quot; # Sample noise z = Variable(FloatTensor(np.random.normal(0, 1, (n_row ** 2, opt.latent_dim)))) # Get labels ranging from 0 to n_classes for n rows labels = np.array([num for _ in range(n_row) for num in range(n_row)]) labels = Variable(LongTensor(labels)) gen_imgs = generator(z, labels) save_image(gen_imgs.data, &quot;images/%d.png&quot; % batches_done, nrow=n_row, normalize=True)# ----------# Training# ----------for epoch in range(opt.n_epochs): for i, (imgs, labels) in enumerate(dataloader): batch_size = imgs.shape[0] # Adversarial ground truths valid = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False) fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False) # Configure input real_imgs = Variable(imgs.type(FloatTensor)) labels = Variable(labels.type(LongTensor)) # ----------------- # Train Generator # ----------------- optimizer_G.zero_grad() # Sample noise and labels as generator input z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, opt.latent_dim)))) gen_labels = Variable(LongTensor(np.random.randint(0, opt.n_classes, batch_size))) # Generate a batch of images gen_imgs = generator(z, gen_labels) # Loss measures generator&#x27;s ability to fool the discriminator è¦æ±‚ç”Ÿæˆå™¨èƒ½ç”ŸæˆçœŸå›¾ç‰‡ validity = discriminator(gen_imgs, gen_labels) g_loss = adversarial_loss(validity, valid) g_loss.backward() optimizer_G.step() # --------------------- # Train Discriminator # --------------------- optimizer_D.zero_grad() # Loss for real images validity_real = discriminator(real_imgs, labels) d_real_loss = adversarial_loss(validity_real, valid) # Loss for fake images validity_fake = discriminator(gen_imgs.detach(), gen_labels) d_fake_loss = adversarial_loss(validity_fake, fake) # Total discriminator loss è¦æ±‚åˆ¤åˆ«å™¨èƒ½åˆ¤åˆ«ç”Ÿæˆçš„çœŸå›¾ç‰‡å’ŒçœŸæ­£çš„çœŸå›¾ç‰‡ d_loss = (d_real_loss + d_fake_loss) / 2 d_loss.backward() optimizer_D.step() print( &quot;[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]&quot; % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item()) ) batches_done = epoch * len(dataloader) + i if batches_done % opt.sample_interval == 0: sample_image(n_row=10, batches_done=batches_done)","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Code-åŸºç¡€æ¨¡å‹","slug":"Code-åŸºç¡€æ¨¡å‹","permalink":"http://example.com/tags/Code-%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B/"}]},{"title":"Coding-GAN","slug":"coding_GAN","date":"2024-01-26T05:51:59.265Z","updated":"2024-05-22T02:22:27.490Z","comments":true,"path":"2024/01/26/coding_GAN/","link":"","permalink":"http://example.com/2024/01/26/coding_GAN/","excerpt":"","text":"æ‘˜è¦ cgan.py æ‘˜è¦ ç”Ÿæˆå™¨çš„è¾“å…¥ä¸ºå™ªå£° zzz ï¼Œè¦æ±‚ç”Ÿæˆå™¨èƒ½ç”ŸæˆçœŸå›¾ç‰‡ï¼Œè¦æ±‚åˆ¤åˆ«å™¨èƒ½åˆ¤åˆ«ç”Ÿæˆçš„çœŸå›¾ç‰‡å’ŒçœŸæ­£çš„çœŸå›¾ç‰‡ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170import argparseimport osimport numpy as npimport mathimport torchvision.transforms as transformsfrom torchvision.utils import save_imagefrom torch.utils.data import DataLoaderfrom torchvision import datasetsfrom torch.autograd import Variableimport torch.nn as nnimport torch.nn.functional as Fimport torchos.makedirs(&quot;images&quot;, exist_ok=True)parser = argparse.ArgumentParser()parser.add_argument(&quot;--n_epochs&quot;, type=int, default=200, help=&quot;number of epochs of training&quot;)parser.add_argument(&quot;--batch_size&quot;, type=int, default=64, help=&quot;size of the batches&quot;)parser.add_argument(&quot;--lr&quot;, type=float, default=0.0002, help=&quot;adam: learning rate&quot;)parser.add_argument(&quot;--b1&quot;, type=float, default=0.5, help=&quot;adam: decay of first order momentum of gradient&quot;)parser.add_argument(&quot;--b2&quot;, type=float, default=0.999, help=&quot;adam: decay of first order momentum of gradient&quot;)parser.add_argument(&quot;--n_cpu&quot;, type=int, default=8, help=&quot;number of cpu threads to use during batch generation&quot;)parser.add_argument(&quot;--latent_dim&quot;, type=int, default=100, help=&quot;dimensionality of the latent space&quot;)parser.add_argument(&quot;--img_size&quot;, type=int, default=28, help=&quot;size of each image dimension&quot;)parser.add_argument(&quot;--channels&quot;, type=int, default=1, help=&quot;number of image channels&quot;)parser.add_argument(&quot;--sample_interval&quot;, type=int, default=400, help=&quot;interval betwen image samples&quot;)opt = parser.parse_args()print(opt)img_shape = (opt.channels, opt.img_size, opt.img_size)cuda = True if torch.cuda.is_available() else Falseclass Generator(nn.Module): def __init__(self): super(Generator, self).__init__() def block(in_feat, out_feat, normalize=True): layers = [nn.Linear(in_feat, out_feat)] if normalize: layers.append(nn.BatchNorm1d(out_feat, 0.8)) layers.append(nn.LeakyReLU(0.2, inplace=True)) return layers self.model = nn.Sequential( *block(opt.latent_dim, 128, normalize=False), *block(128, 256), *block(256, 512), *block(512, 1024), nn.Linear(1024, int(np.prod(img_shape))), nn.Tanh() ) def forward(self, z): img = self.model(z) img = img.view(img.size(0), *img_shape) return imgclass Discriminator(nn.Module): def __init__(self): super(Discriminator, self).__init__() self.model = nn.Sequential( nn.Linear(int(np.prod(img_shape)), 512), nn.LeakyReLU(0.2, inplace=True), nn.Linear(512, 256), nn.LeakyReLU(0.2, inplace=True), nn.Linear(256, 1), nn.Sigmoid(), ) def forward(self, img): img_flat = img.view(img.size(0), -1) validity = self.model(img_flat) return validity# Loss functionadversarial_loss = torch.nn.BCELoss()# Initialize generator and discriminatorgenerator = Generator()discriminator = Discriminator()if cuda: generator.cuda() discriminator.cuda() adversarial_loss.cuda()# Configure data loaderos.makedirs(&quot;../../data/mnist&quot;, exist_ok=True)dataloader = torch.utils.data.DataLoader( datasets.MNIST( &quot;../../data/mnist&quot;, train=True, download=True, transform=transforms.Compose( [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])] ), ), batch_size=opt.batch_size, shuffle=True,)# Optimizersoptimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor# ----------# Training# ----------for epoch in range(opt.n_epochs): for i, (imgs, _) in enumerate(dataloader): # Adversarial ground truths valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False) fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False) # Configure input real_imgs = Variable(imgs.type(Tensor)) # ----------------- # Train Generator # ----------------- optimizer_G.zero_grad() # Sample noise as generator input z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim)))) # Generate a batch of images gen_imgs = generator(z) # Loss measures generator&#x27;s ability to fool the discriminator g_loss = adversarial_loss(discriminator(gen_imgs), valid) g_loss.backward() optimizer_G.step() # --------------------- # Train Discriminator # --------------------- optimizer_D.zero_grad() # Measure discriminator&#x27;s ability to classify real from generated samples real_loss = adversarial_loss(discriminator(real_imgs), valid) fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake) d_loss = (real_loss + fake_loss) / 2 d_loss.backward() optimizer_D.step() print( &quot;[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]&quot; % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item()) ) batches_done = epoch * len(dataloader) + i if batches_done % opt.sample_interval == 0: save_image(gen_imgs.data[:25], &quot;images/%d.png&quot; % batches_done, nrow=5, normalize=True)","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Code-åŸºç¡€æ¨¡å‹","slug":"Code-åŸºç¡€æ¨¡å‹","permalink":"http://example.com/tags/Code-%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B/"}]},{"title":"Hexoè¿è¥ç»´æŠ¤","slug":"coding_hexo","date":"2024-01-26T05:51:59.260Z","updated":"2024-05-22T02:26:20.530Z","comments":true,"path":"2024/01/26/coding_hexo/","link":"","permalink":"http://example.com/2024/01/26/coding_hexo/","excerpt":"","text":"ç”Ÿæˆæ¨é€ ä¸ºæ–‡ç« æ·»åŠ ç›®å½• å…¬å¼ä½¿ç”¨ ç”Ÿæˆæ¨é€ 1hexo g -d ä¸ºæ–‡ç« æ·»åŠ ç›®å½• å®‰è£…æ’ä»¶ 1npm install hexo-toc --save é…ç½®åšå®¢æ ¹ç›®å½•ä¸‹çš„_config.ymlæ–‡ä»¶ 12toc: maxdepth: 3 åœ¨éœ€è¦å±•ç¤ºç›®å½•çš„åœ°æ–¹æ·»åŠ ï¼š 1&lt;!-- toc --&gt; æ³¨æ„ï¼šæ˜¾ç¤ºçš„ç›®å½•åªä¼šåŒ…å«ä»£ç æ®µ &lt; !-- toc --&gt;ä¹‹åçš„å†…å®¹ å…¬å¼ä½¿ç”¨ å®‰è£… 12npm un hexo-renderer-marked --savenpm i hexo-renderer-markdown-it-plus --save åœ¨ _config.ymlä¸­é…ç½® 12345678910111213141516markdown_it_plus: highlight: true html: true xhtmlOut: true breaks: true langPrefix: linkify: true typographer: quotes: â€œâ€â€˜â€™ plugins: - plugin: name: markdown-it-katex enable: true - plugin: name: markdown-it-mark enable: false ä½¿ mathjaxç”Ÿæ•ˆ 12title: Hello Worldmathjax: true","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"ç¼–ç¨‹åŸºç¡€çŸ¥è¯†","slug":"ç¼–ç¨‹åŸºç¡€çŸ¥è¯†","permalink":"http://example.com/tags/%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}]},{"title":"Note-ä¸´åºŠå®éªŒ","slug":"note-clinical_trial","date":"2024-01-22T02:20:16.691Z","updated":"2024-02-04T01:42:23.635Z","comments":true,"path":"2024/01/22/note-clinical_trial/","link":"","permalink":"http://example.com/2024/01/22/note-clinical_trial/","excerpt":"","text":"0æœŸä¸´åºŠè¯•éªŒ ä½¿ç”¨å¾®å‰‚é‡å¥åº·å—è¯•è€…æˆ–ç—…äººè¿›è¡Œç»™è¯ç ”ç©¶ã€‚ æ‰€è°“å¾®å‰‚é‡ï¼Œæ˜¯æŒ‡ä½äºé€šè¿‡ä¸´åºŠå‰æ¯’ç†å­¦ç ”ç©¶è·å¾—çš„åŠ¨ç‰©å®‰å…¨æ€§æ•°æ®è€Œæ¨å¯¼å‡ºçš„æ‹Ÿç”¨äºäººä½“å¯èƒ½äº§ç”Ÿä¸´åºŠè¯ç†å­¦ä½œç”¨å‰‚é‡çš„1/100ï¼ŒåŒæ—¶ï¼Œæœ€å¤§å‰‚é‡ä¸è¶…è¿‡100ugçš„å‰‚é‡ã€‚ â… æœŸä¸´åºŠè¯•éªŒ ä»åˆå§‹å®‰å…¨å‰‚é‡å¼€å§‹ï¼Œé€æ¸åŠ å¤§ï¼Œè§‚å¯Ÿäººä½“å¯¹è¯¥ç§æ–°è¯çš„è€å—ç¨‹åº¦ï¼Œä»¥ç¡®å®šäººä½“å¯æ¥å—è€Œåˆä¸ä¼šå¯¼è‡´æ¯’å‰¯ååº”å‘ç”Ÿçš„å‰‚é‡å¤§å°ã€‚ ä¹‹åå°†è¿›è¡Œå¤šæ¬¡ç»™è¯è¯•éªŒï¼Œä»¥ç¡®å®šé€‚åˆäºâ…¡æœŸä¸´åºŠè¯•éªŒæ‰€éœ€çš„å‰‚é‡å’Œç¨‹åºã€‚åŒæ—¶ï¼Œè¿˜å¿…é¡»è¿›è¡Œäººä½“çš„å•å‰‚é‡å’Œå¤šå‰‚é‡çš„è¯åŠ¨å­¦ç ”ç©¶ï¼Œä»¥ä¸ºâ…¡æœŸä¸´åºŠè¯•éªŒæä¾›åˆé€‚çš„æ²»ç–—æ–¹æ¡ˆã€‚â… æœŸä¸´åºŠè¯•éªŒé€šå¸¸ç”±å¥åº·çš„å¿—æ„¿è€…å‚ä¸ã€‚ä¸€èˆ¬è€Œè¨€ï¼Œâ… æœŸä¸´åºŠè¯•éªŒæ€»å…±éœ€è¦è¯•éªŒ10~80ä¸ªç—…äººã€‚ â…¡æœŸä¸´åºŠè¯•éªŒ ç”¨è¾ƒå°æ€»ä½“çš„é€‰å®šé€‚åº”ç—‡çš„æ‚£è€…ï¼Œå¯¹è¯ç‰©çš„ç–—æ•ˆå’Œå®‰å…¨æ€§è¿›è¡Œä¸´åºŠç ”ç©¶ï¼Œå…¶é—´å°†é‡ç‚¹è§‚å¯Ÿæ–°è¯çš„æ²»ç–—æ•ˆæœå’Œä¸è‰¯ååº”ã€‚ åŒæ—¶ï¼Œè¿˜è¦å¯¹æ–°è¯çš„è¯åŠ¨å­¦å’Œç”Ÿç‰©åˆ©ç”¨åº¦æ–¹é¢è¿›è¡Œç ”ç©¶ï¼Œä»¥ç¡®å®šæ‚£è€…ä¸å¥åº·äººçš„è¯åŠ¨å­¦å·®å¼‚ã€‚â…¡æœŸä¸´åºŠè¯•éªŒçš„ä¸»è¦ç›®çš„æ˜¯ä¸ºâ…¢æœŸä¸´åºŠè¯•éªŒåšå‡†å¤‡ï¼Œä»¥ç¡®å®šåˆæ­¥çš„ä¸´åºŠé€‚åº”ç—‡å’Œæ²»ç–—æ–¹æ¡ˆã€‚â…¡æœŸä¸´åºŠè¯•éªŒæ€»å…±éœ€è¦è¯•éªŒ100-200ä¸ªç—…äººã€‚ â…¢æœŸä¸´åºŠè¯•éªŒ å¯¹å·²é€šè¿‡â…¡æœŸä¸´åºŠè¯•éªŒç¡®å®šäº†å…¶ç–—æ•ˆçš„æ–°è¯ï¼Œä¸ç°æœ‰å·²çŸ¥æ´»æ€§çš„è¯ç‰©æˆ–æ— è¯ç†æ´»æ€§çš„å®‰æ…°å‰‚è¿›è¡Œå¯¹ç…§è¯•éªŒã€‚ è¯¥æœŸè¯•éªŒå¯¹äºæ‚£è€…çš„é€‰æ‹©éå¸¸ä¸¥æ ¼ï¼Œå…¶è¿˜å¿…é¡»å…·æœ‰æ˜ç¡®çš„ç–—æ•ˆæ ‡å‡†å’Œå®‰å…¨æ€§è¯„ä»·æ ‡å‡†ã€‚æ–°è¯åœ¨ç»è¿‡å¯¹ç…§è¯•éªŒåï¼Œå°†å¯¹å…¶ç–—æ•ˆå’Œé•¿æœŸå®‰å…¨æ€§è¿›è¡Œå…¨é¢çš„è¯„ä»·ï¼Œä»¥åˆ¤æ–­å…¶æ˜¯å¦å…·æœ‰æ²»ç–—å­¦å’Œå®‰å…¨æ€§ç‰¹å¾ï¼Œè¿™å†³å®šç€å…¶æ˜¯å¦èƒ½å¤Ÿæ‰¹å‡†ä¸Šå¸‚é”€å”®ã€‚â…¢æœŸä¸´åºŠè¯•éªŒæ€»å…±éœ€è¦è¯•éªŒ300ï¼500ä¸ªç—…äººï¼Œæœ€å°‘è¦æµ‹è¯•100æ¬¡ï¼Œå¦åˆ™ç»Ÿè®¡å­¦ä¸Šä¼šæœ‰è¯¯å·®ï¼Œå¯¹ç…§ç»„çš„æ•°é‡åˆ™æ— å…·ä½“è§„å®šã€‚ â…£æœŸä¸´åºŠè¯•éªŒ åœ¨æ–°è¯æ¨å‡ºåï¼Œé€šè¿‡å¤§é‡è°ƒæŸ¥è¯ç‰©å¯¹ç—…äººçš„ä¸´åºŠæ•ˆæœåŠæƒ…å†µï¼Œç›‘è§†æ–°è¯æœ‰æ— æ•ˆï¼Œå¦‚ä½•æœ€å¥½åœ°ä½¿ç”¨ä»¥åŠå‰¯ä½œç”¨çš„å‘ç”Ÿæœºä¼šå’Œç¨‹åº¦ã€‚ è‹¥ç–—æ•ˆä¸ç†æƒ³æˆ–å‡ºç°ä¸¥é‡çš„å‰¯ä½œç”¨è€Œä¸”å‘ç”Ÿç‡è¾ƒé«˜ï¼Œç®¡åˆ¶éƒ¨é—¨åˆ™ä¼šå°†é‚£æ–°è¯å¬å›å’Œé€€å¸‚ã€‚ç¬¬4æœŸä¸´åºŠè¯•éªŒä¼šä¸€ç›´è¿›è¡Œï¼Œåªè¦ä»æœ‰å¾ˆå¤šäººç”¨è¿™ç§è¯ç‰©ã€‚","categories":[{"name":"ç¬”è®°","slug":"ç¬”è®°","permalink":"http://example.com/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"åŒ»å­¦","slug":"åŒ»å­¦","permalink":"http://example.com/tags/%E5%8C%BB%E5%AD%A6/"}]},{"title":"Coding-torch-æ•°æ®é›†-Datasets","slug":"coding_mydatasets","date":"2024-01-08T15:15:05.583Z","updated":"2024-05-22T03:52:57.842Z","comments":true,"path":"2024/01/08/coding_mydatasets/","link":"","permalink":"http://example.com/2024/01/08/coding_mydatasets/","excerpt":"","text":"torchå†…ç½®datasetsçš„ä½¿ç”¨æ–¹æ³• é€‚ç”¨äºå›¾ç‰‡åˆ†ç±»çš„datasets(æ•°æ®æ”¾åœ¨ä¸åŒçš„æ–‡ä»¶å¤¹ä¸‹è¡¨ç¤ºä¸åŒç±»åˆ«) é€‚ç”¨äºå›¾ç‰‡åˆ†å‰²ï¼Œç›®æ ‡æ£€æµ‹çš„datasets(æ•°æ®å’Œæ ‡ç­¾éƒ½æ˜¯å›¾åƒ) å­æ•°æ®é›†åˆ’åˆ† è¯»å…¥ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸‹çš„å›¾ç‰‡åˆ¶ä½œæ•°æ®é›†ï¼ˆä¸åˆ†ç±»ï¼‰ torchå†…ç½®datasetsçš„ä½¿ç”¨æ–¹æ³• 1234567891011121314151617import torchimport torchvisionimport torchvision.transforms as transforms# æ•°æ®é¢„å¤„ç†transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # å›¾åƒå½’ä¸€åŒ–])# åŠ è½½è®­ç»ƒé›†å’Œæµ‹è¯•é›†trainset = torchvision.datasets.CIFAR10(root=&#x27;./data&#x27;, train=True, download=True, transform=transform)testset = torchvision.datasets.CIFAR10(root=&#x27;./data&#x27;, train=False, download=True, transform=transform)# åˆ›å»ºæ•°æ®åŠ è½½å™¨trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2) é€‚ç”¨äºå›¾ç‰‡åˆ†ç±»çš„datasets(æ•°æ®æ”¾åœ¨ä¸åŒçš„æ–‡ä»¶å¤¹ä¸‹è¡¨ç¤ºä¸åŒç±»åˆ«) 12345678910111213141516171819202122232425262728293031import glob # å¯¼å…¥ç”¨äºæ–‡ä»¶è·¯å¾„åŒ¹é…çš„æ¨¡å—from torchvision import transforms # å¯¼å…¥å›¾åƒè½¬æ¢æ¨¡å—from torch.utils import data # å¯¼å…¥PyTorchæ•°æ®å·¥å…·æ¨¡å—from PIL import Image # å¯¼å…¥PILå›¾åƒå¤„ç†åº“# æ ‡å‡†åŒ–æ•°æ®transforms = transforms.Compose([ transforms.ToTensor(), # å°†å›¾åƒè½¬æ¢ä¸ºå¼ é‡ transforms.Resize((256, 256)), # è°ƒæ•´å›¾åƒå¤§å°ä¸º256x256 transforms.Normalize(mean=0.5, std=0.5) # æ ‡å‡†åŒ–å›¾åƒæ•°æ®])class my_dataset(data.Dataset): def __init__(self, imgs_path, annos_path): self.imgs_path = imgs_path # å›¾åƒæ–‡ä»¶è·¯å¾„ self.annos_path = annos_path # æ ‡ç­¾æ–‡ä»¶è·¯å¾„ def __getitem__(self, index): img_path = self.imgs_path[index] # è·å–å›¾åƒè·¯å¾„ pil_img = Image.open(img_path) # ä½¿ç”¨PILæ‰“å¼€å›¾åƒ pil_img = transforms(pil_img) # å¯¹å›¾åƒè¿›è¡Œé¢„å¤„ç† anno_path = self.annos_path[index] # è·å–æ ‡ç­¾è·¯å¾„ anno_img = Image.open(anno_path) # ä½¿ç”¨PILæ‰“å¼€æ ‡ç­¾å›¾åƒ pil_anno = transforms(anno_img) # å¯¹æ ‡ç­¾å›¾åƒè¿›è¡Œé¢„å¤„ç† return pil_img, pil_anno# åˆ›å»ºè®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†train_dataset = CustomDataset(train_data_path, transform=transform)val_dataset = CustomDataset(val_data_path, transform=transform) é€‚ç”¨äºå›¾ç‰‡åˆ†å‰²ï¼Œç›®æ ‡æ£€æµ‹çš„datasets(æ•°æ®å’Œæ ‡ç­¾éƒ½æ˜¯å›¾åƒ) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import glob # å¯¼å…¥ç”¨äºæ–‡ä»¶è·¯å¾„åŒ¹é…çš„æ¨¡å—from torchvision import transforms # å¯¼å…¥å›¾åƒè½¬æ¢æ¨¡å—from torch.utils import data # å¯¼å…¥PyTorchæ•°æ®å·¥å…·æ¨¡å—from PIL import Image # å¯¼å…¥PILå›¾åƒå¤„ç†åº“# æ ‡å‡†åŒ–æ•°æ®transforms = transforms.Compose([ transforms.ToTensor(), # å°†å›¾åƒè½¬æ¢ä¸ºå¼ é‡ transforms.Resize((256, 256)), # è°ƒæ•´å›¾åƒå¤§å°ä¸º256x256 transforms.Normalize(mean=0.5, std=0.5) # æ ‡å‡†åŒ–å›¾åƒæ•°æ®])class my_dataset(data.Dataset): def __init__(self, imgs_path, annos_path): self.imgs_path = imgs_path # å›¾åƒæ–‡ä»¶è·¯å¾„ self.annos_path = annos_path # æ ‡ç­¾æ–‡ä»¶è·¯å¾„ def __getitem__(self, index): img_path = self.imgs_path[index] # è·å–å›¾åƒè·¯å¾„ pil_img = Image.open(img_path) # ä½¿ç”¨PILæ‰“å¼€å›¾åƒ pil_img = transforms(pil_img) # å¯¹å›¾åƒè¿›è¡Œé¢„å¤„ç† anno_path = self.annos_path[index] # è·å–æ ‡ç­¾è·¯å¾„ anno_img = Image.open(anno_path) # ä½¿ç”¨PILæ‰“å¼€æ ‡ç­¾å›¾åƒ pil_anno = transforms(anno_img) # å¯¹æ ‡ç­¾å›¾åƒè¿›è¡Œé¢„å¤„ç† return pil_img, pil_anno def __len__(self): return len(self.imgs_path) # è¿”å›æ•°æ®é›†çš„é•¿åº¦# è®­ç»ƒæ•°æ®é›†å¯¼å…¥imgs_path = glob.glob(&#x27;facade/train_picture/*.png&#x27;) # åŒ¹é…è®­ç»ƒå›¾åƒæ–‡ä»¶è·¯å¾„label_path = glob.glob(&#x27;facade/train_label/*.jpg&#x27;) # åŒ¹é…è®­ç»ƒæ ‡ç­¾æ–‡ä»¶è·¯å¾„# æµ‹è¯•æ•°æ®é›†å¯¼å…¥test_imgs_path = glob.glob(&#x27;facade/test_picture/*.png&#x27;) # åŒ¹é…æµ‹è¯•å›¾åƒæ–‡ä»¶è·¯å¾„test_label_path = glob.glob(&#x27;facade/test_label/*.jpg&#x27;) # åŒ¹é…æµ‹è¯•æ ‡ç­¾æ–‡ä»¶è·¯å¾„# å¯¹æ•°æ®å’Œæ ‡ç­¾æ’åºï¼Œç¡®ä¿ä¸€ä¸€å¯¹åº”imgs_path = sorted(imgs_path)label_path = sorted(label_path)test_imgs_path = sorted(test_imgs_path)test_label_path = sorted(test_label_path)train_dataset = my_dataset(imgs_path, label_path) test_dataset = my_dataset(test_imgs_path, test_label_path) # åˆ›å»ºæµ‹è¯•æ•°æ®é›†å¯¹è±¡train_loader = data.DataLoader(train_dataset, batch_size=4, shuffle=True) # åˆ›å»ºè®­ç»ƒæ•°æ®åŠ è½½å™¨test_loader = data.DataLoader(test_dataset, batch_size=4, shuffle=False) # åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨ å­æ•°æ®é›†åˆ’åˆ† 1234567891011121314151617181920from torch.utils.data import Subset# åŠ è½½æ•°æ®é›†ï¼Œå¹¶åˆ†æˆä¸¤ä¸ªå­é›†train_data = dsets.ImageFolder(root=&#x27;data_self/train&#x27;, transform=transform)test_data = dsets.ImageFolder(root=&#x27;data_self/test&#x27;, transform=transform)# åˆ›å»ºè®­ç»ƒæ•°æ®é›†çš„ç´¢å¼•åˆ—è¡¨train_indices1 = list(range(0, len(train_data), 2))train_indices2 = list(range(1, len(train_data), 2))# åˆ›å»ºè®­ç»ƒå­é›†1å’Œè®­ç»ƒå­é›†2train_data1 = Subset(train_data, train_indices1)train_data2 = Subset(train_data, train_indices2)# åˆ›å»ºæµ‹è¯•æ•°æ®é›†çš„ç´¢å¼•åˆ—è¡¨test_indices1 = list(range(0, len(test_data), 2))test_indices2 = list(range(1, len(test_data), 2))# åˆ›å»ºæµ‹è¯•å­é›†1å’Œæµ‹è¯•å­é›†2test_data1 = Subset(test_data, test_indices1)test_data2 = Subset(test_data, test_indices2) è¯»å…¥ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸‹çš„å›¾ç‰‡åˆ¶ä½œæ•°æ®é›†ï¼ˆä¸åˆ†ç±»ï¼‰ 12345678910111213141516171819202122232425262728293031323334353637# è‡ªå®šä¹‰æ•°æ®é›†ç±»class CustomImageDataset(Dataset): def __init__(self, root_dir, transform=None): self.root_dir = root_dir self.transform = transform self.images = [f for f in os.listdir(root_dir) if f.endswith(&#x27;.jpg&#x27;)] def __len__(self): return len(self.images) def __getitem__(self, idx): img_path = os.path.join(self.root_dir, self.images[idx]) image = Image.open(img_path).convert(&quot;RGB&quot;) # ç¡®ä¿å›¾ç‰‡æ˜¯RGBæ¨¡å¼ if self.transform: image = self.transform(image) return image# å›¾åƒé¢„å¤„ç†transform = transforms.Compose([ transforms.Resize((opt.img_size, opt.img_size)), # ç¡®ä¿è¿™ä¸æ¨¡å‹è¾“å…¥å°ºå¯¸åŒ¹é… transforms.ToTensor(), # å°†PIL Imageè½¬æ¢ä¸ºTensor transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) # å½’ä¸€åŒ–])# åˆ›å»ºæ•°æ®é›†å®ä¾‹dataset = CustomImageDataset(root_dir=&#x27;/home/yeshixin/work/work-generate/data&#x27;, transform=transform)# åˆ›å»ºDataLoaderå®ä¾‹dataloader = DataLoader( dataset, batch_size=opt.batch_size, # ä½¿ç”¨æ‚¨ä¹‹å‰å®šä¹‰çš„æ‰¹å¤„ç†å¤§å° shuffle=True, # åœ¨æ¯ä¸ªepochå¼€å§‹æ—¶æ‰“ä¹±æ•°æ® num_workers=opt.n_cpu, # ä½¿ç”¨æŒ‡å®šæ•°é‡çš„CPUçº¿ç¨‹åŠ è½½æ•°æ®)","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Code-åŸºç¡€æ¨¡å‹","slug":"Code-åŸºç¡€æ¨¡å‹","permalink":"http://example.com/tags/Code-%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B/"}]},{"title":"Coding-çŒ«ç‹—æ•°æ®é›†åˆ†ç±»-åŸºäºCNN","slug":"coding_network_CNN","date":"2024-01-08T14:22:20.995Z","updated":"2024-01-23T03:54:29.595Z","comments":true,"path":"2024/01/08/coding_network_CNN/","link":"","permalink":"http://example.com/2024/01/08/coding_network_CNN/","excerpt":"","text":"æ‘˜è¦ main.py æ‘˜è¦ è®­ç»ƒä¸€ä¸ªå›¾ç‰‡åˆ†ç±»ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ æ–‡ä»¶ç›®å½• . â”œâ”€â”€ train â”‚ â”œâ”€â”€ cats â”‚ â””â”€â”€ dogs â””â”€â”€ validation â”œâ”€â”€ cats â””â”€â”€ dogs 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140import torchimport torch.nn as nnimport torch.optim as optimfrom torch.utils.data import DataLoader, Datasetfrom torchvision import transformsfrom torchvision.datasets import ImageFolder# å®šä¹‰è‡ªå®šä¹‰æ•°æ®é›†ç±»class CustomDataset(Dataset): def __init__(self, root_dir, transform=None): self.dataset = ImageFolder(root_dir, transform=transform) def __len__(self): return len(self.dataset) def __getitem__(self, idx): image, label = self.dataset[idx] return image, label# å®šä¹‰å·ç§¯ç¥ç»ç½‘ç»œæ¨¡å‹class CNNModel(nn.Module): def __init__(self, num_classes): super(CNNModel, self).__init__() self.features = nn.Sequential( nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), ) self.classifier = nn.Sequential( nn.Linear(32 * 3 * 3, 256), nn.ReLU(inplace=True), nn.Linear(256, num_classes) ) def forward(self, x): x = self.features(x) x = x.view(x.size(0), -1) x = self.classifier(x) return x# è®¾ç½®è®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†çš„è·¯å¾„train_data_path = &#x27;data1/train&#x27;val_data_path = &#x27;data1/validation&#x27;# å®šä¹‰å›¾åƒè½¬æ¢transform = transforms.Compose([ transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])# åˆ›å»ºè®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†train_dataset = CustomDataset(train_data_path, transform=transform)val_dataset = CustomDataset(val_data_path, transform=transform)# åˆ›å»ºæ•°æ®åŠ è½½å™¨batch_size = 32train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)val_loader = DataLoader(val_dataset, batch_size=batch_size)# åˆ›å»ºæ¨¡å‹å®ä¾‹num_classes = len(train_dataset.dataset.classes)model = CNNModel(num_classes)# è®¡ç®—å‚æ•°æ•°é‡num_params = sum(p.numel() for p in model.parameters())print(&quot;æ¨¡å‹å‚æ•°æ•°é‡ï¼š&quot;, num_params)# å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨criterion = nn.CrossEntropyLoss()optimizer = optim.Adam(model.parameters(), lr=0.001)# è®¾ç½®è®­ç»ƒå‚æ•°num_epochs = 2000check_point = 10 #mæ¯10ä¸ªepochéªŒè¯ä¸€å›device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)model.to(device)# å¼€å§‹è®­ç»ƒfor epoch in range(num_epochs): model.train() running_loss = 0.0 correct_predictions = 0 for images, labels in train_loader: images = images.to(device) labels = labels.to(device) optimizer.zero_grad() outputs = model(images) loss = criterion(outputs, labels) loss.backward() optimizer.step() _, predicted = torch.max(outputs.data, 1) correct_predictions += (predicted == labels).sum().item() running_loss += loss.item() epoch_accuracy = correct_predictions / len(train_dataset) epoch_loss = running_loss / len(train_loader) print(f&quot;Epoch [&#123;epoch+1&#125;/&#123;num_epochs&#125;], Loss: &#123;epoch_loss:.4f&#125;, Accuracy: &#123;epoch_accuracy:.4f&#125;&quot;) if epoch%check_point == 0 : # åœ¨éªŒè¯é›†ä¸Šè¿›è¡Œè¯„ä¼° model.eval() total_correct = 0 total_samples = 0 with torch.no_grad(): for images, labels in val_loader: images = images.to(device) labels = labels.to(device) outputs = model(images) _, predicted = torch.max(outputs.data, 1) total_samples += labels.size(0) total_correct += (predicted == labels).sum().item() val_accuracy = total_correct / total_samples print(f&quot;Validation Accuracy: &#123;val_accuracy:.4f&#125;&quot;)","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Code-åˆ†ç±»","slug":"Code-åˆ†ç±»","permalink":"http://example.com/tags/Code-%E5%88%86%E7%B1%BB/"}]},{"title":"Coding-æ¡ä»¶Unet-åŸºäºæ³¨æ„åŠ›æœºåˆ¶","slug":"coding_c_Unet","date":"2024-01-02T07:35:07.623Z","updated":"2024-05-22T02:18:19.529Z","comments":true,"path":"2024/01/02/coding_c_Unet/","link":"","permalink":"http://example.com/2024/01/02/coding_c_Unet/","excerpt":"","text":"æ‘˜è¦ unet.py test.py æ‘˜è¦ å¯å°†æ—¶é—´æ¡ä»¶å’Œç±»åˆ«æ¡ä»¶å¼•å…¥æ¨¡å‹ï¼Œå…±ä¸¤ä¸ªæ–‡ä»¶ï¼šunet.py,test.py,æ¨¡å‹ä¸º b=Unet(t,c,a)b=Unet(t,c,a) b=Unet(t,c,a) å…¶ä¸­bbbæ˜¯è¾“å‡ºï¼Œtttæ˜¯æ—¶é—´æ¡ä»¶ï¼Œcccæ˜¯ç±»åˆ«æ¡ä»¶ï¼Œaaaæ˜¯è¾“å…¥ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386import mathimport torchimport torch.nn as nnimport torch.nn.functional as Ffrom torch.nn.modules.normalization import GroupNormdef get_norm(norm, num_channels, num_groups): if norm == &quot;in&quot;: return nn.InstanceNorm2d(num_channels, affine=True) elif norm == &quot;bn&quot;: return nn.BatchNorm2d(num_channels) elif norm == &quot;gn&quot;: return nn.GroupNorm(num_groups, num_channels) elif norm is None: return nn.Identity() else: raise ValueError(&quot;unknown normalization type&quot;)class PositionalEmbedding(nn.Module): __doc__ = r&quot;&quot;&quot;Computes a positional embedding of timesteps. Input: x: tensor of shape (N) Output: tensor of shape (N, dim) Args: dim (int): embedding dimension scale (float): linear scale to be applied to timesteps. Default: 1.0 &quot;&quot;&quot; def __init__(self, dim, scale=1.0): super().__init__() assert dim % 2 == 0 self.dim = dim self.scale = scale def forward(self, x): device = x.device half_dim = self.dim // 2 emb = math.log(10000) / half_dim emb = torch.exp(torch.arange(half_dim, device=device) * -emb) emb = torch.outer(x * self.scale, emb) emb = torch.cat((emb.sin(), emb.cos()), dim=-1) return embclass Downsample(nn.Module): __doc__ = r&quot;&quot;&quot;Downsamples a given tensor by a factor of 2. Uses strided convolution. Assumes even height and width. Input: x: tensor of shape (N, in_channels, H, W) time_emb: ignored y: ignored Output: tensor of shape (N, in_channels, H // 2, W // 2) Args: in_channels (int): number of input channels &quot;&quot;&quot; def __init__(self, in_channels): super().__init__() self.downsample = nn.Conv2d(in_channels, in_channels, 3, stride=2, padding=1) def forward(self, x, time_emb, y): if x.shape[2] % 2 == 1: raise ValueError(&quot;downsampling tensor height should be even&quot;) if x.shape[3] % 2 == 1: raise ValueError(&quot;downsampling tensor width should be even&quot;) return self.downsample(x)class Upsample(nn.Module): __doc__ = r&quot;&quot;&quot;Upsamples a given tensor by a factor of 2. Uses resize convolution to avoid checkerboard artifacts. Input: x: tensor of shape (N, in_channels, H, W) time_emb: ignored y: ignored Output: tensor of shape (N, in_channels, H * 2, W * 2) Args: in_channels (int): number of input channels &quot;&quot;&quot; def __init__(self, in_channels): super().__init__() self.upsample = nn.Sequential( nn.Upsample(scale_factor=2, mode=&quot;nearest&quot;), nn.Conv2d(in_channels, in_channels, 3, padding=1), ) def forward(self, x, time_emb, y): return self.upsample(x)class AttentionBlock(nn.Module): __doc__ = r&quot;&quot;&quot;Applies QKV self-attention with a residual connection. Input: x: tensor of shape (N, in_channels, H, W) norm (string or None): which normalization to use (instance, group, batch, or none). Default: &quot;gn&quot; num_groups (int): number of groups used in group normalization. Default: 32 Output: tensor of shape (N, in_channels, H, W) Args: in_channels (int): number of input channels &quot;&quot;&quot; def __init__(self, in_channels, norm=&quot;gn&quot;, num_groups=32): super().__init__() self.in_channels = in_channels self.norm = get_norm(norm, in_channels, num_groups) self.to_qkv = nn.Conv2d(in_channels, in_channels * 3, 1) self.to_out = nn.Conv2d(in_channels, in_channels, 1) def forward(self, x): b, c, h, w = x.shape q, k, v = torch.split(self.to_qkv(self.norm(x)), self.in_channels, dim=1) q = q.permute(0, 2, 3, 1).view(b, h * w, c) k = k.view(b, c, h * w) v = v.permute(0, 2, 3, 1).view(b, h * w, c) dot_products = torch.bmm(q, k) * (c ** (-0.5)) assert dot_products.shape == (b, h * w, h * w) attention = torch.softmax(dot_products, dim=-1) out = torch.bmm(attention, v) assert out.shape == (b, h * w, c) out = out.view(b, h, w, c).permute(0, 3, 1, 2) return self.to_out(out) + xclass ResidualBlock(nn.Module): __doc__ = r&quot;&quot;&quot;Applies two conv blocks with resudual connection. Adds time and class conditioning by adding bias after first convolution. Input: x: tensor of shape (N, in_channels, H, W) time_emb: time embedding tensor of shape (N, time_emb_dim) or None if the block doesn&#x27;t use time conditioning y: classes tensor of shape (N) or None if the block doesn&#x27;t use class conditioning Output: tensor of shape (N, out_channels, H, W) Args: in_channels (int): number of input channels out_channels (int): number of output channels time_emb_dim (int or None): time embedding dimension or None if the block doesn&#x27;t use time conditioning. Default: None num_classes (int or None): number of classes or None if the block doesn&#x27;t use class conditioning. Default: None activation (function): activation function. Default: torch.nn.functional.relu norm (string or None): which normalization to use (instance, group, batch, or none). Default: &quot;gn&quot; num_groups (int): number of groups used in group normalization. Default: 32 use_attention (bool): if True applies AttentionBlock to the output. Default: False &quot;&quot;&quot; def __init__( self, in_channels, out_channels, dropout, time_emb_dim=None, num_classes=None, activation=F.relu, norm=&quot;gn&quot;, num_groups=32, use_attention=False, ): super().__init__() self.activation = activation self.norm_1 = get_norm(norm, in_channels, num_groups) self.conv_1 = nn.Conv2d(in_channels, out_channels, 3, padding=1) self.norm_2 = get_norm(norm, out_channels, num_groups) self.conv_2 = nn.Sequential( nn.Dropout(p=dropout), nn.Conv2d(out_channels, out_channels, 3, padding=1), ) self.time_bias = nn.Linear(time_emb_dim, out_channels) if time_emb_dim is not None else None self.class_bias = nn.Embedding(num_classes, out_channels) if num_classes is not None else None self.residual_connection = nn.Conv2d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity() self.attention = nn.Identity() if not use_attention else AttentionBlock(out_channels, norm, num_groups) def forward(self, x, time_emb=None, y=None): out = self.activation(self.norm_1(x)) out = self.conv_1(out) if self.time_bias is not None: if time_emb is None: raise ValueError(&quot;time conditioning was specified but time_emb is not passed&quot;) out += self.time_bias(self.activation(time_emb))[:, :, None, None] if self.class_bias is not None: if y is None: raise ValueError(&quot;class conditioning was specified but y is not passed&quot;) out += self.class_bias(y)[:, :, None, None] out = self.activation(self.norm_2(out)) out = self.conv_2(out) + self.residual_connection(x) out = self.attention(out) return outclass UNet(nn.Module): __doc__ = &quot;&quot;&quot;UNet model used to estimate noise. Input: x: tensor of shape (N, in_channels, H, W) time_emb: time embedding tensor of shape (N, time_emb_dim) or None if the block doesn&#x27;t use time conditioning y: classes tensor of shape (N) or None if the block doesn&#x27;t use class conditioning Output: tensor of shape (N, out_channels, H, W) Args: img_channels (int): number of image channels base_channels (int): number of base channels (after first convolution) channel_mults (tuple): tuple of channel multiplers. Default: (1, 2, 4, 8) time_emb_dim (int or None): time embedding dimension or None if the block doesn&#x27;t use time conditioning. Default: None time_emb_scale (float): linear scale to be applied to timesteps. Default: 1.0 num_classes (int or None): number of classes or None if the block doesn&#x27;t use class conditioning. Default: None activation (function): activation function. Default: torch.nn.functional.relu dropout (float): dropout rate at the end of each residual block attention_resolutions (tuple): list of relative resolutions at which to apply attention. Default: () norm (string or None): which normalization to use (instance, group, batch, or none). Default: &quot;gn&quot; num_groups (int): number of groups used in group normalization. Default: 32 initial_pad (int): initial padding applied to image. Should be used if height or width is not a power of 2. Default: 0 &quot;&quot;&quot; def __init__( self, img_channels, base_channels, channel_mults=(1, 2, 4, 8), num_res_blocks=2, time_emb_dim=None, time_emb_scale=1.0, num_classes=None, activation=F.relu, dropout=0.1, attention_resolutions=(), norm=&quot;gn&quot;, num_groups=32, initial_pad=0, ): super().__init__() self.activation = activation self.initial_pad = initial_pad self.num_classes = num_classes self.time_mlp = nn.Sequential( PositionalEmbedding(base_channels, time_emb_scale), nn.Linear(base_channels, time_emb_dim), nn.SiLU(), nn.Linear(time_emb_dim, time_emb_dim), ) if time_emb_dim is not None else None self.init_conv = nn.Conv2d(img_channels, base_channels, 3, padding=1) self.downs = nn.ModuleList() self.ups = nn.ModuleList() channels = [base_channels] now_channels = base_channels for i, mult in enumerate(channel_mults): out_channels = base_channels * mult for _ in range(num_res_blocks): self.downs.append(ResidualBlock( now_channels, out_channels, dropout, time_emb_dim=time_emb_dim, num_classes=num_classes, activation=activation, norm=norm, num_groups=num_groups, use_attention=i in attention_resolutions, )) now_channels = out_channels channels.append(now_channels) if i != len(channel_mults) - 1: self.downs.append(Downsample(now_channels)) channels.append(now_channels) self.mid = nn.ModuleList([ ResidualBlock( now_channels, now_channels, dropout, time_emb_dim=time_emb_dim, num_classes=num_classes, activation=activation, norm=norm, num_groups=num_groups, use_attention=True, ), ResidualBlock( now_channels, now_channels, dropout, time_emb_dim=time_emb_dim, num_classes=num_classes, activation=activation, norm=norm, num_groups=num_groups, use_attention=False, ), ]) for i, mult in reversed(list(enumerate(channel_mults))): out_channels = base_channels * mult for _ in range(num_res_blocks + 1): self.ups.append(ResidualBlock( channels.pop() + now_channels, out_channels, dropout, time_emb_dim=time_emb_dim, num_classes=num_classes, activation=activation, norm=norm, num_groups=num_groups, use_attention=i in attention_resolutions, )) now_channels = out_channels if i != 0: self.ups.append(Upsample(now_channels)) assert len(channels) == 0 self.out_norm = get_norm(norm, base_channels, num_groups) self.out_conv = nn.Conv2d(base_channels, img_channels, 3, padding=1) def forward(self, x, time=None, y=None): ip = self.initial_pad if ip != 0: x = F.pad(x, (ip,) * 4) if self.time_mlp is not None: if time is None: raise ValueError(&quot;time conditioning was specified but tim is not passed&quot;) time_emb = self.time_mlp(time) else: time_emb = None if self.num_classes is not None and y is None: raise ValueError(&quot;class conditioning was specified but y is not passed&quot;) x = self.init_conv(x) skips = [x] for layer in self.downs: x = layer(x, time_emb, y) skips.append(x) for layer in self.mid: x = layer(x, time_emb, y) for layer in self.ups: if isinstance(layer, ResidualBlock): x = torch.cat([x, skips.pop()], dim=1) x = layer(x, time_emb, y) x = self.activation(self.out_norm(x)) x = self.out_conv(x) if self.initial_pad != 0: return x[:, :, ip:-ip, ip:-ip] else: return x 123456789101112131415161718192021222324252627282930313233from unet import *import torch.nn.functional as Fif __name__==&quot;__main__&quot;: activations = &#123; &quot;relu&quot;: F.relu, &quot;mish&quot;: F.mish, &quot;silu&quot;: F.silu, &#125; model = UNet( img_channels=3, base_channels=64, channel_mults=(1, 2, 2, 2), time_emb_dim=512, norm=&#x27;gn&#x27;, dropout=0.1, activation=activations[&#x27;silu&#x27;], attention_resolutions=(1,), num_classes=10, initial_pad=0, ) a = torch.FloatTensor(1,3,32,32) t = torch.randn(1).long() y = torch.randn(1).long() b = model(a,t,y) pass","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Code-åŸºç¡€æ¨¡å‹","slug":"Code-åŸºç¡€æ¨¡å‹","permalink":"http://example.com/tags/Code-%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B/"}]},{"title":"Coding-3DåŒ»å­¦å›¾åƒåˆ†ç±»-åŸºäº3D-Resnet","slug":"coding_medical_network_example","date":"2023-12-26T08:18:48.892Z","updated":"2024-01-23T03:54:18.379Z","comments":true,"path":"2023/12/26/coding_medical_network_example/","link":"","permalink":"http://example.com/2023/12/26/coding_medical_network_example/","excerpt":"","text":"æ‘˜è¦ main.py æ‘˜è¦ è®­ç»ƒä¸€ä¸ª3DåŒ»å­¦å›¾åƒåˆ†ç±»ç¥ç»ç½‘ç»œï¼ˆ3D-Resnetï¼‰ï¼ŒåŒ…æ‹¬ï¼š 1.è‡ªå®šä¹‰dataloadåˆ¶ä½œ 2.ç½‘ç»œå®šä¹‰(3D-Resnet) 3.è®­ç»ƒè¿‡ç¨‹ 4.æµ‹è¯•è¿‡ç¨‹ 5.æ¨¡å‹è¯„ä¼°ï¼ˆå‡†ç¡®ç‡ï¼‰ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225import torchimport torch.nn as nnimport numpy as npfrom torch.utils.data import Datasetimport osclass mydatasets(Dataset): def __init__(self, data,label): self.data = data # åŠ ä¸Šé€šé“æ•° self.label = label def __getitem__(self, index): data = self.data[index] # è·å–é«˜é˜¶FCN label = self.label[index] return data,label def __len__(self): return self.data.shape[0] # è¿”å›æ•°æ®é›†çš„é•¿åº¦class BasicBlock(nn.Module): expansion = 1 def __init__(self, in_channels, out_channels, stride=1): super(BasicBlock, self).__init__() # ç¬¬ä¸€ä¸ªå·ç§¯å±‚ self.conv1 = nn.Conv3d( in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False ) self.bn1 = nn.BatchNorm3d(out_channels) self.relu = nn.ReLU(inplace=True) # ç¬¬äºŒä¸ªå·ç§¯å±‚ self.conv2 = nn.Conv3d( out_channels, out_channels * self.expansion, kernel_size=3, stride=1, padding=1, bias=False, ) self.bn2 = nn.BatchNorm3d(out_channels * self.expansion) # æ®‹å·®è¿æ¥ï¼ˆshortcut connectionï¼‰ self.shortcut = nn.Sequential() if stride != 1 or in_channels != out_channels * self.expansion: self.shortcut = nn.Sequential( nn.Conv3d( in_channels, out_channels * self.expansion, kernel_size=1, stride=stride, bias=False, ), nn.BatchNorm3d(out_channels * self.expansion), ) def forward(self, x): residual = x out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) out += self.shortcut(residual) out = self.relu(out) return outclass ResNet(nn.Module): def __init__(self, block, num_blocks, num_classes=10): super(ResNet, self).__init__() self.in_channels = 64 # ç¬¬ä¸€ä¸ªå·ç§¯å±‚ self.conv1 = nn.Conv3d( 1, 64, kernel_size=3, stride=1, padding=1, bias=False ) self.bn1 = nn.BatchNorm3d(64) self.relu = nn.ReLU(inplace=True) # ResNetçš„å››ä¸ªé˜¶æ®µ self.layer1 = self.make_layer(block, 64, num_blocks[0], stride=1) self.layer2 = self.make_layer(block, 128, num_blocks[1], stride=2) self.layer3 = self.make_layer(block, 256, num_blocks[2], stride=2) self.layer4 = self.make_layer(block, 512, num_blocks[3], stride=2) # å…¨å±€å¹³å‡æ± åŒ–å±‚å’Œå…¨è¿æ¥å±‚ self.avg_pool = nn.AdaptiveAvgPool3d((1, 1, 1)) self.fc = nn.Linear(512 * block.expansion, num_classes) def make_layer(self, block, out_channels, num_blocks, stride): layers = [] layers.append(block(self.in_channels, out_channels, stride)) self.in_channels = out_channels * block.expansion for _ in range(1, num_blocks): layers.append(block(self.in_channels, out_channels)) return nn.Sequential(*layers) def forward(self, x): out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.layer1(out) out = self.layer2(out) out = self.layer3(out) out = self.layer4(out) out = self.avg_pool(out) out = torch.flatten(out, 1) out = self.fc(out) return outdef ResNet18(num_classes=10): return ResNet(BasicBlock, [2, 2, 2, 2], num_classes)def data_load(data_path,batch_size): data_label = np.load(data_path,batch_size) torch.manual_seed(9) random_index = np.random.permutation(data_label[&#x27;data&#x27;].shape[0]) data = torch.from_numpy(data_label[&#x27;data&#x27;][random_index]).float() label= torch.from_numpy(data_label[&#x27;label&#x27;][random_index]).float() train_data = data[:160] train_label = label[:160] test_data = data[160:] test_label = label[160:] train_dataset = mydatasets(train_data,train_label) test_dataset = mydatasets(test_data,test_label) train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True) # åˆ›å»ºè®­ç»ƒæ•°æ®åŠ è½½å™¨ test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=False) # åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨ return train_loader,test_loaderdef train(model, train_loader, criterion, optimizer, device): model.train() # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼ train_loss = 0 for data, label in train_loader: data = data.to(device) data = torch.unsqueeze(data,1) optimizer.zero_grad() # æ¸…é™¤æ¢¯åº¦ output = model(data) # å‰å‘ä¼ æ’­ loss = criterion(output, label.to(device).long()) # è®¡ç®—æŸå¤± loss.backward() # åå‘ä¼ æ’­ï¼Œè®¡ç®—æ¢¯åº¦ optimizer.step() # æ›´æ–°æ¨¡å‹å‚æ•° train_loss += loss.item() * data.size(0) train_loss /= len(train_loader.dataset) # è®¡ç®—å¹³å‡è®­ç»ƒæŸå¤± return train_lossdef validate(model, val_loader, criterion, device): model.eval() # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼ val_loss = 0 correct = 0 #æ­£ç¡®ä¸ªæ•° total = 0 #æ€»æ•° with torch.no_grad(): for data, label in val_loader: data = data.to(device) data = torch.unsqueeze(data,1) output = model(data) # å‰å‘ä¼ æ’­ _, predicted = torch.max(output.data, 1) total += label.size(0) correct += (predicted == label.to(device)).sum().item() loss = criterion(output, label.to(device).long()) # è®¡ç®—æŸå¤± val_loss += loss.item() * data.size(0) accuracy = 100 * correct / total # print(&#x27;Accuracy on the test set: %d %%&#x27; % accuracy) val_loss /= len(val_loader.dataset) # è®¡ç®—å¹³å‡éªŒè¯æŸå¤± return accuracy,val_loss if __name__ == &quot;__main__&quot;: epoch_times = 100 batch_size = 4 device = torch.device(&#x27;cuda&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;) train_loader,test_loader = data_load(&#x27;/home/yeshixin/work/newwork/DDPM-main/data/mri_ad90_cn113_data_label_normal.npz&#x27;,batch_size) model = ResNet18(2) model.to(device) # criterion = nn.MSELoss() criterion = nn.CrossEntropyLoss() optimizer = torch.optim.Adam(model.parameters(),lr=0.001) train_losses = [] val_losses = [] best_val_loss = np.inf best_val_acc = 0 if not os.path.exists(&#x27;ckpt&#x27;): os.mkdir(&#x27;./ckpt&#x27;) # è®­ç»ƒæ¨¡å‹ for epoch in range(epoch_times): train_loss = train(model, train_loader, criterion, optimizer, device) # è®­ç»ƒæ¨¡å‹ val_acc,val_loss = validate(model, test_loader, criterion, device) # éªŒè¯æ¨¡å‹ train_losses.append(train_loss) # ä¿å­˜è®­ç»ƒæŸå¤± val_losses.append(val_loss) # ä¿å­˜éªŒè¯æŸå¤± # å­˜å‚¨æœ€å°æŸå¤±æ¨¡å‹ if val_loss &lt; best_val_loss: best_val_loss = val_loss best_model = model.state_dict() torch.save(best_model, &#x27;ckpt/BestLoss_&#x27;+str(best_val_loss)+&#x27;_model.ckpt&#x27;) # ä¿å­˜æœ€ä½³æ¨¡å‹å‚æ•° print(&quot;best_val_loss: &quot; + str(best_val_loss)) with open(&quot;ckpt/model_loss.txt&quot;, &quot;w&quot;) as f: f.write(str(val_loss)) # å­˜å‚¨æœ€å¤§å‡†ç¡®ç‡æ¨¡å‹ if val_acc &gt; best_val_acc: best_val_acc = val_acc best_model = model.state_dict() torch.save(best_model, &#x27;ckpt/BestAcc_&#x27;+str(best_val_acc)+&#x27;_model.ckpt&#x27;) # ä¿å­˜æœ€ä½³æ¨¡å‹å‚æ•° print(&quot;best_val_acc: &quot; + str(best_val_acc)) with open(&quot;ckpt/model_acc.txt&quot;, &quot;w&quot;) as f: f.write(str(best_val_acc)) print(&#x27;Epoch [&#123;&#125;/&#123;&#125;], Train Loss: &#123;:.4f&#125;, Val Loss: &#123;:.4f&#125;, Val Acc: &#123;:.4f&#125; %&#x27;.format(epoch+1, epoch_times, train_loss, val_loss,val_acc))","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Code-åˆ†ç±»","slug":"Code-åˆ†ç±»","permalink":"http://example.com/tags/Code-%E5%88%86%E7%B1%BB/"}]},{"title":"Coding-CGAN-æ¡ä»¶ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ-åŸºäºé«˜é˜¶FCNæ•°æ®","slug":"coding_GAN_High_Fcn","date":"2023-12-21T16:09:25.314Z","updated":"2024-05-21T12:15:06.554Z","comments":true,"path":"2023/12/22/coding_GAN_High_Fcn/","link":"","permalink":"http://example.com/2023/12/22/coding_GAN_High_Fcn/","excerpt":"","text":"æ‘˜è¦ main.py generate.py æ‘˜è¦ main.pyåŒ…æ‹¬é«˜é˜¶FCNçš„å¤„ç†ï¼Œç”Ÿæˆå¯¹æŠ—ç½‘ç»œçš„è®­ç»ƒ generate.pyä½¿ç”¨ç”Ÿæˆå™¨ç”Ÿæˆæ ·æœ¬ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299import argparseimport osimport numpy as npimport mathimport torchvision.transforms as transformsfrom torchvision.utils import save_imagefrom torch.utils.data import DataLoaderfrom torchvision import datasetsfrom torch.autograd import Variableimport torch.nn as nnimport torch.nn.functional as Fimport torchfrom scipy.io import loadmatfrom torch.utils import data # å¯¼å…¥PyTorchæ•°æ®å·¥å…·æ¨¡å—import randomfrom scipy.stats import pearsonros.makedirs(&quot;train_images&quot;, exist_ok=True)os.makedirs(&quot;test_images&quot;, exist_ok=True)os.makedirs(&quot;save_model&quot;, exist_ok=True)parser = argparse.ArgumentParser()parser.add_argument(&quot;--n_epochs&quot;, type=int, default=200, help=&quot;number of epochs of training&quot;)parser.add_argument(&quot;--batch_size&quot;, type=int, default=4, help=&quot;size of the batches&quot;)parser.add_argument(&quot;--lr&quot;, type=float, default=0.0002, help=&quot;adam: learning rate&quot;)parser.add_argument(&quot;--b1&quot;, type=float, default=0.5, help=&quot;adam: decay of first order momentum of gradient&quot;)parser.add_argument(&quot;--b2&quot;, type=float, default=0.999, help=&quot;adam: decay of first order momentum of gradient&quot;)parser.add_argument(&quot;--n_cpu&quot;, type=int, default=8, help=&quot;number of cpu threads to use during batch generation&quot;)parser.add_argument(&quot;--latent_dim&quot;, type=int, default=100, help=&quot;å™ªå£°çš„ç»´åº¦&quot;)parser.add_argument(&quot;--n_classes&quot;, type=int, default=2, help=&quot;ç±»åˆ«æ•°é‡&quot;)parser.add_argument(&quot;--img_size&quot;, type=int, default=116, help=&quot;åŠŸèƒ½è¿æ¥çŸ©é˜µçš„ç»´åº¦&quot;)parser.add_argument(&quot;--channels&quot;, type=int, default=1, help=&quot;çŸ©é˜µé€šé“&quot;)parser.add_argument(&quot;--sample_interval&quot;, type=int, default=400, help=&quot;interval between image sampling&quot;)opt = parser.parse_args()print(opt)img_shape = (opt.channels, opt.img_size, opt.img_size)cuda = True if torch.cuda.is_available() else Falseclass my_dataset(data.Dataset): def __init__(self, Hig_X,label_): self.Hig_X = np.expand_dims(Hig_X,1) # åŠ ä¸Šé€šé“æ•° self.label = label_ def __getitem__(self, index): X = self.Hig_X[index] # è·å–é«˜é˜¶FCN label = self.label[index] return X,label def __len__(self): return self.Hig_X.shape[0] # è¿”å›æ•°æ®é›†çš„é•¿åº¦def calculate_similarity(matrix1, matrix2): correlation, _ = pearsonr(matrix1.flatten(), matrix2.flatten()) return correlation# ç²¾åº¦åˆ¤æ–­ï¼Œå³è®¡ç®—ä¸¤ä¸ªçŸ©é˜µçš„ç›¸å…³ç³»æ•°def calculate_accuracy(generator, dataloader, device, val_subjects=None): generator.eval() correct_predictions = 0 for batch_idx, (batch_matrix) in enumerate(dataloader): matrix = batch_matrix.to(device) size = matrix.size(0) random_noise = torch.randn(size, 100).to(device=device) with torch.no_grad(): gen_matrix = generator(random_noise) for i in range(size): similarity = calculate_similarity(gen_matrix[i].cpu().numpy(), matrix[i].cpu().numpy()) # é˜ˆå€¼æ˜¯ä¸€ä¸ªç»éªŒå€¼ï¼Œæ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ if similarity &gt; 0.6 and (val_subjects is None or batch_idx in val_subjects): correct_predictions += 1 accuracy = correct_predictions / len(dataloader.dataset) return accuracyclass Generator(nn.Module): def __init__(self): super(Generator, self).__init__() self.label_emb = nn.Embedding(opt.n_classes, opt.n_classes) def block(in_feat, out_feat, normalize=True): layers = [nn.Linear(in_feat, out_feat)] if normalize: layers.append(nn.BatchNorm1d(out_feat, 0.8)) layers.append(nn.LeakyReLU(0.2, inplace=True)) return layers self.model = nn.Sequential( *block(opt.latent_dim + opt.n_classes, 128, normalize=False), *block(128, 256), *block(256, 512), *block(512, 1024), nn.Linear(1024, int(np.prod(img_shape))), nn.Tanh() ) def forward(self, noise, labels): # Concatenate label embedding and image to produce input gen_input = torch.cat((self.label_emb(labels), noise), -1) img = self.model(gen_input) img = img.view(img.size(0), *img_shape) return imgclass Discriminator(nn.Module): def __init__(self): super(Discriminator, self).__init__() self.label_embedding = nn.Embedding(opt.n_classes, opt.n_classes) self.model = nn.Sequential( nn.Linear(opt.n_classes + int(np.prod(img_shape)), 512), nn.LeakyReLU(0.2, inplace=True), nn.Linear(512, 512), nn.Dropout(0.4), nn.LeakyReLU(0.2, inplace=True), nn.Linear(512, 512), nn.Dropout(0.4), nn.LeakyReLU(0.2, inplace=True), nn.Linear(512, 1), ) def forward(self, img, labels): # Concatenate label embedding and image to produce input d_in = torch.cat((img.view(img.size(0), -1), self.label_embedding(labels)), -1) validity = self.model(d_in) return validity# Loss functionsadversarial_loss = torch.nn.MSELoss()# Initialize generator and discriminatorgenerator = Generator()discriminator = Discriminator()if cuda: generator.cuda() discriminator.cuda() adversarial_loss.cuda()# Configure data loader # åŸå§‹æ–‡ä»¶è·¯å¾„fMRI_file_path = &#x27;.//ROISignals_insomnia_aal116.mat&#x27;# åŠ è½½æ•°æ®fMRI_data = loadmat(fMRI_file_path)[&#x27;ROISignals&#x27;]# æ­£å¸¸äººä¸º1,ç—…äººä¸º0fMRI_label = torch.cat((torch.ones(32,1),torch.zeros(30,1)),dim=0).squeeze()# ä½é˜¶çŸ©é˜µè®¡ç®—Low_X_ = []for i in range(fMRI_data.shape[2]): temp = np.corrcoef(fMRI_data[:,:,i],rowvar=False) Low_X_.append(temp)Low_X = np.array(Low_X_) #(62,116,116)# é«˜é˜¶çŸ©é˜µè®¡ç®—Hig_X_ = []for i in range(Low_X.shape[0]): temp = np.corrcoef(Low_X[:,:,i],rowvar=False) Hig_X_.append(temp)Hig_X = np.array(Hig_X_) #(62,116,116)random_index = np.random.permutation(len(fMRI_label))Hig_X = Hig_X[random_index]fMRI_label = fMRI_label[random_index]train_data = Hig_X[:50]train_label = fMRI_label[:50]test_data = Hig_X[50:]test_label = fMRI_label[:50]train_dataset = my_dataset(train_data,train_label)test_dataset = my_dataset(test_data,test_label)train_loader = data.DataLoader(train_dataset,batch_size=opt.batch_size,shuffle=True)test_loader = data.DataLoader(test_dataset,batch_size=opt.batch_size,shuffle=False)# Optimizersoptimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensorLongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor# ----------# Training# ----------for epoch in range(opt.n_epochs): for i, (imgs, labels) in enumerate(train_loader): batch_size = imgs.shape[0] # Adversarial ground truths valid = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False) fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False) # Configure input real_imgs = Variable(imgs.type(FloatTensor)) labels = Variable(labels.type(LongTensor)) # ----------------- # Train Generator # ----------------- optimizer_G.zero_grad() # Sample noise and labels as generator input z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, opt.latent_dim)))) gen_labels = Variable(LongTensor(np.random.randint(0, opt.n_classes, batch_size))) # Generate a batch of images gen_imgs = generator(z, gen_labels) # Loss measures generator&#x27;s ability to fool the discriminator validity = discriminator(gen_imgs, gen_labels) g_loss = adversarial_loss(validity, valid) g_loss.backward() optimizer_G.step() # --------------------- # Train Discriminator # --------------------- optimizer_D.zero_grad() # Loss for real images validity_real = discriminator(real_imgs, labels) d_real_loss = adversarial_loss(validity_real, valid) # Loss for fake images validity_fake = discriminator(gen_imgs.detach(), gen_labels) d_fake_loss = adversarial_loss(validity_fake, fake) # Total discriminator loss d_loss = (d_real_loss + d_fake_loss) / 2 d_loss.backward() optimizer_D.step() print( &quot;[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]&quot; % (epoch, opt.n_epochs, i, len(train_loader), d_loss.item(), g_loss.item()) ) batches_done = epoch * len(train_loader) + i # å­˜å‚¨è®­ç»ƒè¿‡ç¨‹çš„ç»“æœ if batches_done % opt.sample_interval == 0: #ä¸€ä¸ªepochä¸­æ¯éš”å¤šå°‘é—´éš”ä¿å­˜ä¸€æ¬¡ gen_imgs_normalized = (gen_imgs - gen_imgs.min()) / (gen_imgs.max() - gen_imgs.min()) save_image(gen_imgs_normalized.data[:25], &quot;train_images/%d.png&quot; % batches_done, nrow=5, normalize=False) # æµ‹è¯•è¿‡ç¨‹ with torch.no_grad(): best_acc = 0 generator.eval() correct_predictions = 0 for imgs, label in test_loader: z = Variable(FloatTensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim)))) gen_labels = Variable(LongTensor(np.random.randint(0, opt.n_classes, imgs.shape[0]))) gen_imgs = generator(z, gen_labels) for i in range(imgs.shape[0]): similarity = calculate_similarity(gen_imgs[i].cpu().numpy(), imgs[i].cpu().numpy()) # é˜ˆå€¼æ˜¯ä¸€ä¸ªç»éªŒå€¼ï¼Œæ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ if similarity &gt; 0.6: correct_predictions += 1 accuracy = correct_predictions / len(test_loader.dataset) # ä¿å­˜epochä¸­ç²¾åº¦æœ€å¥½çš„æ¨¡å‹ if best_acc &lt; accuracy: best_acc = accuracy #ä¿å­˜æ¨¡å‹ torch.save(generator.state_dict(), &quot;save_model/best_model.pth&quot;) print(&#x27;epoch:&#x27;+str(epoch)+&#x27; æµ‹è¯•é›†acc:&#x27;+str(accuracy)+&quot; best_acc:&quot;+str(best_acc)) gen_imgs_normalized = (gen_imgs - gen_imgs.min()) / (gen_imgs.max() - gen_imgs.min()) save_image(gen_imgs_normalized.data[:25], &quot;test_images/acc_&#123;&#125;epoch_&#123;&#125;.png&quot;.format(accuracy,epoch), nrow=5, normalize=False) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081import argparseimport torch.nn as nnimport torch.nn.functional as Fimport torchimport numpy as npfrom torch.autograd import Variablefrom torchvision.utils import save_imageimport osparser = argparse.ArgumentParser()parser.add_argument(&quot;--n_epochs&quot;, type=int, default=200, help=&quot;number of epochs of training&quot;)parser.add_argument(&quot;--batch_size&quot;, type=int, default=4, help=&quot;size of the batches&quot;)parser.add_argument(&quot;--lr&quot;, type=float, default=0.0002, help=&quot;adam: learning rate&quot;)parser.add_argument(&quot;--b1&quot;, type=float, default=0.5, help=&quot;adam: decay of first order momentum of gradient&quot;)parser.add_argument(&quot;--b2&quot;, type=float, default=0.999, help=&quot;adam: decay of first order momentum of gradient&quot;)parser.add_argument(&quot;--n_cpu&quot;, type=int, default=8, help=&quot;number of cpu threads to use during batch generation&quot;)parser.add_argument(&quot;--latent_dim&quot;, type=int, default=100, help=&quot;å™ªå£°çš„ç»´åº¦&quot;)parser.add_argument(&quot;--n_classes&quot;, type=int, default=2, help=&quot;ç±»åˆ«æ•°é‡&quot;)parser.add_argument(&quot;--img_size&quot;, type=int, default=116, help=&quot;åŠŸèƒ½è¿æ¥çŸ©é˜µçš„ç»´åº¦&quot;)parser.add_argument(&quot;--channels&quot;, type=int, default=1, help=&quot;çŸ©é˜µé€šé“&quot;)parser.add_argument(&quot;--sample_interval&quot;, type=int, default=400, help=&quot;interval between image sampling&quot;)opt = parser.parse_args()print(opt)img_shape = (opt.channels, opt.img_size, opt.img_size)cuda = True if torch.cuda.is_available() else Falseclass Generator(nn.Module): def __init__(self): super(Generator, self).__init__() self.label_emb = nn.Embedding(opt.n_classes, opt.n_classes) def block(in_feat, out_feat, normalize=True): layers = [nn.Linear(in_feat, out_feat)] if normalize: layers.append(nn.BatchNorm1d(out_feat, 0.8)) layers.append(nn.LeakyReLU(0.2, inplace=True)) return layers self.model = nn.Sequential( *block(opt.latent_dim + opt.n_classes, 128, normalize=False), *block(128, 256), *block(256, 512), *block(512, 1024), nn.Linear(1024, int(np.prod(img_shape))), nn.Tanh() ) def forward(self, noise, labels): # Concatenate label embedding and image to produce input gen_input = torch.cat((self.label_emb(labels), noise), -1) img = self.model(gen_input) img = img.view(img.size(0), *img_shape) return img FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensorLongTensor = torch.cuda.LongTensor if cuda else torch.LongTensoros.makedirs(&quot;Generated_samples&quot;, exist_ok=True)generator = Generator()generator.cuda()# æŒ‡å®šä¿å­˜çš„æ¨¡å‹æ–‡ä»¶è·¯å¾„model_path = &#x27;save_model\\\\best_model.pth&#x27;# åŠ è½½ä¿å­˜çš„æ¨¡å‹çŠ¶æ€å­—å…¸generator.load_state_dict(torch.load(model_path))# å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼generator.eval()# è®¾ç½®ç”Ÿæˆæ ·æœ¬æ•°batch_size = 25z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, opt.latent_dim))))gen_labels = Variable(LongTensor(np.random.randint(0, opt.n_classes, batch_size)))gen_imgs = generator(z , gen_labels)# æ ‡å‡†åŒ–gen_imgs_normalized = (gen_imgs - gen_imgs.min()) / (gen_imgs.max() - gen_imgs.min()) # å­˜å‚¨æ ·æœ¬å’Œæ ‡ç­¾np.savez(&#x27;Generated_samples/Generated_samples.npz&#x27;, array1=gen_imgs.detach().cpu(), array2=gen_labels.detach().cpu())#å­˜å‚¨å›¾ç‰‡save_image(gen_imgs_normalized.data[:25], &quot;Generated_samples/acc_epoch_.png&quot;, nrow=25, normalize=False)","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Code-ç”Ÿæˆ","slug":"Code-ç”Ÿæˆ","permalink":"http://example.com/tags/Code-%E7%94%9F%E6%88%90/"}]},{"title":"PaperReading-åŸºäºå¯¹æŠ—è®­ç»ƒå’Œä¸ç¡®å®šæ€§æ ¡æ­£çš„ä¸€æ¬¡æ€§åˆ›ä¼¤è„‘åˆ†å‰²","slug":"paper_åŸºäºå¯¹æŠ—è®­ç»ƒå’Œä¸ç¡®å®šæ€§æ ¡æ­£çš„ä¸€æ¬¡æ€§åˆ›ä¼¤è„‘åˆ†å‰²","date":"2023-10-28T10:05:44.012Z","updated":"2024-05-21T12:18:54.118Z","comments":true,"path":"2023/10/28/paper_åŸºäºå¯¹æŠ—è®­ç»ƒå’Œä¸ç¡®å®šæ€§æ ¡æ­£çš„ä¸€æ¬¡æ€§åˆ›ä¼¤è„‘åˆ†å‰²/","link":"","permalink":"http://example.com/2023/10/28/paper_%E5%9F%BA%E4%BA%8E%E5%AF%B9%E6%8A%97%E8%AE%AD%E7%BB%83%E5%92%8C%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E6%A0%A1%E6%AD%A3%E7%9A%84%E4%B8%80%E6%AC%A1%E6%80%A7%E5%88%9B%E4%BC%A4%E8%84%91%E5%88%86%E5%89%B2/","excerpt":"","text":"One-Shot Traumatic Brain Segmentation with Adversarial Training and Uncertainty Rectification 1.é—®é¢˜æ€»ç»“ åŸºäºå­¦ä¹ å˜æ¢çš„å•æ¬¡åˆ†å‰²æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜:(1)å¢å¼ºæ ·æœ¬çš„å¤šæ ·æ€§å—é™ã€‚(2)å­¦ä¹ å˜æ¢å¼•å…¥äº†æ½œåœ¨çš„é”™è¯¯æ ‡ç­¾ 2.è§£å†³æ–¹æ³• (1)é€šè¿‡å¢å¼ºæ ·æœ¬çš„å¯¹æŠ—æ€§åˆ†å¸ƒæ¥æé«˜å¢å¼ºæ•°æ®çš„å¤šæ ·æ€§å’Œåˆ†å‰²çš„é²æ£’æ€§ã€‚(2)æ ¹æ®åˆ†å‰²è¿‡ç¨‹ä¸­çš„ä¸ç¡®å®šæ€§ï¼Œå¯¹å­¦ä¹ å˜æ¢å¸¦æ¥çš„æ½œåœ¨æ ‡ç­¾è¯¯å·®è¿›è¡Œæ ¡æ­£ã€‚ 3.æ€»ç»“ åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„ä¸€æ¬¡æ€§åˆ†å‰²æ–¹æ³•ï¼Œç”¨äºä¸¥é‡åˆ›ä¼¤æ€§è„‘åˆ†å‰²ï¼Œè¿™æ˜¯ä¸€ç§å›°éš¾çš„ä¸´åºŠåœºæ™¯ï¼Œå¯ç”¨çš„æ³¨é‡Šæ•°æ®æœ‰é™ã€‚æˆ‘ä»¬çš„æ–¹æ³•è§£å†³äº†sTBIè„‘åˆ†å‰²ä¸­çš„å…³é”®é—®é¢˜ï¼Œå³éœ€è¦å¤šæ ·åŒ–çš„è®­ç»ƒæ•°æ®å’Œå‡å°‘ç”±å¤–è§‚å˜æ¢å¼•å…¥çš„æ½œåœ¨æ ‡ç­¾é”™è¯¯ã€‚å¯¹æŠ—è®­ç»ƒçš„å¼•å…¥å¢å¼ºäº†æ•°æ®çš„å¤šæ ·æ€§å’Œåˆ†å‰²çš„é²æ£’æ€§ï¼ŒåŒæ—¶è®¾è®¡äº†ä¸ç¡®å®šæ€§æ ¡æ­£æ¥è¡¥å¿æ½œåœ¨çš„æ ‡ç­¾é”™è¯¯ã€‚ åœ¨sTBIè„‘ä¸Šçš„å®éªŒç»“æœè¯æ˜äº†æˆ‘ä»¬æå‡ºçš„æ–¹æ³•çš„æœ‰æ•ˆæ€§åŠå…¶ç›¸å¯¹äºæœ€å…ˆè¿›çš„æ›¿ä»£æ–¹æ³•çš„ä¼˜åŠ¿ï¼Œçªå‡ºäº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨å®ç°æ›´å‡†ç¡®çš„ä¸¥é‡åˆ›ä¼¤è„‘åˆ†å‰²æ–¹é¢çš„æ½œåŠ›ï¼Œè¿™å¯èƒ½æœ‰åŠ©äºä¸´åºŠç®¡é“ã€‚","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Paper-åŒ»å­¦å½±åƒ","slug":"Paper-åŒ»å­¦å½±åƒ","permalink":"http://example.com/tags/Paper-%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F/"}]},{"title":"PaperReading-ä½¿ç”¨å­¦ä¹ å˜æ¢çš„æ•°æ®å¢å¼ºï¼Œç”¨äºä¸€æ¬¡æ€§åŒ»å­¦å›¾åƒåˆ†å‰²","slug":"paper_ä½¿ç”¨å­¦ä¹ å˜æ¢çš„æ•°æ®å¢å¼º_ç”¨äºä¸€æ¬¡æ€§åŒ»å­¦å›¾åƒåˆ†å‰²","date":"2023-10-28T10:05:34.560Z","updated":"2024-05-21T12:19:32.013Z","comments":true,"path":"2023/10/28/paper_ä½¿ç”¨å­¦ä¹ å˜æ¢çš„æ•°æ®å¢å¼º_ç”¨äºä¸€æ¬¡æ€§åŒ»å­¦å›¾åƒåˆ†å‰²/","link":"","permalink":"http://example.com/2023/10/28/paper_%E4%BD%BF%E7%94%A8%E5%AD%A6%E4%B9%A0%E5%8F%98%E6%8D%A2%E7%9A%84%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA_%E7%94%A8%E4%BA%8E%E4%B8%80%E6%AC%A1%E6%80%A7%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/","excerpt":"","text":"Data augmentation using learned transformations for one-shot medical image segmentation 1.é—®é¢˜æ€»ç»“ å›¾åƒåˆ†å‰²æ˜¯åŒ»å­¦åº”ç”¨ä¸­çš„é‡è¦ä»»åŠ¡ã€‚åŸºäºå·ç§¯ç½‘ç»œçš„æ–¹æ³•å·²ç»å®ç°äº†éå¸¸å¥½çš„æ•ˆæœã€‚ä½†æ˜¯å®ƒä»¬é€šå¸¸ä¾èµ–äºå¤§é‡æ ‡è®°çš„æ•°æ®é›†ã€‚æ ‡è®°åŒ»å­¦å›¾åƒå¾€å¾€éœ€è¦å¤§é‡çš„ä¸“ä¸šçŸ¥è¯†å’Œæ—¶é—´ï¼Œå¹¶ä¸”ç”¨äºæ•°æ®å¢å¼ºçš„å…¸å‹æ‰‹åŠ¨è°ƒæ•´æ–¹æ³•æ— æ³•æ•è·æ­¤ç±»å›¾åƒä¸­å¤æ‚å˜åŒ–ã€‚ 2.è§£å†³æ–¹æ³• é€šè¿‡å­¦ä¹ åˆæˆå¤šæ ·çš„ç°å®çš„æ ‡ç­¾å®ä¾‹æ¥è§£å†³æœ‰é™çš„æ ‡ç­¾æ•°æ®é—®é¢˜ã€‚æˆ‘ä»¬çš„æ•°æ®å¢å¼ºæ–°æ–¹æ³•åˆ©ç”¨äº†æ²¡æœ‰æ ‡ç­¾çš„å›¾åƒã€‚ä½¿ç”¨åŸºäºå­¦ä¹ çš„é…å‡†æ–¹æ³•ï¼Œå¯¹æ•°æ®é›†ä¸­çš„å›¾åƒä¹‹é—´çš„ç©ºé—´å’Œå¤–è§‚å˜æ¢é›†è¿›è¡Œå»ºæ¨¡ã€‚è¿™äº›æ¨¡å‹æ•è·äº†æœªæ ‡è®°å›¾åƒä¹‹é—´çš„è§£å‰–å’Œå›¾åƒå¤šæ ·æ€§ã€‚æˆ‘ä»¬åˆæˆæ–°çš„å®ä¾‹é€šè¿‡é‡‡æ ·å˜æ¢å¹¶æŠŠä»–ä»¬åº”ç”¨åˆ°å•ä¸ªæœ‰æ ‡ç­¾çš„å®ä¾‹ä¸Šã€‚ 3.æ€»ç»“ æå‡ºäº†ä¸€ä¸ªåŸºäºå­¦ä¹ çš„æ•°æ®å¢å¼ºæ–¹æ³•ï¼Œå¹¶ä¸”åœ¨ä¸€æ¬¡åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­è¿›è¡Œäº†æ¼”ç¤ºã€‚ æˆ‘ä»¬ä»ä¸€ä¸ªå¸¦æ ‡ç­¾çš„å›¾åƒå’Œä¸€äº›æœªå¸¦æ ‡ç­¾çš„å›¾åƒå¼€å§‹ã€‚ä½¿ç”¨åŸºäºå­¦ä¹ çš„é…å‡†æ–¹æ³•ï¼Œæˆ‘ä»¬åœ¨å¸¦æ ‡ç­¾å’Œæœªå¸¦æ ‡ç­¾çš„å›¾åƒä¹‹é—´å»ºæ¨¡ç©ºé—´å’Œå¤–è§‚è½¬æ¢é›†ã€‚è¿™äº›è½¬æ¢å¯ä»¥æ•è·è¯¸å¦‚éçº¿æ€§å˜å½¢å’Œå›¾åƒå¼ºåº¦çš„å˜æ¢ã€‚æˆ‘ä»¬åˆæˆæ–°çš„æ ‡ç­¾é€šè¿‡é‡‡æ ·è½¬æ¢å¹¶ä¸”å¹¶å°†å…¶åº”ç”¨äºæ ‡ç­¾ï¼Œäº§ç”Ÿå„ç§é€¼çœŸçš„æ–°å›¾åƒã€‚","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Paper-åŒ»å­¦å½±åƒ","slug":"Paper-åŒ»å­¦å½±åƒ","permalink":"http://example.com/tags/Paper-%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F/"}]},{"title":"C++åŸºç¡€çŸ¥è¯†","slug":"cpp_tips","date":"2023-10-04T03:08:19.430Z","updated":"2024-05-22T02:28:06.759Z","comments":true,"path":"2023/10/04/cpp_tips/","link":"","permalink":"http://example.com/2023/10/04/cpp_tips/","excerpt":"","text":"è™šææ„å‡½æ•° åœ¨ C++ ä¸­ï¼Œè™šææ„å‡½æ•°ï¼ˆvirtual destructorï¼‰æ˜¯åœ¨åŸºç±»ä¸­å£°æ˜å¹¶ä½¿ç”¨ virtual å…³é”®å­—ä¿®é¥°çš„ææ„å‡½æ•°ã€‚ è™šææ„å‡½æ•°åœ¨å¤„ç†åŸºç±»æŒ‡é’ˆæŒ‡å‘æ´¾ç”Ÿç±»å¯¹è±¡æ—¶éå¸¸æœ‰ç”¨ã€‚å½“ä½¿ç”¨åŸºç±»æŒ‡é’ˆæ¥åˆ é™¤ä¸€ä¸ªæŒ‡å‘æ´¾ç”Ÿç±»å¯¹è±¡çš„å®ä¾‹æ—¶ï¼Œå¦‚æœåŸºç±»çš„ææ„å‡½æ•°ä¸æ˜¯è™šæ‹Ÿçš„ï¼Œåªä¼šè°ƒç”¨åŸºç±»çš„ææ„å‡½æ•°ï¼Œè€Œä¸ä¼šè°ƒç”¨æ´¾ç”Ÿç±»çš„ææ„å‡½æ•°ã€‚è¿™å¯èƒ½å¯¼è‡´æ´¾ç”Ÿç±»å¯¹è±¡ä¸­çš„èµ„æºæ— æ³•æ­£ç¡®é‡Šæ”¾ï¼Œé€ æˆå†…å­˜æ³„æ¼ã€‚ é€šè¿‡å°†åŸºç±»çš„ææ„å‡½æ•°å£°æ˜ä¸ºè™šæ‹Ÿçš„ï¼Œå¯ä»¥ç¡®ä¿åœ¨åˆ é™¤åŸºç±»æŒ‡é’ˆæ—¶æ­£ç¡®è°ƒç”¨æ´¾ç”Ÿç±»çš„ææ„å‡½æ•°ï¼Œä»è€Œæ­£ç¡®é‡Šæ”¾æ´¾ç”Ÿç±»å¯¹è±¡çš„èµ„æºã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªä½¿ç”¨è™šææ„å‡½æ•°çš„ç¤ºä¾‹ï¼š 1234567891011121314151617181920212223#include&lt;iostream&gt;#include&lt;string&gt;using namespace std;class base&#123;public: virtual ~base()&#123; cout&lt;&lt;&quot;base&#x27;s ~&quot;; &#125;;&#125;;class child:public base&#123; public: ~child()&#123; cout&lt;&lt;&quot;child&#x27;s~&quot;; &#125;&#125;;int main()&#123; base* p = new child(); delete p; return 0;&#125; forå¾ªç¯éå†è¿­ä»£å™¨ 123456789101112#include&lt;iostream&gt;#include&lt;list&gt;int main()&#123; std::list&lt;int&gt; a; a.push_back(1); a.push_back(2); a.push_back(3); for(auto &amp;i:a )&#123; std::cout&lt;&lt;i&lt;&lt;std::endl; &#125; return 0;&#125; cmakeåˆçº§ æ–‡ä»¶å¤¹è®¾ç½® â”œâ”€â”€ CMakeLists.txt â”œâ”€â”€ sylar â”‚ â”œâ”€â”€ CMakeLists.txt â”‚ â”œâ”€â”€ main.cpp ç¬¬ä¸€ä¸ªCMakeLists.txt 1234567cmake_minimum_required(VERSION 3.12)project(sylar)set(CMAKE_CXX_STANDARD 14)add_subdirectory(sylar)# add_executable(sylar sylar/main.cpp) ç¬¬äºŒä¸ªCMakeLists.txt 1add_executable(sylar main.cpp) å¯å˜å‚æ•°åˆ—è¡¨ 1234567891011121314151617181920#include &lt;iostream&gt;#include &lt;cstdarg&gt;// å¯å˜å‚æ•°åˆ—è¡¨çš„å‡½æ•°å®šä¹‰void print(int count, ...) &#123; va_list args; va_start(args, count); for (int i = 0; i &lt; count; ++i) &#123; int value = va_arg(args, int); std::cout &lt;&lt; value &lt;&lt; std::endl; &#125; va_end(args);&#125;int main() &#123; print(6,1,7,9,2,3,4); return 0;&#125; æ“ä½œç¬¦é‡è½½ 12345678910111213141516171819#include &lt;iostream&gt;// è‡ªå®šä¹‰ç±» MyClassclass MyClass &#123;public: int data; MyClass(int value) : data(value) &#123;&#125; friend std::ostream&amp; operator&lt;&lt;(std::ostream&amp; os, const MyClass&amp; obj) &#123; os &lt;&lt; &quot;MyClass: &quot; &lt;&lt; obj.data; return os; &#125;&#125;;int main() &#123; MyClass obj(42); std::cout &lt;&lt; obj &lt;&lt; std::endl; return 0;&#125; å•ä¾‹æ¨¡å¼ 123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;iostream&gt;class Singleton &#123;private: // ç§æœ‰çš„é™æ€æˆå‘˜å˜é‡ï¼Œç”¨äºå­˜å‚¨å•ä¾‹å®ä¾‹ static Singleton* instance; // ç§æœ‰çš„æ„é€ å‡½æ•°ï¼Œé˜²æ­¢å¤–éƒ¨ç›´æ¥å®ä¾‹åŒ–å¯¹è±¡ Singleton() &#123;&#125;public: // é™æ€æˆå‘˜å‡½æ•°ï¼Œç”¨äºè·å–å•ä¾‹å¯¹è±¡çš„å”¯ä¸€å®ä¾‹ static Singleton* getInstance() &#123; if (instance == nullptr) &#123; instance = new Singleton(); &#125; return instance; &#125; // ç¤ºä¾‹æˆå‘˜å‡½æ•° void showMessage() &#123; std::cout &lt;&lt; &quot;Hello from Singleton!&quot; &lt;&lt; std::endl; &#125;&#125;;// åˆå§‹åŒ–é™æ€æˆå‘˜å˜é‡Singleton* Singleton::instance = nullptr;int main() &#123; Singleton* instance1 = Singleton::getInstance(); Singleton* instance2 = Singleton::getInstance(); // instance1å’Œinstance2æŒ‡å‘ç›¸åŒçš„å¯¹è±¡ instance1-&gt;showMessage(); // è¾“å‡º: Hello from Singleton! instance2-&gt;showMessage(); // è¾“å‡º: Hello from Singleton! // æ¸…ç†å•ä¾‹å¯¹è±¡ delete instance1; instance1 = nullptr; return 0;&#125; æ¨¡æ¿ç±» 1234567891011121314151617181920212223#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;boost/lexical_cast.hpp&gt;template &lt;class F, class T&gt;class LexicalCast &#123;public: T operator()(const F&amp; v) &#123; return boost::lexical_cast&lt;T&gt;(v); //å°†Tè½¬æ¢ä¸ºint &#125;&#125;;int main() &#123; LexicalCast&lt;std::string, int&gt; stringToInt; int num = stringToInt(&quot;12345&quot;); std::cout &lt;&lt; &quot;Converted integer: &quot; &lt;&lt; num &lt;&lt; std::endl; LexicalCast&lt;double, std::string&gt; doubleToString; std::string str = doubleToString(3.14159); std::cout &lt;&lt; &quot;Converted string: &quot; &lt;&lt; str &lt;&lt; std::endl; return 0;&#125; static å…³é”®è¯ åœ¨ C++ å¤´æ–‡ä»¶ï¼ˆ.hï¼‰ä¸­å®šä¹‰çš„é™æ€å‡½æ•°ï¼Œåœ¨å¯¹åº”çš„å®ç°æ–‡ä»¶ï¼ˆ.cppï¼‰ä¸­ä¸éœ€è¦å†ä½¿ç”¨ static å…³é”®è¯ä¿®é¥°ã€‚ å½“åœ¨å¤´æ–‡ä»¶ä¸­å£°æ˜é™æ€å‡½æ•°æ—¶ï¼Œä½¿ç”¨ static å…³é”®è¯æ˜¯ä¸ºäº†å°†å‡½æ•°çš„ä½œç”¨åŸŸé™åˆ¶åœ¨å½“å‰æ–‡ä»¶ä¸­ï¼Œé¿å…ä¸å…¶ä»–æ–‡ä»¶ä¸­åŒåçš„å‡½æ•°äº§ç”Ÿå†²çªã€‚è¿™æ ·åšæ˜¯å› ä¸ºå¤´æ–‡ä»¶é€šå¸¸ä¼šè¢«å¤šä¸ªæºæ–‡ä»¶åŒ…å«ï¼Œå¦‚æœåœ¨å¤´æ–‡ä»¶ä¸­ä½¿ç”¨ static ä¿®é¥°ç¬¦ï¼Œæ¯ä¸ªåŒ…å«è¯¥å¤´æ–‡ä»¶çš„æºæ–‡ä»¶éƒ½ä¼šæœ‰ä¸€ä¸ªç‹¬ç«‹çš„é™æ€å‡½æ•°å‰¯æœ¬ï¼Œå¯èƒ½å¯¼è‡´é“¾æ¥é”™è¯¯ã€‚ è€Œåœ¨å®ç°æ–‡ä»¶ä¸­ï¼Œå·²ç»å¤„äºå•ä¸ªæ–‡ä»¶çš„ä½œç”¨åŸŸä¸­ï¼Œä¸éœ€è¦å†æ¬¡ä½¿ç”¨ static å…³é”®è¯æ¥é™åˆ¶å‡½æ•°çš„ä½œç”¨åŸŸã€‚å®ç°æ–‡ä»¶ä¸­çš„é™æ€å‡½æ•°çš„å®šä¹‰åªéœ€è¦ä¸å¤´æ–‡ä»¶ä¸­çš„å‡½æ•°å£°æ˜ç›¸åŒ¹é…å³å¯ã€‚ å› æ­¤ï¼Œå¤´æ–‡ä»¶ä¸­çš„é™æ€å‡½æ•°å£°æ˜ä¸éœ€è¦å†ä½¿ç”¨ static å…³é”®è¯ä¿®é¥°ï¼Œè€Œåœ¨å¯¹åº”çš„å®ç°æ–‡ä»¶ä¸­ï¼Œåªéœ€è¦æä¾›é™æ€å‡½æ•°çš„å®šä¹‰å³å¯ã€‚è¿™æ ·å¯ä»¥ä¿æŒå‡½æ•°åœ¨æ•´ä¸ªç¨‹åºä¸­çš„å”¯ä¸€æ€§ï¼Œå¹¶æ­£ç¡®åœ°ä¸å…¶ä»–æ–‡ä»¶ä¸­çš„ä»£ç è¿›è¡Œé“¾æ¥ã€‚ åœ¨ C++ ä¸­ï¼Œ# æ˜¯ä¸€ç§é¢„å¤„ç†æ“ä½œç¬¦ï¼Œç§°ä¸ºå­—ç¬¦ä¸²åŒ–æ“ä½œç¬¦ï¼ˆstringizing operatorï¼‰ã€‚å®ƒç”¨äºå°†å®å‚æ•°è½¬æ¢ä¸ºå­—ç¬¦ä¸²å­—é¢å€¼ã€‚","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"ç¼–ç¨‹åŸºç¡€çŸ¥è¯†","slug":"ç¼–ç¨‹åŸºç¡€çŸ¥è¯†","permalink":"http://example.com/tags/%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}]},{"title":"Everything","slug":"knowledge_daily_study","date":"2023-09-30T15:34:12.030Z","updated":"2024-06-17T10:46:37.455Z","comments":true,"path":"2023/09/30/knowledge_daily_study/","link":"","permalink":"http://example.com/2023/09/30/knowledge_daily_study/","excerpt":"","text":"linuxé…ç½®å…å¯†ç™»å½• screenå‘½ä»¤ ssh: connect to host github.com port 22: Connection refused nignxæ­£å‘ä»£ç†é…ç½® code-serveré”™è¯¯è§£å†³ ä¸€äº›windowsæŒ‡ä»¤ å›¾å·ç§¯ç¥ç»ç½‘ç»œåŸºç¡€ çœŸç† é…¸è‘¡è„å¿ƒç† å¥½ååˆ¶åº¦ ###vscode pythonè°ƒè¯•çš„launch.jsoné…ç½®æ–‡ä»¶ 1234567891011121314151617181920212223242526&#123; &quot;version&quot;: &quot;0.2.0&quot;, &quot;configurations&quot;: [ &#123; &quot;name&quot;: &quot;Python: Run Image Detection Demo&quot;, &quot;type&quot;: &quot;debugpy&quot;, &quot;request&quot;: &quot;launch&quot;, &quot;program&quot;: &quot;$&#123;workspaceFolder&#125;/demo/image_demo.py&quot;, &quot;console&quot;: &quot;integratedTerminal&quot;, &quot;args&quot;: [ &quot;demo/demo.jpg&quot;, &quot;configs/mask_rcnn/mask-rcnn_r101_fpn_1x_coco.py&quot;, &quot;--weights&quot;, &quot;mymodel/mask_rcnn_r101_fpn_1x_coco_20200204-1efe0ed5.pth&quot;, &quot;--texts&quot;, &quot;bench&quot;, &quot;--device&quot;, &quot;cuda:0&quot; ], &quot;env&quot;: &#123; // å¦‚æœæœ‰éœ€è¦ï¼Œå¯ä»¥åœ¨è¿™é‡Œæ·»åŠ é¢å¤–çš„ç¯å¢ƒå˜é‡ &#125; &#125; ]&#125; linuxé…ç½®å…å¯†ç™»å½• æœ¬æœºè¿è¡Œ 1ssh-keygen -t rsa å°†æœ¬æœº.SSHæ–‡ä»¶å¤¹ä¸‹çš„id_rsa.pubè¿½åŠ åˆ°è¿œç¨‹ä¸»æœº.sshæ–‡ä»¶å¤¹ä¸‹çš„authorized_keysæ–‡ä»¶ä¸­ 1cat id_rsa.pub &gt;&gt; authorized_keys screenå‘½ä»¤ 1234567891011121314# æ–°å»ºçª—å£screen -S name# æŒ‚èµ· [detached] ctrl + a + d # åˆ—å‡ºçª—å£åˆ—è¡¨screen -ls# æ€æ­»å¤šä½™çª—å£kill -9 threadnum# æ¸…é™¤æ­»å»çš„çª—å£screen -wipe ssh: connect to host port 22: Connection refused è§£å†³æ–¹æ³•ï¼š 1$ vim ~/.ssh/config 1234# Add section below to itHost github.com Hostname ssh.github.com Port 443 1234$ ssh -T git@github.comHi xxxxx! You&#x27;ve successfully authenticated, but GitHub does notprovide shell access. nignxæ­£å‘ä»£ç†é…ç½® 123456789101112131415161718192021#æ­£å‘ä»£ç†è½¬å‘httpè¯·æ±‚ server &#123; #æŒ‡å®šDNSæœåŠ¡å™¨IPåœ°å€ # resolver 114.114.114.114; #ç›‘å¬80ç«¯å£ï¼Œhttpé»˜è®¤ç«¯å£80 listen 80; #æœåŠ¡å™¨IPæˆ–åŸŸå server_name xxx.xxxxx.top; #æ­£å‘ä»£ç†è½¬å‘httpè¯·æ±‚ location / &#123; proxy_pass http://xxxxx.top:20003; proxy_set_header HOST $host; proxy_buffers 256 4k; proxy_max_temp_file_size 0k; proxy_connect_timeout 30; proxy_send_timeout 60; proxy_read_timeout 60; proxy_next_upstream error timeout invalid_header http_502; &#125;&#125; code-serveré”™è¯¯è§£å†³ 1234567891011121314151617181920212223#æ­£å‘ä»£ç†è½¬å‘httpè¯·æ±‚ code2server &#123; #æŒ‡å®šDNSæœåŠ¡å™¨IPåœ°å€ # resolver 114.114.114.114; #ç›‘å¬80ç«¯å£ï¼Œhttpé»˜è®¤ç«¯å£80 listen 80; #æœåŠ¡å™¨IPæˆ–åŸŸå server_name xxx.xxxxx.top; #æ­£å‘ä»£ç†è½¬å‘httpè¯·æ±‚ location / &#123; proxy_pass http://xxxxx.top:20013; proxy_set_header HOST $host; proxy_buffers 256 4k; proxy_max_temp_file_size 0k; proxy_connect_timeout 30; proxy_send_timeout 60; proxy_read_timeout 60; proxy_next_upstream error timeout invalid_header http_502; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection upgrade; &#125;&#125; ä¸€äº›windowsæŒ‡ä»¤ Windowsè½¬å‘wsl 123netsh interface portproxy add v4tov4 listenaddress=0.0.0.0 listenport=7777 connectaddress=localhost connectport=8888netsh interface portproxy show allnetsh interface portproxy delete v4tov4 listenport=7777 listenaddress=0.0.0.0 protocol=tcp ä»£ç†è®¾ç½® 12set http_proxy=sock5://192.168.31.100:1080set https_proxy=sock5://192.168.31.100:1080 éº»é»„ éº»é»„ç¢±å±äºè‚¾ä¸Šè…ºç´ å—ä½“æ¿€åŠ¨å‰‚ï¼Œæ˜¯ä»æ¤ç‰©éº»é»„è‰ä¸­æå–çš„ä¸€ç§ç”Ÿç‰©ç¢±ã€‚æœ‰ä»¥ä¸‹è¯ç†ä½œç”¨ï¼š1ã€èˆ’å¼ æ”¯æ°”ç®¡ã€‚2ã€å¢åŠ å¿ƒè‚Œæ”¶ç¼©åŠ›é‡ï¼ŒåŠ å¤§å¿ƒè„è¡€æ¶²è¾“å‡ºé‡ã€‚3ã€èƒ½å¤Ÿå…´å¥‹ä¸­æ¢ç¥ç»ç³»ç»Ÿã€‚åœ¨ä¸´åºŠä¸Šç”¨äºæ…¢æ€§ä½è¡€å‹ã€ç¼“è§£æ”¯æ°”ç®¡å“®å–˜ã€å¯¹æŠ—è¨éº»ç–¹ã€è¡€ç®¡ç¥ç»æ€§æ°´è‚¿ã€‚ åšæ­¤è–„å½¼ï¼Œæ±‰è¯­æˆè¯­ï¼Œæ‹¼éŸ³æ˜¯hÃ²u cÇ bÃ³ bÇï¼Œæ¯”å–»å¯¹äººã€å¯¹äº‹ä¸åŒçœ‹å¾…ã€‚ çœŸç† ä¸æ‚£å¯¡è€Œæ‚£ä¸å‡ é…¸è‘¡è„å¿ƒç† å¦å®šè‡ªå·±ä¹‹å‰æƒ³åƒè‘¡è„çš„æ„æ„¿ï¼ŒæŠŠè‡ªå·±çš„â€œä¸å¾—å·²â€åŒ…è£…æˆä¸€ç§è‡ªç”±ï¼Œå› ä¸ºæˆ‘æ˜¯ä¸»åŠ¨ä¸åƒçš„ï¼Œå› ä¸ºè‘¡è„ä¸å¥½åƒã€‚é…¸è‘¡è„å¿ƒç†çš„æœ¬è´¨æ˜¯å®¢è§‚ç¯å¢ƒæ— åŠ›æ”¹å˜ï¼Œé‚£æˆ‘å°±æ”¹å˜è‡ªå·±ï¼Œè°ƒæ•´è‡ªå·±æ¥é€‚åº”ç¯å¢ƒé…¸è‘¡è„å¿ƒç†å’Œç”œæŸ æª¬å¿ƒç†å¾€å¾€æ˜¯åŒæ—¶å‡ºç°ã€‚ä¸¤è€…ä¸€ç»„åˆï¼Œå¾€å°äº†è¯´ï¼Œå¾—è¿‡ä¸”è¿‡å‡‘åˆç”¨å§ï¼Œå¾€å¤§äº†è¯´ï¼Œé‚£å°±å¯ä»¥åŸ¹å…»å‡ºå¥´æ€§ã€‚æ¯”å¦‚è¯´åœ¨å¤ä»£çš‡æƒç¤¾ä¼šï¼Œè‡£æ°‘å¾—ä¸åˆ°è‡ªç”±ï¼Œäºæ˜¯å°±ä¼šå«Œå¼ƒè‡ªç”±ï¼ŒåŒæ—¶æˆ‘æ²¡åŠæ³•æ‘†è„±ä¸“åˆ¶ï¼Œé‚£æˆ‘å°±è½¬è€Œæ‹¥æŠ¤ä¸“åˆ¶ï¼Œå—·å—·èµç¾ç»Ÿæ²»è€…ï¼Œäººä¸€æ—¦ç»å†è¿™ä¸¤ä¸ªå¿ƒç†è¿‡ç¨‹ï¼Œå¥´æ€§å°±å…»æˆäº†ã€‚å¥´æ‰åœ¨å¾—ä¸åˆ°è‘¡è„çš„æƒ…å†µä¸‹ï¼Œç»™è‡ªå·±ç¼–é€ äº†ç”œæŸ æª¬ç¥è¯ å¥½ååˆ¶åº¦ ä¸€ä¸ªåˆ¶åº¦çš„å¥½åï¼Œå¹¶ä¸åœ¨äºå®ƒé¼“å¹æˆ–å¥‰è¡Œä»€ä¹ˆä¸»ä¹‰ï¼Œè€Œåœ¨äºç°å®å±‚é¢æƒåŠ›ç»“æ„æ˜¯å¦åˆç†ã€‚ æƒåŠ›ç»“æ„åˆç†ï¼Œæœ‰åˆ¶çº¦æœ‰ç›‘ç£ï¼Œå³ä½¿æœ‰å›½ç‹çš‡å¸ä¹Ÿå¹¶ä¸æ„å‘³ç€å°±æ˜¯å›ä¸»ä¸“åˆ¶ã€‚ ä½†æƒåŠ›ç»“æ„æ˜¯å„æ–­çš„ï¼Œå³ä½¿å›½åæ˜¯æ°‘ä¸»ä¸»ä¹‰å…±å’Œå›½ã€å®ªæ³•ä¸­å†™æ»¡æ°‘ä¸»ï¼Œå³ä½¿é¼“å¹è§£æ”¾å…¨äººç±»ï¼Œè‡ªè¯©æ‰‹é‡Œæ‹¿ç€ä¸€æœ¬å®‡å®™çœŸç†ï¼Œé‚£ä¹Ÿæ³¨å®šæ˜¯æš´æ”¿ã€‚ é©¬å…‹æ€ä¸»ä¹‰è®¤ä¸ºå›½å®¶æ˜¯é˜¶çº§çŸ›ç›¾ä¸å¯è°ƒå’Œçš„äº§ç‰©ï¼Œè®¤ä¸ºå›½å®¶æ˜¯ç»Ÿæ²»é˜¶çº§ç”¨æ¥å‹è¿«å¦ä¸€é˜¶çº§ï¼Œç»´æŠ¤è‡ªèº«ç»Ÿæ²»çš„å·¥å…· ä»–ä»¬æ˜¯ææƒ§çš„å¥´ä»†ï¼Œè°æŒæ§ä»–ä»¬ç”Ÿæ­»ä»–ä»¬å°±çˆ±è° æ ä¹‹äºæ°‘ï¼Œæ°‘å˜åœ¨å³ä¾¿æ ä¹‹äºå•† æ‘†ä¸å®Œçš„é˜”æ°”ï¼Œå¼„ä¸å®Œçš„æƒï¼Œåƒä¸å®Œçš„çé¦ï¼ŒèŠ±ä¸å®Œçš„é’±ï¼Œå¬ä¸å®Œçš„é¢‚æ­Œï¼Œæ”¶ä¸å®Œçš„äº†ç¤¼ï¼Œäº«ä¸å°½çš„è£åå¯Œè´µï¼Œè¿‡ä¸å®Œçš„å¹´ â€œé•¿å›ä¹‹æ¶å…¶ç½ªå°ï¼Œé€¢å›ä¹‹æ¶å…¶ç½ªå¤§â€ï¼ŒåªçŸ¥é“æ„Ÿæ©æˆ´å¾·ï¼Œä¸çŸ¥é“æ‰¹è¯„ç›‘ç£ï¼›åªçŸ¥é“ä¹‰åŠ¡ï¼Œä¸çŸ¥é“æƒåˆ©ï¼›åªå…³å¿ƒç§äººäº‹åŠ¡ï¼Œä¸å…³å¿ƒå…¬å…±äº‹åŠ¡ï¼Œå¯¹è‹¦éš¾å’Œç¤¾ä¼šé—®é¢˜è§†è€Œä¸è§ï¼Œå¯¹æŒ‡å‡ºé—®é¢˜çš„äººæ¶è¯­ç›¸å‘ï¼Œå¯¹æŒä¸åŒæ„è§è€…è¿›è¡Œæ€æƒ³éœ¸å‡Œï¼Œè¿™äº›äººè¦ä¹ˆæ˜¯åˆ«æœ‰ç”¨å¿ƒï¼Œè¦ä¹ˆæ˜¯æ•…æ„è£…å‚»ï¼Œæ— è®ºæ˜¯å“ªä¸€ç§ï¼Œéƒ½æ˜¯èµ¢åœ¨å½“ä¸‹ï¼Œç¥¸åœ¨åƒç§‹ æƒåŠ›å¯¼è‡´è…è´¥ï¼Œç»å¯¹çš„æƒåŠ›å¯¼è‡´ç»å¯¹çš„è…è´¥ ä»–ä»¬å§‹ç»ˆæŠŠæ”¿æ²»ä½œä¸ºè¾¾æˆç»æµç›®çš„çš„æ‰‹æ®µ ä¼ ç»Ÿæ–‡åŒ–å æ”¯é…åœ°ä½çš„éƒ¨åˆ†æ˜¯æœ€è…æœ½çš„ä¸œè¥¿ï¼Œå¿…é¡»è¿›è¡Œä¸¥å‰çš„è‡ªæˆ‘æ‰¹åˆ¤ï¼Œå‰©ä¸‹çš„å†…å®¹æ‰æœ‰èµ„æ ¼å’Œå…±äº§ä¸»ä¹‰æ‹‰å…³ç³»ã€‚ äº†è§£è‡ªå·±è½åçš„åŸå› ï¼Œçœ‹çœ‹åˆ«äººå¼ºå¤§çš„æ ¹æºï¼Œä¸€å‘³åœ°ä»‡æ¨ï¼Œä¸ä¼šè®©äººè¿›æ­¥ï¼Œåªä¼šè®©äººç–¯ç‹‚ â€œé•¿å›ä¹‹æ¶å…¶ç½ªå°ï¼Œé€¢å›ä¹‹æ¶å…¶ç½ªå¤§â€ï¼ŒåªçŸ¥é“æ„Ÿæ©æˆ´å¾·ï¼Œä¸çŸ¥é“æ‰¹è¯„ç›‘ç£ï¼›åªçŸ¥é“ä¹‰åŠ¡ï¼Œä¸çŸ¥é“æƒåˆ©ï¼›åªå…³å¿ƒç§äººäº‹åŠ¡ï¼Œä¸å…³å¿ƒå…¬å…±äº‹åŠ¡ï¼Œå¯¹è‹¦éš¾å’Œç¤¾ä¼šé—®é¢˜è§†è€Œä¸è§ï¼Œå¯¹æŒ‡å‡ºé—®é¢˜çš„äººæ¶è¯­ç›¸å‘ï¼Œå¯¹æŒä¸åŒæ„è§è€…è¿›è¡Œæ€æƒ³éœ¸å‡Œï¼Œè¿™äº›äººè¦ä¹ˆæ˜¯åˆ«æœ‰ç”¨å¿ƒï¼Œè¦ä¹ˆæ˜¯æ•…æ„è£…å‚»ï¼Œæ— è®ºæ˜¯å“ªä¸€ç§ï¼Œéƒ½æ˜¯èµ¢åœ¨å½“ä¸‹ï¼Œç¥¸åœ¨åƒç§‹ ä¸€å¥æ²¡æœ‰ç»è¿‡ä»»ä½•è¯æ˜çš„ã€ä¸åŒ…å«å½¢å®¹è¯å‰¯è¯ä¿®é¥°çš„ã€ä»…ä»…å¸¦äº†æ€§åˆ«æ ‡ç­¾çš„è¯è¯­ï¼Œå°±æˆäº†æŸæ€§åˆ«ä¼ªè£…æˆå¼±åŠ¿ç¾¤ä½“æ— ä¸‹é™äºˆå–äºˆæ±‚çš„é®ç¾å¸ƒã€‚ äº¡å›½äº¡å¤©ä¸‹çš„åŒºåˆ«ï¼Œæ”¹å˜äº†çš‡å¸çš„å§“åå’Œå›½å®¶çš„ç§°å·ï¼Œå«äº¡å›½ã€‚è€Œç­ç»äººæ€§å’Œä»ä¹‰ï¼ŒæŠŠäººæå¾—å’Œç¦½å…½ä¸€æ ·äº’ç›¸æ®‹å®³ï¼Œå«äº¡å¤©ä¸‹ã€‚ ä¹Œåˆä¹‹ä¸­åªæœ‰æŠŠæ¸ºå°çš„ä¸ªä½“æŠ•èº«äºä¸€ä¸ªè™šæ— ç¼¥ç¼ˆçš„ä¼Ÿå¤§çš„äº‹ä¸šä¸­çš„æ—¶å€™ï¼Œä»–æ‰ä¼šè§‰å¾—è‡ªå·±çš„äººç”Ÿæœ‰ä»·å€¼ï¼Œæ‰ä¼šè§‰å¾—è‡ªå·±ä¹Ÿæ›¾å¹²è¿‡å¤§äº‹ä¸šï¼Œç»å¯¹çœ‹ä¸æ¸…è‡ªå·±ä»å§‹è‡³ç»ˆç‚®ç°äººç”Ÿçš„è¿™ç§å‘½è¿æœ¬è´¨ ææƒæ”¿æ²»çš„ä¸€å¤§ç‰¹ç‚¹ï¼Œå°±æ˜¯æ‰€æœ‰çš„æ”¿æ²»åšå¼ˆï¼Œéƒ½æ˜¯æš—ç®±æ“ä½œï¼ŒæƒåŠ›å®Œå…¨åœ¨ä¸€å †ç§˜ä¸ç¤ºäººçš„æ½œè§„åˆ™ä¸‹è¿ä½œï¼Œä¸å¯é¢„çŸ¥ã€‚æ‹¿åˆ°å°é¢ä¸Šæ¥çš„ç»“æœéƒ½æ˜¯ä¸æ˜ä¸ç™½çš„ç»“æœã€‚æ‰€æœ‰äººçš„å®‰å±éƒ½å¯„äºä¸€äººä¹‹å¿µï¼ŒåŒ…æ‹¬ç‹¬è£è€…è‡ªå·±éƒ½æ²¡æœ‰ç»å¯¹çš„å®‰å…¨å¯è¨€ï¼Œåœ¨ç‹¬å¤«ä¹‹ä¸‹ï¼Œéƒ½æ˜¯å¥´æ‰ã€‚ åœ¨ç‰¹æƒæ”¿æ²»ä¸‹çš„æ”¿æ²»æƒåŠ›ï¼Œä¸æ˜¯è¢«ç”¨æ¥è¡¨è¾¾äººæ°‘çš„æ„å¿—ï¼Œå›¾è°‹äººæ°‘çš„åˆ©ç›Šï¼Œåœ¨ç‰¹æƒæ”¿æ²»ä¸‹çš„æ”¿æ²»æƒåŠ›ä¸æ˜¯è¢«è¿ç”¨æ¥è¡¨è¾¾äººæ°‘çš„æ„å¿—ï¼Œå›¾è°‹äººæ°‘çš„åˆ©ç›Šï¼Œåè€Œæ˜¯åœ¨â€œå›½å®¶çš„â€æˆ–â€œå›½æ°‘çš„â€åä¹‰ä¸‹ï¼Œè¢«è¿ç”¨æ¥ç®¡åˆ¶äººæ°‘ï¼Œå¥´å½¹äººæ°‘ï¼Œä»¥è¾¾æˆæƒåŠ¿è€…è‡ªç§è‡ªåˆ©çš„ç›®çš„ã€‚è¿™ç§æ”¿æ²»å½¢æ€å­˜åœ¨çš„å‰æï¼Œæ˜¯äººæ°‘è¿˜è¢«æŸç¼šè¢«é™åˆ¶åœ¨æ„šæ˜§æ— çŸ¥çš„çŠ¶æ€ä¸­ æ–‡åŒ–å­˜å¼‚ï¼Œæ–‡æ˜è¶‹åŒ ä½†æ˜¯ç‰¹æƒé˜¶çº§å®£ç§°ä»–ä»¬çš„ç‰¹æƒæ˜¯å¤©æˆï¼Œä¹ƒå¤©å‘½ã€‚åæ¥åˆå­¦ä¼šäº†æ›´å‰å®³çš„æ‹›æ•°ï¼Œé‚£å°±æ˜¯æŠŠè‡ªå·±éšè—åœ¨æ°‘æ—ï¼Œå›½å®¶è¿™äº›å®å¤§å™äº‹åé¢ï¼Œäººæ°‘åå¯¹ä»–ä»¬çš„ç‰¹æƒå°±æ˜¯é€†å¤©è€Œè¡Œï¼Œå°±æ˜¯ä¸çˆ±å›½ã€‚æ²¡æœ‰çŸ¥è¯†çš„æ°‘ä¼—ä¹Ÿä¸æ™“å¾—ç ”ç©¶è¿™äº›è¯æœ‰æ²¡æœ‰é“ç†ï¼Œåªæ˜¯ç›²ç›®é™„å’Œæ”¯æŒç‰¹æƒé˜¶çº§ï¼Œåè€Œå»åå¯¹é‚£äº›ä¸ºä»–ä»¬äº‰å–å¹³ç­‰å’Œè‡ªç”±æƒåˆ©çš„äºº å¥‡æŠ€æ·«å·§ç»ˆç©¶æ˜¯å°é“ï¼Œå®¶å›½å‘å±•ï¼Œéœ€æ³¨é‡ç¤¼æ³•ï¼Œäººæƒ…ä¸–æ•…ï¼Œé’»è¥ç»æµä»•é€”ï¼Œå¼˜æ‰¬é…’æ–‡åŒ–ï¼Œæ–¹æ˜¯æ­£é€”ã€‚å–ä¸­åº¸ä¹‹é“ï¼Œæ— ä¸ºè€Œæˆå¤§æ‰ã€‚èŒ¶æ¯çš„æ‘†æ”¾ï¼Œé…’æ¡Œä¸Šçš„ç¤¼ä»ªï¼Œç‚¹èœçš„å–èˆï¼Œé…’å“çš„é€‰æ‹©ï¼Œæ•¬é…’çš„é¡ºåºï¼Œå®£ä¼ ç¨¿çš„æªè¾ï¼Œé¢†å¯¼ç…§ç›¸æ—¶çš„ç«™ä½ï¼Œé¢†å¯¼çš„ç”¨è¯ï¼Œé¢†å¯¼çš„æ½œæ²Ÿé€šï¼Œé¢†å¯¼å¤–éƒ¨å‘è¨€ã€é¢†å¯¼å†…éƒ¨è°ˆè¯ï¼Œé¢†å¯¼ä¹‹é—´çš„å…³ç³»ï¼Œè¿™äº›æ‰æ˜¯è‰ºæœ¯ã€‚æˆ‘ä»¬è¿˜å¹´è½»ï¼Œç°åœ¨åˆšè¿›å…¥ç¤¾ä¼šå‡ å¹´è¿˜ä¸æ‡‚ï¼Œå¹´çºªè½»è½»ä¸ç†è§£è¿™äº›ï¼Œæœªæ¥è¦å­¦çš„è¿˜å¾ˆå¤šï¼Œè·¯è¿˜å¾ˆé•¿","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"ç¼–ç¨‹åŸºç¡€çŸ¥è¯†","slug":"ç¼–ç¨‹åŸºç¡€çŸ¥è¯†","permalink":"http://example.com/tags/%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}]},{"title":"Coding-è¡¨æ ¼æ“ä½œ","slug":"coding_table_opeartion","date":"2023-09-30T15:33:46.788Z","updated":"2024-05-22T02:19:32.565Z","comments":true,"path":"2023/09/30/coding_table_opeartion/","link":"","permalink":"http://example.com/2023/09/30/coding_table_opeartion/","excerpt":"","text":"è¯»å–æ—¥æœŸè¡¨æ ¼æ•°æ®å¹¶æ˜¾ç¤º è¯»å–æ—¥æœŸè¡¨æ ¼æ•°æ®å¹¶æ˜¾ç¤º 12345678910111213141516171819202122import matplotlib.pyplot as pltimport pandas as pddf = pd.read_csv(&#x27;plot.csv&#x27;)# æ ¼å¼è½¬ä¸ºæ—¥æœŸdf[&#x27;date&#x27;] = pd.to_datetime(df[&#x27;date&#x27;])df.set_index(&#x27;date&#x27;, inplace=True)#è¾“å…¥æŠ˜çº¿å›¾æ•°æ®plt.plot(df.index,df[&quot;a2c&quot;],label=&#x27;a2c&#x27;,linewidth=1,color=&#x27;c&#x27;,marker=&#x27;&#x27;,markerfacecolor=&#x27;blue&#x27;,markersize=5)plt.xlabel(&quot;date&quot;)#æ¨ªåæ ‡ä¸ºç‰©å“ç¼–å·plt.ylabel(&#x27;loss&#x27;)#çºµåæ ‡ä¸ºå„ç±»æŒ‡æ ‡plt.title(&quot;&quot;)#æŠ˜çº¿å›¾çš„åç§°#å›¾ä¾‹è¯´æ˜plt.legend()#æ˜¾ç¤ºç½‘æ ¼plt.grid()#æ˜¾ç¤ºå›¾åƒplt.show()","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Code-æ–‡ä»¶æ“ä½œ","slug":"Code-æ–‡ä»¶æ“ä½œ","permalink":"http://example.com/tags/Code-%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/"}]},{"title":"Coding-æœºå™¨å­¦ä¹ åˆ†ç±»å™¨","slug":"coding_python__classification_method","date":"2023-09-27T04:30:22.190Z","updated":"2024-01-23T03:55:13.457Z","comments":true,"path":"2023/09/27/coding_python__classification_method/","link":"","permalink":"http://example.com/2023/09/27/coding_python__classification_method/","excerpt":"","text":"Tæ£€éªŒ SVM æœ´ç´ è´å¶æ–¯ Kè¿‘é‚» Tæ£€éªŒ å¯¹æ ‡ç­¾ä¸º1å’Œ-1çš„æ ·æœ¬è¿›è¡ŒTæ£€éªŒ 12345678910111213141516from scipy.stats import ttest_indfrom statsmodels.stats.multitest import fdrcorrectiondef t_test(data, label): # å°†æ­£è´Ÿæ ·æœ¬åˆ†å¼€ pos_data = data[label == 1] neg_data = data[label == -1] # å¯¹æ­£è´Ÿæ ·æœ¬åšç‹¬ç«‹æ ·æœ¬tæ£€éªŒ t_values, p_values = ttest_ind(pos_data, neg_data, axis=0) # ä½¿ç”¨FDRæ§åˆ¶æ–¹æ³•å»é™¤ä¸æ˜¾è‘—çš„ç‰¹å¾ reject, p_values_corrected = fdrcorrection(p_values, alpha=0.1) significant_features = np.where(reject)[0] # è¿”å›æ˜¾è‘—ç‰¹å¾çš„ç´¢å¼• return data[:,significant_features] SVM SVMå¯¹èºå°¾èŠ±æ•°æ®é›†åˆ†ç±»ï¼Œå¯ä»¥åˆ©ç”¨æ­¤ä»£ç è¿›è¡Œæ•°æ®é›†çš„åˆæ­¥åˆ†ç±»å¯è¡Œæ€§éªŒè¯ 1234567891011121314151617181920212223242526272829303132333435363738import numpy as npfrom sklearn.datasets import load_irisfrom sklearn.model_selection import GridSearchCV, KFold,train_test_splitfrom sklearn.svm import SVCiris = load_iris()data = iris.datalabels = iris.target# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=1)print(train_data.shape)print(test_data.shape)# å®šä¹‰å‚æ•°èŒƒå›´x = np.logspace(-4, 4, num=9, base=2)param_grid = &#123; &quot;C&quot;: x,&#125;# å®šä¹‰æ¨¡å‹å’Œäº¤å‰éªŒè¯model = SVC(kernel=&quot;linear&quot;)cv = KFold(n_splits=10, shuffle=True, random_state=1)# å®šä¹‰ç½‘æ ¼å‚æ•°æœç´¢æ³•grid_search = GridSearchCV(model, param_grid, cv=cv, scoring=&quot;accuracy&quot;)# è¿›è¡Œäº¤å‰éªŒè¯grid_search.fit(train_data, train_labels)# è¾“å‡ºæœ€ä½³å‚æ•°å’Œäº¤å‰éªŒè¯å¾—åˆ†print(&quot;Best parameters: &quot;, grid_search.best_params_)print(&quot;Cross-validation score: &quot;, grid_search.best_score_)# åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹test_score = grid_search.score(test_data, test_labels)print(&quot;Test set score: &quot;, test_score) æœ´ç´ è´å¶æ–¯ æœ´ç´ è´å¶æ–¯å¯¹èºå°¾èŠ±æ•°æ®é›†åˆ†ç±» 12345678910111213141516171819202122from sklearn.datasets import load_irisfrom sklearn.model_selection import train_test_splitfrom sklearn.naive_bayes import GaussianNBfrom sklearn.metrics import accuracy_score# åŠ è½½èºå°¾èŠ±æ•°æ®é›†iris = load_iris()data = iris.datalabels = iris.target# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=1)# åˆ›å»ºè´å¶æ–¯åˆ†ç±»å™¨å¯¹è±¡classifier = GaussianNB()# åœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒæ¨¡å‹classifier.fit(train_data, train_labels)# åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œé¢„æµ‹predictions = classifier.predict(test_data) Kè¿‘é‚» Kè¿‘é‚»å¯¹èºå°¾èŠ±æ•°æ®é›†åˆ†ç±» 12345678910111213141516171819202122232425from sklearn.datasets import load_irisfrom sklearn.model_selection import train_test_splitfrom sklearn.neighbors import KNeighborsClassifierfrom sklearn.metrics import accuracy_score# åŠ è½½èºå°¾èŠ±æ•°æ®é›†iris = load_iris()data = iris.datalabels = iris.target# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=1)# åˆ›å»ºKNNåˆ†ç±»å™¨å¯¹è±¡classifier = KNeighborsClassifier(n_neighbors=5)# åœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒæ¨¡å‹classifier.fit(train_data, train_labels)# åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œé¢„æµ‹predictions = classifier.predict(test_data)# è®¡ç®—åˆ†ç±»å‡†ç¡®ç‡accuracy = accuracy_score(test_labels, predictions)print(&quot;Accuracy: &quot;, accuracy)","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Code-åˆ†ç±»","slug":"Code-åˆ†ç±»","permalink":"http://example.com/tags/Code-%E5%88%86%E7%B1%BB/"}]},{"title":"Coding-æ–‡ä»¶æ“ä½œ","slug":"coding_python_file_operation","date":"2023-09-27T03:48:03.191Z","updated":"2024-01-23T03:55:17.327Z","comments":true,"path":"2023/09/27/coding_python_file_operation/","link":"","permalink":"http://example.com/2023/09/27/coding_python_file_operation/","excerpt":"","text":"ä¸­æ–‡å­—ç¬¦æ–‡ä»¶åæ¢æˆæ‹¼éŸ³ å…¶ä»–æ ¼å¼å›¾ç‰‡è½¬JPG ä¸­æ–‡å­—ç¬¦æ–‡ä»¶åæ¢æˆæ‹¼éŸ³ å°†è¾“å…¥æ–‡ä»¶å¤¹é‡Œçš„å›¾ç‰‡å‹ç¼©æœ‰å­˜å‚¨åˆ°è¾“å‡ºæ–‡ä»¶å¤¹ä¸­ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import osimport refrom pypinyin import pinyin, Styledef sanitize_filename(filename): # å°†æ±‰å­—è½¬æ¢ä¸ºæ‹¼éŸ³ pinyin_list = pinyin(filename, style=Style.NORMAL) pinyin_string = &#x27;&#x27;.join([item[0] for item in pinyin_list]) # ç§»é™¤éæ³•å­—ç¬¦ï¼Œåªä¿ç•™å­—æ¯ã€æ•°å­—ã€&quot;-&quot;ã€&quot;_&quot;å’Œ&quot;.&quot; sanitized_filename = re.sub(r&#x27;[^\\w\\-_.]&#x27;, &#x27;&#x27;, pinyin_string) return sanitized_filenamedef sanitize_directory(directory): # è·å–ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å’Œæ–‡ä»¶å¤¹ items = os.listdir(directory) # éå†æ‰€æœ‰é¡¹ for item in items: item_path = os.path.join(directory, item) if os.path.isdir(item_path): # å¦‚æœæ˜¯ç›®å½•ï¼Œé€’å½’å¤„ç†å­ç›®å½• sanitize_directory(item_path) # ä¿®æ”¹ç›®å½•åç§° sanitized_dirname = sanitize_filename(item) new_dir_path = os.path.join(directory, sanitized_dirname) if item != sanitized_dirname: os.rename(item_path, new_dir_path) else: # å¦‚æœæ˜¯æ–‡ä»¶ï¼Œä¿®æ”¹æ–‡ä»¶åç§° sanitized_filename = sanitize_filename(item) new_file_path = os.path.join(directory, sanitized_filename) if item != sanitized_filename: os.rename(item_path, new_file_path)# è®¾ç½®æ–‡ä»¶å¤¹è·¯å¾„folder_path = &#x27;input_floder&#x27;# é€’å½’ä¿®æ”¹ç›®å½•å’Œæ–‡ä»¶åç§°sanitize_directory(folder_path) å…¶ä»–æ ¼å¼å›¾ç‰‡è½¬JPG 12345678910111213141516171819202122232425262728293031323334import osfrom PIL import Imagedef convert_to_jpg(input_path, output_path): with Image.open(input_path) as image: # è½¬æ¢ä¸ºJPEGæ ¼å¼å¹¶ä¿å­˜ rgb_image = image.convert(&quot;RGB&quot;) rgb_image.save(output_path, format=&quot;JPEG&quot;)def convert_images_to_jpg(input_folder, output_folder): # å¦‚æœè¾“å‡ºæ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºè¯¥æ–‡ä»¶å¤¹ if not os.path.exists(output_folder): os.makedirs(output_folder) # éå†æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰å­æ–‡ä»¶å¤¹å’Œæ–‡ä»¶ for root, dirs, files in os.walk(input_folder): for file in files: # è·å–æ–‡ä»¶çš„å®Œæ•´è·¯å¾„ input_path = os.path.join(root, file) # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºå›¾ç‰‡æ ¼å¼ if file.lower().endswith((&#x27;.png&#x27;, &#x27;.bmp&#x27;, &#x27;.gif&#x27;, &#x27;.tiff&#x27;)): # æ„å»ºè¾“å‡ºè·¯å¾„ output_path = os.path.join(output_folder, os.path.splitext(file)[0] + &#x27;.jpg&#x27;) # å°†æ–‡ä»¶è½¬æ¢ä¸ºJPEGæ ¼å¼ convert_to_jpg(input_path, output_path)# è®¾ç½®è¾“å…¥å’Œè¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„input_folder = &#x27;input_folder&#x27;output_folder = &#x27;output_folder&#x27;# è½¬æ¢å›¾ç‰‡æ ¼å¼ä¸ºJPEGconvert_images_to_jpg(input_folder, output_folder)","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Code-æ–‡ä»¶æ“ä½œ","slug":"Code-æ–‡ä»¶æ“ä½œ","permalink":"http://example.com/tags/Code-%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/"}]},{"title":"Coding-å›¾åƒå¤„ç†","slug":"coding_python_image_process","date":"2023-09-26T09:05:15.426Z","updated":"2024-01-23T03:55:27.746Z","comments":true,"path":"2023/09/26/coding_python_image_process/","link":"","permalink":"http://example.com/2023/09/26/coding_python_image_process/","excerpt":"","text":"æ¢å¤å°†å½’ä¸€åŒ–åçš„å›¾ç‰‡ å¤šçº¿ç¨‹å‹ç¼©å›¾ç‰‡ å…¶ä»–æ ¼å¼å›¾ç‰‡è½¬JPG å°†æ–‡ä»¶å¤¹ä¸‹çš„ä¸‰é€šé“å›¾ç‰‡è½¬ä¸ºå•é€šé“ æ¢å¤å°†å½’ä¸€åŒ–åçš„å›¾ç‰‡ å˜æ¢ 123456transform = transforms.Compose([transforms.Resize((224, 224)),transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]) å­˜å‚¨éªŒè¯é›†ä¸­é¢„æµ‹é”™è¯¯çš„å›¾ç‰‡ 12345678910111213141516171819202122232425with torch.no_grad(): for images, labels in val_loader: images = images.to(device) labels = labels.to(device) outputs = model(images) _, predicted = torch.max(outputs.data, 1) total_samples += labels.size(0) total_correct += (predicted == labels).sum().item() # æ‰¾å‡ºè¯†åˆ«é”™è¯¯çš„å›¾ç‰‡ misclassified_idx = (predicted != labels) misclassified_images.extend(images[misclassified_idx].cpu().numpy()) val_accuracy = total_correct / total_samples print(f&quot;Validation Accuracy: &#123;val_accuracy:.4f&#125;&quot;) # ä¿å­˜è¯†åˆ«é”™è¯¯çš„å›¾ç‰‡ for i, image in enumerate(misclassified_images): image = np.transpose(image, (1, 2, 0)) # è½¬æ¢ä¸ºé€šé“åœ¨æœ€åçš„å½¢å¼ image = (image * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]) * 255 #æ¢å¤è¿‡ç¨‹ image = image.astype(np.uint8) # å°†åƒç´ å€¼è¿˜åŸä¸º 0-255 èŒƒå›´ image = Image.fromarray(image) image.save(f&quot;error_images/misclassified_&#123;epoch&#125;_&#123;i&#125;.jpg&quot;) å¤šçº¿ç¨‹å‹ç¼©å›¾ç‰‡ å°†è¾“å…¥æ–‡ä»¶å¤¹é‡Œçš„å›¾ç‰‡å‹ç¼©æœ‰å­˜å‚¨åˆ°è¾“å‡ºæ–‡ä»¶å¤¹ä¸­ 123456789101112131415161718192021222324252627282930313233343536373839404142import osimport shutilfrom concurrent.futures import ThreadPoolExecutorfrom PIL import Imageinput_folder = &#x27;input_folder&#x27;output_folder = &#x27;output_folder&#x27;# åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹if not os.path.exists(output_folder): os.makedirs(output_folder)# è·å–è¾“å…¥æ–‡ä»¶å¤¹ä¸­æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶çš„æ–‡ä»¶åfile_names = [f for f in os.listdir(input_folder) if os.path.isfile(os.path.join(input_folder, f)) and any(f.endswith(ext) for ext in [&#x27;.jpg&#x27;, &#x27;.jpeg&#x27;, &#x27;.png&#x27;, &#x27;.bmp&#x27;, &#x27;.gif&#x27;])]def process_image(file_name): # è·å–è¾“å…¥æ–‡ä»¶çš„è·¯å¾„ input_file_path = os.path.join(input_folder, file_name) output_file_path = os.path.join(output_folder, file_name) # æ‰“å¼€å›¾ç‰‡æ–‡ä»¶ with Image.open(input_file_path) as image: # æ£€æŸ¥å›¾ç‰‡æ ¼å¼ if image.format in [&#x27;JPEG&#x27;, &#x27;JPG&#x27;, &#x27;PNG&#x27;]: # å‹ç¼©å›¾ç‰‡å¹¶ä¿å­˜åˆ°è¾“å‡ºæ–‡ä»¶å¤¹ compressed_image = image.copy() compressed_image.save(output_file_path, optimize=True, quality=25) # æ£€æŸ¥å›¾ç‰‡å¤§å°æ˜¯å¦è¶…è¿‡500KB while os.path.getsize(output_file_path) &gt; 500 * 800: # ç¼©å°å›¾ç‰‡å°ºå¯¸ width, height = compressed_image.size new_width = int(width * 0.9) new_height = int(height * 0.9) compressed_image = compressed_image.resize((new_width, new_height)) # ä¿å­˜å‹ç¼©åçš„å›¾ç‰‡ compressed_image.save(output_file_path, optimize=True, quality=25)# ä½¿ç”¨ThreadPoolExecutoræ¥å¹¶è¡Œå¤„ç†æ¯ä¸€å¼ å›¾ç‰‡with ThreadPoolExecutor() as executor: executor.map(process_image, file_names) å…¶ä»–æ ¼å¼å›¾ç‰‡è½¬JPG 12345678910111213141516171819202122232425262728293031323334import osfrom PIL import Imagedef convert_to_jpg(input_path, output_path): with Image.open(input_path) as image: # è½¬æ¢ä¸ºJPEGæ ¼å¼å¹¶ä¿å­˜ rgb_image = image.convert(&quot;RGB&quot;) rgb_image.save(output_path, format=&quot;JPEG&quot;)def convert_images_to_jpg(input_folder, output_folder): # å¦‚æœè¾“å‡ºæ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºè¯¥æ–‡ä»¶å¤¹ if not os.path.exists(output_folder): os.makedirs(output_folder) # éå†æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰å­æ–‡ä»¶å¤¹å’Œæ–‡ä»¶ for root, dirs, files in os.walk(input_folder): for file in files: # è·å–æ–‡ä»¶çš„å®Œæ•´è·¯å¾„ input_path = os.path.join(root, file) # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºå›¾ç‰‡æ ¼å¼ if file.lower().endswith((&#x27;.png&#x27;, &#x27;.bmp&#x27;, &#x27;.gif&#x27;, &#x27;.tiff&#x27;)): # æ„å»ºè¾“å‡ºè·¯å¾„ output_path = os.path.join(output_folder, os.path.splitext(file)[0] + &#x27;.jpg&#x27;) # å°†æ–‡ä»¶è½¬æ¢ä¸ºJPEGæ ¼å¼ convert_to_jpg(input_path, output_path)# è®¾ç½®è¾“å…¥å’Œè¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„input_folder = &#x27;input_folder&#x27;output_folder = &#x27;output_folder&#x27;# è½¬æ¢å›¾ç‰‡æ ¼å¼ä¸ºJPEGconvert_images_to_jpg(input_folder, output_folder) å°†æ–‡ä»¶å¤¹ä¸‹çš„ä¸‰é€šé“å›¾ç‰‡è½¬ä¸ºå•é€šé“ 123456789101112from PIL import Imageimport ospath = &#x27;input_floder&#x27;list_ = os.listdir(path)list_ = [ os.path.join(path,i) for i in list_]for i in list_: image = Image.open(i) gray_image = image.convert(&#x27;L&#x27;) gray_image.save(i)","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Code-å›¾åƒå¤„ç†","slug":"Code-å›¾åƒå¤„ç†","permalink":"http://example.com/tags/Code-%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}]},{"title":"Coding-MLP-UNET-RESNET-2D OR 3D","slug":"coding_network_usual_use","date":"2023-09-12T07:49:08.125Z","updated":"2024-05-22T02:11:11.786Z","comments":true,"path":"2023/09/12/coding_network_usual_use/","link":"","permalink":"http://example.com/2023/09/12/coding_network_usual_use/","excerpt":"","text":"MLP 2D-Unet 2D-Resnet 3D-Resnet MLP 1234567891011121314151617181920212223242526import torch.nn as nnclass FCModel(nn.Module): def __init__(self, input_size, hidden_size, num_classes): super(FCModel, self).__init__() self.fc1 = nn.Linear(input_size, hidden_size) self.fc2 = nn.Linear(hidden_size, num_classes) def forward(self, x): batch_size, seq_length, input_size = x.size() x = x.view(batch_size * seq_length, input_size) # Reshape input to (batch_size * seq_length, input_size) h = self.fc1(x) out = self.fc2(h) out = out.view(batch_size, seq_length, -1) # Reshape output back to (batch_size, seq_length, num_classes) out = out[:, -1, :] # Take the last time step&#x27;s output return out# è®¾ç½®è¶…å‚æ•°input_size = 13456hidden_size = 64num_classes = 2# åˆ›å»ºæ¨¡å‹å®ä¾‹model = FCModel(input_size, hidden_size, num_classes) 2D-Unet 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107import torchimport torch.nn as nnimport torch.nn.functional as F# UNetçš„ä¸€å¤§å±‚ï¼ŒåŒ…å«äº†ä¸¤å±‚å°çš„å·ç§¯class DoubleConv(nn.Module): def __init__(self, in_ch, out_ch): super(DoubleConv, self).__init__() self.conv = nn.Sequential( nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True), nn.Conv2d(out_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True) ) def forward(self, x): x = self.conv(x) return x# å®šä¹‰è¾“å…¥è¿›æ¥çš„ç¬¬ä¸€å±‚class InConv(nn.Module): def __init__(self, in_ch, out_ch): super(InConv, self).__init__() self.conv = DoubleConv(in_ch, out_ch) def forward(self, x): x = self.conv(x) return x# å®šä¹‰encoderä¸­çš„å‘ä¸‹ä¼ æ’­ï¼ŒåŒ…æ‹¬ä¸€ä¸ªmaxpoolå’Œä¸€å¤§å±‚ class Down(nn.Module): def __init__(self, in_ch, out_ch): super(Down, self).__init__() self.mpconv = nn.Sequential( nn.MaxPool2d(2), DoubleConv(in_ch, out_ch) ) def forward(self, x): x = self.mpconv(x) return x# å®šä¹‰decoderä¸­çš„å‘ä¸Šä¼ æ’­class Up(nn.Module): def __init__(self, in_ch, out_ch, bilinear=True): super(Up, self).__init__() # å®šä¹‰äº†self.upçš„æ–¹æ³• if bilinear: self.up = nn.Upsample(scale_factor=2, mode=&#x27;bilinear&#x27;, align_corners=True) else: self.up = nn.ConvTranspose2d(in_ch // 2, in_ch // 2, 2, stride=2) # // é™¤ä»¥çš„ç»“æœå‘ä¸‹å–æ•´ self.conv = DoubleConv(in_ch, out_ch) def forward(self, x1, x2): # x2æ˜¯å·¦ä¾§çš„è¾“å‡ºï¼Œx1æ˜¯ä¸Šä¸€å¤§å±‚æ¥çš„è¾“å‡º x1 = self.up(x1) diffY = x2.size()[2] - x1.size()[2] diffX = x2.size()[3] - x1.size()[3] x1 = F.pad(x1, (diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2)) x = torch.cat([x2, x1], dim=1) # å°†ä¸¤ä¸ªtensoræ‹¼æ¥åœ¨ä¸€èµ· dim=1ï¼šåœ¨é€šé“æ•°ï¼ˆCï¼‰ä¸Šè¿›è¡Œæ‹¼æ¥ x = self.conv(x) return x# å®šä¹‰æœ€ç»ˆçš„è¾“å‡ºclass OutConv(nn.Module): def __init__(self, in_ch, out_ch): super(OutConv, self).__init__() self.conv = nn.Conv2d(in_ch, out_ch, 1) def forward(self, x): x = self.conv(x) return xclass Unet(nn.Module): def __init__(self, in_channels, classes): # in_channels å›¾ç‰‡çš„é€šé“æ•°ï¼Œ1ä¸ºç°åº¦å›¾ï¼Œ3ä¸ºå½©è‰²å›¾ super(Unet, self).__init__() self.n_channels = in_channels self.n_classes = classes self.inc = InConv(in_channels, 64) self.down1 = Down(64, 128) self.down2 = Down(128, 256) self.down3 = Down(256, 512) self.down4 = Down(512, 512) self.up1 = Up(1024, 256) self.up2 = Up(512, 128) self.up3 = Up(256, 64) self.up4 = Up(128, 64) self.outc = OutConv(64, classes) def forward(self, x): x1 = self.inc(x) x2 = self.down1(x1) x3 = self.down2(x2) x4 = self.down3(x3) x5 = self.down4(x4) x = self.up1(x5, x4) x = self.up2(x, x3) x = self.up3(x, x2) x = self.up4(x, x1) x = self.outc(x) return x 2D-Resnet 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105import torchimport torch.nn as nnclass BasicBlock(nn.Module): expansion = 1 def __init__(self, in_channels, out_channels, stride=1): super(BasicBlock, self).__init__() # ç¬¬ä¸€ä¸ªå·ç§¯å±‚ self.conv1 = nn.Conv2d( in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False ) self.bn1 = nn.BatchNorm2d(out_channels) self.relu = nn.ReLU(inplace=True) # ç¬¬äºŒä¸ªå·ç§¯å±‚ self.conv2 = nn.Conv2d( out_channels, out_channels * self.expansion, kernel_size=3, stride=1, padding=1, bias=False, ) self.bn2 = nn.BatchNorm2d(out_channels * self.expansion) # æ®‹å·®è¿æ¥ï¼ˆshortcut connectionï¼‰ self.shortcut = nn.Sequential() if stride != 1 or in_channels != out_channels * self.expansion: self.shortcut = nn.Sequential( nn.Conv2d( in_channels, out_channels * self.expansion, kernel_size=1, stride=stride, bias=False, ), nn.BatchNorm2d(out_channels * self.expansion), ) def forward(self, x): residual = x out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) out += self.shortcut(residual) out = self.relu(out) return outclass ResNet(nn.Module): def __init__(self, block, num_blocks, num_classes=10): super(ResNet, self).__init__() self.in_channels = 64 # ç¬¬ä¸€ä¸ªå·ç§¯å±‚ self.conv1 = nn.Conv2d( 3, 64, kernel_size=3, stride=1, padding=1, bias=False ) self.bn1 = nn.BatchNorm2d(64) self.relu = nn.ReLU(inplace=True) # ResNetçš„å››ä¸ªé˜¶æ®µ self.layer1 = self.make_layer(block, 64, num_blocks[0], stride=1) self.layer2 = self.make_layer(block, 128, num_blocks[1], stride=2) self.layer3 = self.make_layer(block, 256, num_blocks[2], stride=2) self.layer4 = self.make_layer(block, 512, num_blocks[3], stride=2) # å…¨å±€å¹³å‡æ± åŒ–å±‚å’Œå…¨è¿æ¥å±‚ self.avg_pool = nn.AdaptiveAvgPool2d((1, 1)) self.fc = nn.Linear(512 * block.expansion, num_classes) def make_layer(self, block, out_channels, num_blocks, stride): layers = [] layers.append(block(self.in_channels, out_channels, stride)) self.in_channels = out_channels * block.expansion for _ in range(1, num_blocks): layers.append(block(self.in_channels, out_channels)) return nn.Sequential(*layers) def forward(self, x): out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.layer1(out) out = self.layer2(out) out = self.layer3(out) out = self.layer4(out) out = self.avg_pool(out) out = torch.flatten(out, 1) out = self.fc(out) return outdef ResNet18(num_classes=10): return ResNet(BasicBlock, [2, 2, 2, 2], num_classes) 3D-Resnet 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103class BasicBlock(nn.Module): expansion = 1 def __init__(self, in_channels, out_channels, stride=1): super(BasicBlock, self).__init__() # ç¬¬ä¸€ä¸ªå·ç§¯å±‚ self.conv1 = nn.Conv3d( in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False ) self.bn1 = nn.BatchNorm3d(out_channels) self.relu = nn.ReLU(inplace=True) # ç¬¬äºŒä¸ªå·ç§¯å±‚ self.conv2 = nn.Conv3d( out_channels, out_channels * self.expansion, kernel_size=3, stride=1, padding=1, bias=False, ) self.bn2 = nn.BatchNorm3d(out_channels * self.expansion) # æ®‹å·®è¿æ¥ï¼ˆshortcut connectionï¼‰ self.shortcut = nn.Sequential() if stride != 1 or in_channels != out_channels * self.expansion: self.shortcut = nn.Sequential( nn.Conv3d( in_channels, out_channels * self.expansion, kernel_size=1, stride=stride, bias=False, ), nn.BatchNorm3d(out_channels * self.expansion), ) def forward(self, x): residual = x out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) out += self.shortcut(residual) out = self.relu(out) return outclass ResNet(nn.Module): def __init__(self, block, num_blocks, num_classes=10): super(ResNet, self).__init__() self.in_channels = 64 # ç¬¬ä¸€ä¸ªå·ç§¯å±‚ self.conv1 = nn.Conv3d( 1, 64, kernel_size=3, stride=1, padding=1, bias=False ) self.bn1 = nn.BatchNorm3d(64) self.relu = nn.ReLU(inplace=True) # ResNetçš„å››ä¸ªé˜¶æ®µ self.layer1 = self.make_layer(block, 64, num_blocks[0], stride=1) self.layer2 = self.make_layer(block, 128, num_blocks[1], stride=2) self.layer3 = self.make_layer(block, 256, num_blocks[2], stride=2) self.layer4 = self.make_layer(block, 512, num_blocks[3], stride=2) # å…¨å±€å¹³å‡æ± åŒ–å±‚å’Œå…¨è¿æ¥å±‚ self.avg_pool = nn.AdaptiveAvgPool3d((1, 1, 1)) self.fc = nn.Linear(512 * block.expansion, num_classes) def make_layer(self, block, out_channels, num_blocks, stride): layers = [] layers.append(block(self.in_channels, out_channels, stride)) self.in_channels = out_channels * block.expansion for _ in range(1, num_blocks): layers.append(block(self.in_channels, out_channels)) return nn.Sequential(*layers) def forward(self, x): out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.layer1(out) out = self.layer2(out) out = self.layer3(out) out = self.layer4(out) out = self.avg_pool(out) out = torch.flatten(out, 1) out = self.fc(out) return outdef ResNet18_3D(num_classes=10): return ResNet(BasicBlock, [2, 2, 2, 2], num_classes)","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Code-åŸºç¡€æ¨¡å‹","slug":"Code-åŸºç¡€æ¨¡å‹","permalink":"http://example.com/tags/Code-%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B/"}]},{"title":"Coding-åŒ»å­¦å›¾åƒå¤„ç†","slug":"coding_python_medical","date":"2023-09-04T02:09:53.960Z","updated":"2024-01-23T03:55:36.622Z","comments":true,"path":"2023/09/04/coding_python_medical/","link":"","permalink":"http://example.com/2023/09/04/coding_python_medical/","excerpt":"","text":"è¯»å–niiæ–‡ä»¶ï¼Œå­˜å‚¨niiæ–‡ä»¶ è¯»å–niiæ–‡ä»¶ï¼Œå­˜å‚¨niiæ–‡ä»¶ 12345678910111213141516import nibabel as nib# è¯»å–NIfTIæ–‡ä»¶nii_file = &#x27;1_output.nii&#x27;nii_img = nib.load(nii_file)# è·å–å›¾åƒæ•°æ®å’Œå…ƒæ•°æ®data = nii_img.get_fdata()header = nii_img.header# è¿›è¡Œå¿…è¦çš„æ“ä½œï¼Œä¾‹å¦‚å¤„ç†æ•°æ®æˆ–åˆ†æ# ä¿å­˜NIfTIæ–‡ä»¶output_file = &#x27;2_output.nii&#x27;output_img = nib.Nifti1Image(data, affine=None, header=header)nib.save(output_img, output_file)","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Code-å›¾åƒå¤„ç†","slug":"Code-å›¾åƒå¤„ç†","permalink":"http://example.com/tags/Code-%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}]},{"title":"PaperReading-DMC-Fusion:åŸºäºåˆ†ç±»å™¨ç‰¹å¾åˆæˆçš„æ·±åº¦å¤šçº§è”èåˆé’ˆå¯¹åŒ»å­¦å¤šæ¨¡æ€å›¾åƒ","slug":"DMC-Fusion Deep Multi-cascade Fusion with Classifier-Based Feature Synthesis for Medical Multi-modal Images","date":"2023-09-03T11:38:59.208Z","updated":"2024-01-20T03:02:04.245Z","comments":true,"path":"2023/09/03/DMC-Fusion Deep Multi-cascade Fusion with Classifier-Based Feature Synthesis for Medical Multi-modal Images/","link":"","permalink":"http://example.com/2023/09/03/DMC-Fusion%20Deep%20Multi-cascade%20Fusion%20with%20Classifier-Based%20Feature%20Synthesis%20for%20Medical%20Multi-modal%20Images/","excerpt":"","text":"DMC-Fusion: Deep Multi-cascade Fusion with Classifier-Based Feature Synthesis for Medical Multi-modal Images 1.æ‘˜è¦ å¤šæ¨¡æ€åŒ»å­¦å›¾åƒèåˆæ˜¯ä¸´åºŠç²¾ç¡®è¯Šæ–­å’Œæ‰‹æœ¯è®¡åˆ’çš„é‡è¦è¯¾é¢˜ã€‚å°½ç®¡åƒDensefuseè¿™æ ·çš„å•ç‰¹å¾èåˆç­–ç•¥å–å¾—äº†ä»¤äººé¼“èˆçš„æ•ˆæœï¼Œä½†å®ƒå¾€å¾€ä¸èƒ½å®Œå…¨ä¿ç•™æºå›¾åƒçš„ç‰¹å¾ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºåˆ†ç±»å™¨ç‰¹å¾åˆæˆçš„æ·±åº¦å¤šèåˆæ¡†æ¶ï¼Œç”¨äºå¤šæ¨¡æ€åŒ»å­¦å›¾åƒçš„è‡ªåŠ¨èåˆã€‚è¯¥ç®—æ³•ç”±åŸºäºå¯†é›†è¿æ¥ï¼ˆdense connectionsï¼‰çš„é¢„è®­ç»ƒè‡ªç¼–ç å™¨ã€ç‰¹å¾åˆ†ç±»å™¨å’Œä¸€ç§åˆ†åˆ«èåˆé«˜é¢‘å’Œä½é¢‘çš„å¤šçº§è”èåˆè§£ç å™¨ã€‚ç¼–ç å™¨å’Œè§£ç å™¨ä»MS-COCOæ•°æ®é›†ä¼ è¾“ï¼Œå¹¶åœ¨å¤šæ¨¡æ€åŒ»å­¦å›¾åƒå…¬å…±æ•°æ®é›†ä¸ŠåŒæ—¶è¿›è¡Œé¢„è®­ç»ƒä»¥æå–ç‰¹å¾ã€‚é€šè¿‡é«˜æ–¯é«˜é€šæ»¤æ³¢å’Œå³°å€¼ä¿¡å™ªæ¯”é˜ˆå€¼æ³•å¯¹ç‰¹å¾è¿›è¡Œåˆ†ç±»ï¼Œç„¶åå°†é¢„è®­ç»ƒçš„Dense-Blockå’Œè§£ç å™¨çš„æ¯ä¸€å±‚ç‰¹å¾æ˜ å°„åˆ’åˆ†ä¸ºé«˜é¢‘å’Œä½é¢‘åºåˆ—ã€‚å…·ä½“è€Œè¨€ï¼Œåœ¨æ‰€æå‡ºçš„ç‰¹å¾èåˆå—ä¸­ï¼Œé‡‡ç”¨å‚æ•°è‡ªé€‚åº”è„‰å†²è€¦åˆç¥ç»ç½‘ç»œå’ŒL1åŠ æƒåˆ†åˆ«è¿›è¡Œé«˜é¢‘å’Œä½é¢‘èåˆã€‚æœ€åï¼Œæˆ‘ä»¬åœ¨å…¨è§£ç ç‰¹å¾é˜¶æ®µè®¾è®¡äº†ä¸€ç§æ–°å‹çš„å¤šçº§èåˆè§£ç å™¨ï¼Œä»¥é€‰æ‹©æ€§åœ°èåˆä¸åŒæ¨¡æ€çš„æœ‰ç”¨ä¿¡æ¯ã€‚æˆ‘ä»¬è¿˜ä½¿ç”¨èåˆå›¾åƒéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•å¯¹è„‘éƒ¨ç–¾ç—…çš„åˆ†ç±»ï¼Œå¹¶è¿›è¡Œäº†ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒï¼Œä»¥è¯´æ˜åˆ†ç±»æ€§èƒ½çš„æé«˜æ˜¯ç”±äºèåˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å®šæ€§å’Œå®šé‡è¯„ä»·æ–¹é¢éƒ½è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ°´å¹³ã€‚ 2.å¼•è¨€ 3.è®ºæ–‡ç»“æ„ 4.æ€»ç»“ 5.æ–‡ç« ç¬”è®° MRIå’ŒPETçš„åŸºæœ¬åŸç†çš„å™è¿°ï¼š ç£å…±æŒ¯æˆåƒ(MRI)æ˜¯ä¸€ç§åˆ©ç”¨ç£åœºå’Œæ— çº¿ç”µæ³¢å¯¹äººä½“å†…éƒ¨å™¨å®˜è¿›è¡Œæˆåƒçš„ç»“æ„æ–¹å¼ã€‚è¿™ç§éä¾µå…¥æ€§è¯Šæ–­å·¥å…·æµ‹é‡æ‰€éœ€èº«ä½“éƒ¨ä½çš„è§£å‰–ç»“æ„ã€‚è€Œæ­£ç”µå­å‘å°„æ–­å±‚æ‰«æ(PET)æ˜¯ä¸€ç§åŠŸèƒ½æ¨¡å¼ï¼Œä½¿ç”¨æ”¾å°„æ€§ç¤ºè¸ªå‰‚æ¥é‡åŒ–äººä½“ç»„ç»‡å’Œå™¨å®˜ä¸­çš„ä»£è°¢æ´»åŠ¨ã€‚","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[]},{"title":"Coding-å½©è‰²å›¾ç‰‡åˆ†ç±»-åŸºäº2D-Unet","slug":"coding_network_example","date":"2023-09-02T13:09:09.106Z","updated":"2024-01-23T03:54:55.135Z","comments":true,"path":"2023/09/02/coding_network_example/","link":"","permalink":"http://example.com/2023/09/02/coding_network_example/","excerpt":"","text":"æ‘˜è¦ main.py æ‘˜è¦ è®­ç»ƒä¸€ä¸ªå›¾ç‰‡åˆ†ç±»ç¥ç»ç½‘ç»œï¼ˆ2D-Unetï¼‰ï¼ŒåŒ…æ‹¬ 1.è‡ªå®šä¹‰dataloadåˆ¶ä½œ 2,ç½‘ç»œå®šä¹‰ 3.è®­ç»ƒè¿‡ç¨‹ 4.æµ‹è¯•è¿‡ç¨‹ 5.æ¨¡å‹è¯„ä¼°ï¼ˆå‡†ç¡®ç‡ï¼‰ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120import glob # å¯¼å…¥ç”¨äºæ–‡ä»¶è·¯å¾„åŒ¹é…çš„æ¨¡å—from torchvision import transforms # å¯¼å…¥å›¾åƒè½¬æ¢æ¨¡å—from torch.utils import data # å¯¼å…¥PyTorchæ•°æ®å·¥å…·æ¨¡å—from PIL import Image # å¯¼å…¥PILå›¾åƒå¤„ç†åº“import matplotlib.pyplot as plt # å¯¼å…¥ç»˜å›¾åº“import torch # å¯¼å…¥PyTorchåº“import torch.nn as nn # å¯¼å…¥PyTorchç¥ç»ç½‘ç»œæ¨¡å—import torch.nn.functional as F # å¯¼å…¥PyTorchå‡½æ•°åº“from unet import Unet # å¯¼å…¥è‡ªå®šä¹‰çš„U-Netæ¨¡å‹import numpy as np # å¯¼å…¥NumPyåº“# æ ‡å‡†åŒ–æ•°æ®transforms = transforms.Compose([ transforms.ToTensor(), # å°†å›¾åƒè½¬æ¢ä¸ºå¼ é‡ transforms.Resize((256, 256)), # è°ƒæ•´å›¾åƒå¤§å°ä¸º256x256 transforms.Normalize(mean=0.5, std=0.5) # æ ‡å‡†åŒ–å›¾åƒæ•°æ®])class my_dataset(data.Dataset): def __init__(self, imgs_path, annos_path): self.imgs_path = imgs_path # å›¾åƒæ–‡ä»¶è·¯å¾„ self.annos_path = annos_path # æ ‡ç­¾æ–‡ä»¶è·¯å¾„ def __getitem__(self, index): img_path = self.imgs_path[index] # è·å–å›¾åƒè·¯å¾„ pil_img = Image.open(img_path) # ä½¿ç”¨PILæ‰“å¼€å›¾åƒ pil_img = transforms(pil_img) # å¯¹å›¾åƒè¿›è¡Œé¢„å¤„ç† anno_path = self.annos_path[index] # è·å–æ ‡ç­¾è·¯å¾„ anno_img = Image.open(anno_path) # ä½¿ç”¨PILæ‰“å¼€æ ‡ç­¾å›¾åƒ pil_anno = transforms(anno_img) # å¯¹æ ‡ç­¾å›¾åƒè¿›è¡Œé¢„å¤„ç† return pil_img, pil_anno def __len__(self): return len(self.imgs_path) # è¿”å›æ•°æ®é›†çš„é•¿åº¦def train(model, train_loader, criterion, optimizer, device): model.train() # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼ train_loss = 0 for data, label in train_loader: data = data.to(device) optimizer.zero_grad() # æ¸…é™¤æ¢¯åº¦ output = model(data) # å‰å‘ä¼ æ’­ loss = criterion(output, label.to(device).float()) # è®¡ç®—æŸå¤± loss.backward() # åå‘ä¼ æ’­ï¼Œè®¡ç®—æ¢¯åº¦ optimizer.step() # æ›´æ–°æ¨¡å‹å‚æ•° train_loss += loss.item() * data.size(0) train_loss /= len(train_loader.dataset) # è®¡ç®—å¹³å‡è®­ç»ƒæŸå¤± return train_lossdef validate(model, val_loader, criterion, device): model.eval() # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼ val_loss = 0 with torch.no_grad(): for data, label in val_loader: data = data.to(device) output = model(data) # å‰å‘ä¼ æ’­ loss = criterion(output, label.to(device).float()) # è®¡ç®—æŸå¤± val_loss += loss.item() * data.size(0) val_loss /= len(val_loader.dataset) # è®¡ç®—å¹³å‡éªŒè¯æŸå¤± return val_loss if __name__ ==&#x27;__main__&#x27;: # è®­ç»ƒæ•°æ®é›†å¯¼å…¥ imgs_path = glob.glob(&#x27;facade/train_picture/*.png&#x27;) # åŒ¹é…è®­ç»ƒå›¾åƒæ–‡ä»¶è·¯å¾„ label_path = glob.glob(&#x27;facade/train_label/*.jpg&#x27;) # åŒ¹é…è®­ç»ƒæ ‡ç­¾æ–‡ä»¶è·¯å¾„ # æµ‹è¯•æ•°æ®é›†å¯¼å…¥ test_imgs_path = glob.glob(&#x27;facade/test_picture/*.png&#x27;) # åŒ¹é…æµ‹è¯•å›¾åƒæ–‡ä»¶è·¯å¾„ test_label_path = glob.glob(&#x27;facade/test_label/*.jpg&#x27;) # åŒ¹é…æµ‹è¯•æ ‡ç­¾æ–‡ä»¶è·¯å¾„ # å¯¹æ•°æ®å’Œæ ‡ç­¾æ’åºï¼Œç¡®ä¿ä¸€ä¸€å¯¹åº” imgs_path = sorted(imgs_path) label_path = sorted(label_path) test_imgs_path = sorted(test_imgs_path) test_label_path = sorted(test_label_path) train_dataset = my_dataset(imgs_path, label_path) test_dataset = my_dataset(test_imgs_path, test_label_path) # åˆ›å»ºæµ‹è¯•æ•°æ®é›†å¯¹è±¡ train_loader = data.DataLoader(train_dataset, batch_size=4, shuffle=True) # åˆ›å»ºè®­ç»ƒæ•°æ®åŠ è½½å™¨ test_loader = data.DataLoader(test_dataset, batch_size=4, shuffle=False) # åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨ # åˆ›å»ºU-Netæ¨¡å‹ in_channels = 3 # è¾“å…¥é€šé“æ•° out_channels = 3 # è¾“å‡ºé€šé“æ•° model = Unet(in_channels, out_channels) # åˆ›å»ºU-Netæ¨¡å‹å¯¹è±¡ criterion = nn.MSELoss() # åˆ›å»ºå‡æ–¹è¯¯å·®æŸå¤±å‡½æ•°å¯¹è±¡ optimizer = torch.optim.Adam(model.parameters(), lr=0.0001) # åˆ›å»ºä¼˜åŒ–å™¨å¯¹è±¡ # å°†æ¨¡å‹å’Œæ•°æ®ç§»åŠ¨åˆ°GPUä¸Š device = torch.device(&#x27;cuda&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;) # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„GPU model.to(device) # å°†æ¨¡å‹ç§»åŠ¨åˆ°GPUä¸Š train_losses = [] # ä¿å­˜è®­ç»ƒæŸå¤±çš„åˆ—è¡¨ val_losses = [] # ä¿å­˜éªŒè¯æŸå¤±çš„åˆ—è¡¨ best_val_loss = np.inf # åˆå§‹åŒ–æœ€ä½³éªŒè¯æŸå¤±ä¸ºæ­£æ— ç©· best_model = None # åˆå§‹åŒ–æœ€ä½³æ¨¡å‹ä¸ºç©º epoch_times = 300 # è®¾å®šè¿­ä»£æ¬¡æ•° # è®­ç»ƒæ¨¡å‹ for epoch in range(epoch_times): train_loss = train(model, train_loader, criterion, optimizer, device) # è®­ç»ƒæ¨¡å‹ val_loss = validate(model, test_loader, criterion, device) # éªŒè¯æ¨¡å‹ train_losses.append(train_loss) # ä¿å­˜è®­ç»ƒæŸå¤± val_losses.append(val_loss) # ä¿å­˜éªŒè¯æŸå¤± if val_loss &lt; best_val_loss: best_val_loss = val_loss best_model = model.state_dict() torch.save(best_model, &#x27;ckpt/model.ckpt&#x27;) # ä¿å­˜æœ€ä½³æ¨¡å‹å‚æ•° print(&quot;best_val_loss: &quot; + str(val_loss)) with open(&quot;ckpt/model_loss.txt&quot;, &quot;w&quot;) as f: f.write(str(val_loss)) print(&#x27;Epoch [&#123;&#125;/&#123;&#125;], Train Loss: &#123;:.4f&#125;, Val Loss: &#123;:.4f&#125;&#x27;.format(epoch+1, epoch_times, train_loss, val_loss)) val.py (å¯¼å…¥æ¨¡å‹è¿›è¡Œç”Ÿæˆæµ‹è¯•) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950from unet import Unet # å¯¼å…¥è‡ªå®šä¹‰çš„U-Netæ¨¡å‹import torch # å¯¼å…¥PyTorchåº“from torch.utils import data # å¯¼å…¥PyTorchæ•°æ®å·¥å…·æ¨¡å—from PIL import Image # å¯¼å…¥PILå›¾åƒå¤„ç†åº“from torchvision import transforms # å¯¼å…¥å›¾åƒè½¬æ¢æ¨¡å—import glob # å¯¼å…¥ç”¨äºæ–‡ä»¶è·¯å¾„åŒ¹é…çš„æ¨¡å—# æ ‡å‡†åŒ–æ•°æ®transforms = transforms.Compose([ transforms.ToTensor(), # å°†å›¾åƒè½¬æ¢ä¸ºå¼ é‡ transforms.Resize((256, 256)), # è°ƒæ•´å›¾åƒå¤§å°ä¸º256x256 transforms.Normalize(mean=0.5, std=0.5) # æ ‡å‡†åŒ–å›¾åƒæ•°æ®])class my_dataset(data.Dataset): def __init__(self, imgs_path, annos_path): self.imgs_path = imgs_path # å›¾åƒæ–‡ä»¶è·¯å¾„ self.annos_path = annos_path # æ ‡ç­¾æ–‡ä»¶è·¯å¾„ def __getitem__(self, index): img_path = self.imgs_path[index] # è·å–å›¾åƒè·¯å¾„ pil_img = Image.open(img_path) # ä½¿ç”¨PILæ‰“å¼€å›¾åƒ pil_img = transforms(pil_img) # å¯¹å›¾åƒè¿›è¡Œé¢„å¤„ç† anno_path = self.annos_path[index] # è·å–æ ‡ç­¾è·¯å¾„ anno_img = Image.open(anno_path) # ä½¿ç”¨PILæ‰“å¼€æ ‡ç­¾å›¾åƒ pil_anno = transforms(anno_img) # å¯¹æ ‡ç­¾å›¾åƒè¿›è¡Œé¢„å¤„ç† return pil_img, pil_anno def __len__(self): return len(self.imgs_path) # è¿”å›æ•°æ®é›†çš„é•¿åº¦# æµ‹è¯•æ•°æ®é›†å¯¼å…¥test_imgs_path = glob.glob(&#x27;facade/test_picture/*.png&#x27;) # åŒ¹é…æµ‹è¯•å›¾åƒæ–‡ä»¶è·¯å¾„test_label_path = glob.glob(&#x27;facade/test_label/*.jpg&#x27;) # åŒ¹é…æµ‹è¯•æ ‡ç­¾æ–‡ä»¶è·¯å¾„test_dataset = my_dataset(test_imgs_path, test_label_path) # åˆ›å»ºæµ‹è¯•æ•°æ®é›†å¯¹è±¡test_loader = data.DataLoader(test_dataset, batch_size=1, shuffle=False) # åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨model = Unet(3, 3) # åˆ›å»ºU-Netæ¨¡å‹å¯¹è±¡checkpoint = torch.load(&#x27;ckpt/model.ckpt&#x27;) # åŠ è½½æ¨¡å‹å‚æ•°model.load_state_dict(checkpoint) # åŠ è½½æ¨¡å‹å‚æ•°for data, label in test_loader: data = data * 0.5 + 0.5 # åæ ‡å‡†åŒ–å›¾åƒæ•°æ® output = model(data) # å‰å‘ä¼ æ’­ output = torch.squeeze(output, 0) # å»é™¤è¾“å‡ºå¼ é‡çš„ç»´åº¦ä¸º1çš„ç»´åº¦ array = output.cpu().detach().numpy().transpose(1, 2, 0) # å°†è¾“å‡ºå¼ é‡è½¬æ¢ä¸ºNumPyæ•°ç»„ï¼Œå¹¶è°ƒæ•´é€šé“é¡ºåºä¸ºHWC image = Image.fromarray((array * 255).astype(&#x27;uint8&#x27;)) # åˆ›å»ºPILå›¾åƒå¯¹è±¡ image.save(&#x27;image1.jpg&#x27;) # ä¿å­˜å›¾åƒä¸ºJPEGæ–‡ä»¶ unet.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107import torchimport torch.nn as nnimport torch.nn.functional as F# UNetçš„ä¸€å¤§å±‚ï¼ŒåŒ…å«äº†ä¸¤å±‚å°çš„å·ç§¯class DoubleConv(nn.Module): def __init__(self, in_ch, out_ch): super(DoubleConv, self).__init__() self.conv = nn.Sequential( nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True), nn.Conv2d(out_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True) ) def forward(self, x): x = self.conv(x) return x# å®šä¹‰è¾“å…¥è¿›æ¥çš„ç¬¬ä¸€å±‚class InConv(nn.Module): def __init__(self, in_ch, out_ch): super(InConv, self).__init__() self.conv = DoubleConv(in_ch, out_ch) def forward(self, x): x = self.conv(x) return x# å®šä¹‰encoderä¸­çš„å‘ä¸‹ä¼ æ’­ï¼ŒåŒ…æ‹¬ä¸€ä¸ªmaxpoolå’Œä¸€å¤§å±‚ class Down(nn.Module): def __init__(self, in_ch, out_ch): super(Down, self).__init__() self.mpconv = nn.Sequential( nn.MaxPool2d(2), DoubleConv(in_ch, out_ch) ) def forward(self, x): x = self.mpconv(x) return x# å®šä¹‰decoderä¸­çš„å‘ä¸Šä¼ æ’­class Up(nn.Module): def __init__(self, in_ch, out_ch, bilinear=True): super(Up, self).__init__() # å®šä¹‰äº†self.upçš„æ–¹æ³• if bilinear: self.up = nn.Upsample(scale_factor=2, mode=&#x27;bilinear&#x27;, align_corners=True) else: self.up = nn.ConvTranspose2d(in_ch // 2, in_ch // 2, 2, stride=2) # // é™¤ä»¥çš„ç»“æœå‘ä¸‹å–æ•´ self.conv = DoubleConv(in_ch, out_ch) def forward(self, x1, x2): # x2æ˜¯å·¦ä¾§çš„è¾“å‡ºï¼Œx1æ˜¯ä¸Šä¸€å¤§å±‚æ¥çš„è¾“å‡º x1 = self.up(x1) diffY = x2.size()[2] - x1.size()[2] diffX = x2.size()[3] - x1.size()[3] x1 = F.pad(x1, (diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2)) x = torch.cat([x2, x1], dim=1) # å°†ä¸¤ä¸ªtensoræ‹¼æ¥åœ¨ä¸€èµ· dim=1ï¼šåœ¨é€šé“æ•°ï¼ˆCï¼‰ä¸Šè¿›è¡Œæ‹¼æ¥ x = self.conv(x) return x# å®šä¹‰æœ€ç»ˆçš„è¾“å‡ºclass OutConv(nn.Module): def __init__(self, in_ch, out_ch): super(OutConv, self).__init__() self.conv = nn.Conv2d(in_ch, out_ch, 1) def forward(self, x): x = self.conv(x) return xclass Unet(nn.Module): def __init__(self, in_channels, classes): # in_channels å›¾ç‰‡çš„é€šé“æ•°ï¼Œ1ä¸ºç°åº¦å›¾ï¼Œ3ä¸ºå½©è‰²å›¾ super(Unet, self).__init__() self.n_channels = in_channels self.n_classes = classes self.inc = InConv(in_channels, 64) self.down1 = Down(64, 128) self.down2 = Down(128, 256) self.down3 = Down(256, 512) self.down4 = Down(512, 512) self.up1 = Up(1024, 256) self.up2 = Up(512, 128) self.up3 = Up(256, 64) self.up4 = Up(128, 64) self.outc = OutConv(64, classes) def forward(self, x): x1 = self.inc(x) x2 = self.down1(x1) x3 = self.down2(x2) x4 = self.down3(x3) x5 = self.down4(x4) x = self.up1(x5, x4) x = self.up2(x, x3) x = self.up3(x, x2) x = self.up4(x, x1) x = self.outc(x) return x","categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Code-åˆ†ç±»","slug":"Code-åˆ†ç±»","permalink":"http://example.com/tags/Code-%E5%88%86%E7%B1%BB/"}]},{"title":"PaperReading-ç”Ÿæˆå¯¹æŠ—ç½‘ç»œåœ¨åŒ»å­¦æˆåƒä¸­çš„åº”ç”¨ç»¼è¿°","slug":"paper_ç”Ÿæˆå¯¹æŠ—ç½‘ç»œåœ¨åŒ»å­¦æˆåƒä¸­çš„åº”ç”¨ç»¼è¿°","date":"2023-09-01T14:06:29.256Z","updated":"2024-06-13T02:43:16.122Z","comments":true,"path":"2023/09/01/paper_ç”Ÿæˆå¯¹æŠ—ç½‘ç»œåœ¨åŒ»å­¦æˆåƒä¸­çš„åº”ç”¨ç»¼è¿°/","link":"","permalink":"http://example.com/2023/09/01/paper_%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C%E5%9C%A8%E5%8C%BB%E5%AD%A6%E6%88%90%E5%83%8F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%E7%BB%BC%E8%BF%B0/","excerpt":"","text":"Generative adversarial network in medical imaging: A review 1.æ‘˜è¦ ç”Ÿæˆå¯¹æŠ—ç½‘ç»œç”±äºå…¶æ— éœ€æ˜ç¡®å»ºæ¨¡æ¦‚ç‡å¯†åº¦å‡½æ•°å³å¯ç”Ÿæˆæ•°æ®çš„èƒ½åŠ›è€Œåœ¨è®¡ç®—æœºè§†è§‰ç•Œå—åˆ°äº†å¹¿æ³›çš„å…³æ³¨ã€‚é‰´åˆ«å™¨å¸¦æ¥çš„å¯¹æŠ—æŸå¤±æä¾›äº†ä¸€ç§å·§å¦™çš„æ–¹æ³•ï¼Œå°†æœªæ ‡è®°çš„æ ·æœ¬æ•´åˆåˆ°è®­ç»ƒä¸­ï¼Œå¹¶å®ç°æ›´é«˜çš„é˜¶ä¸€è‡´æ€§ã€‚äº‹å®è¯æ˜ï¼Œè¿™åœ¨è®¸å¤šæƒ…å†µä¸‹éƒ½å¾ˆæœ‰ç”¨ï¼Œä¾‹å¦‚åŸŸé€‚åº”ã€æ•°æ®å¢å¼ºå’Œå›¾åƒåˆ°å›¾åƒçš„è½¬æ¢ã€‚è¿™äº›ç‰¹æ€§å¸å¼•äº†åŒ»å­¦å½±åƒç•Œçš„ç ”ç©¶äººå‘˜ï¼Œå¹¶åœ¨è®¸å¤šä¼ ç»Ÿå’Œæ–°å‹åº”ç”¨ä¸­å¾—åˆ°äº†è¿…é€Ÿçš„åº”ç”¨ï¼Œå¦‚å›¾åƒé‡å»ºã€åˆ†å‰²ã€æ£€æµ‹ã€åˆ†ç±»å’Œäº¤å‰æ¨¡æ€åˆæˆã€‚æ ¹æ®æˆ‘ä»¬çš„è§‚å¯Ÿï¼Œè¿™ä¸€è¶‹åŠ¿å°†ç»§ç»­ä¸‹å»ï¼Œå› æ­¤æˆ‘ä»¬å¯¹ä½¿ç”¨å¯¹æŠ—è®­ç»ƒæ–¹æ¡ˆçš„åŒ»å­¦æˆåƒçš„æœ€æ–°è¿›å±•è¿›è¡Œäº†å›é¡¾ï¼Œå¸Œæœ›èƒ½ä½¿å¯¹è¿™é¡¹æŠ€æœ¯æ„Ÿå…´è¶£çš„ç ”ç©¶äººå‘˜å—ç›Šã€‚ 2.å¼•è¨€ ä»2012å¹´å¼€å§‹ï¼Œéšç€æ·±åº¦å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„å¤å…´(Krizhevsky et al, 2012)ï¼Œæ·±åº¦å­¦ä¹ æ–¹æ³•åœ¨åŒ»å­¦æˆåƒé¢†åŸŸçš„åº”ç”¨æ€¥å‰§å¢åŠ ã€‚ ganæ˜¯ä¸€ç§ç‰¹æ®Šç±»å‹çš„ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œå®ƒåŒæ—¶è®­ç»ƒä¸¤ä¸ªç½‘ç»œï¼Œä¸€ä¸ªä¸“æ³¨äºå›¾åƒç”Ÿæˆï¼Œå¦ä¸€ä¸ªä¸“æ³¨äºè¯†åˆ«ã€‚ æ·±åº¦å­¦ä¹ çš„æ ¹æºå¯ä»¥è¿½æº¯åˆ°20ä¸–çºª80å¹´ä»£(Fukushima and Miyake, 1982)ï¼Œè€Œå¯¹æŠ—è®­ç»ƒçš„æ¦‚å¿µç›¸å¯¹è¾ƒæ–°ï¼Œæœ€è¿‘å–å¾—äº†é‡å¤§è¿›å±•(Goodfellow et al .ï¼Œ 2014)ã€‚æœ¬æ–‡ä»‹ç»äº†gançš„æ€»ä½“æ¦‚å†µï¼Œæè¿°äº†å®ƒä»¬åœ¨åŒ»å­¦æˆåƒä¸­çš„åº”ç”¨å‰æ™¯ï¼Œå¹¶ç¡®å®šäº†ä¸€äº›éœ€è¦è§£å†³çš„æŒ‘æˆ˜ï¼Œä»¥ä½¿å®ƒä»¬åœ¨å…¶ä»–åŒ»å­¦æˆåƒç›¸å…³ä»»åŠ¡ä¸­æˆåŠŸåº”ç”¨ ä¸ºäº†å…¨é¢æ¦‚è¿°ganåœ¨åŒ»å­¦æˆåƒæ–¹é¢çš„æ‰€æœ‰ç›¸å…³å·¥ä½œï¼Œæˆ‘ä»¬æ£€ç´¢äº†PubMedã€arXivâ€¦ æœ¬æ–‡çš„å…¶ä½™éƒ¨åˆ†ç»“æ„å¦‚ä¸‹â€¦ 3.è®ºæ–‡ç»“æ„ 2.èƒŒæ™¯ 2.1 Vanilla GAN 2.2 ä¼˜åŒ–gançš„æŒ‘æˆ˜ 2.3 gançš„å˜ä½“ 2.3.1 Dçš„å˜åŒ–ç›®æ ‡ 2.3.2 Gçš„å˜åŒ–ç›®æ ‡ 3.åœ¨åŒ»å­¦æˆåƒä¸­çš„åº”ç”¨ 3.1. é‡å»º 3.2 åŒ»å­¦å›¾åƒåˆæˆ 3.2.1 æ— æ¡ä»¶çš„åˆæˆ 3.2.2 äº¤å‰æ¨¡æ€åˆæˆ 3.2.3 å…¶ä»–æ¡ä»¶åˆæˆ 3.3 åˆ†å‰² 3.4 åˆ†ç±» 3.5 æ£€æµ‹ 3.6 é…å‡† 3.7 å…¶ä»–å·¥ä½œ 4.è®¨è®º 4.1 æœªæ¥çš„æŒ‘æˆ˜ 4.2 æœ‰è¶£çš„æœªæ¥åº”ç”¨ 4.æ–‡ç« ç¬”è®° GANå­˜åœ¨çš„é—®é¢˜ å¹¶ä¸èƒ½ä¿è¯Gå’ŒDçš„è®­ç»ƒåœ¨JSå‘æ•£çš„æƒ…å†µä¸‹è¾¾åˆ°å¹³è¡¡ã€‚å› æ­¤ï¼Œä¸€ä¸ªç½‘ç»œå¯èƒ½ä¸å¯é¿å…åœ°æ¯”å¦ä¸€ä¸ªç½‘ç»œæ›´å¼ºå¤§ï¼Œåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹æ˜¯Dã€‚å½“Då˜å¾—è¿‡äºå¼ºå¤§è€Œä¸æ˜¯Gæ—¶ï¼Œç”Ÿæˆçš„æ ·æœ¬å˜å¾—å¤ªå®¹æ˜“ä¸çœŸå®æ ·æœ¬åˆ†ç¦»ï¼Œä»è€Œè¾¾åˆ°Dçš„æ¢¯åº¦æ¥è¿‘äºé›¶çš„é˜¶æ®µï¼Œæ— æ³•ä¸ºGçš„è¿›ä¸€æ­¥è®­ç»ƒæä¾›æŒ‡å¯¼ã€‚ç”±äºéš¾ä»¥ç”Ÿæˆæœ‰æ„ä¹‰çš„é«˜é¢‘ç»†èŠ‚ï¼Œè¿™ç§æƒ…å†µåœ¨ç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒæ—¶æ›´å¸¸è§ã€‚ å¦ä¸€ä¸ªåœ¨è®­ç»ƒganæ—¶ç»å¸¸é‡åˆ°çš„é—®é¢˜æ˜¯æ¨¡æ€å´©æºƒï¼Œé¡¾åæ€ä¹‰ï¼Œæ¨¡æ€å´©æºƒæ˜¯æŒ‡Gå­¦ä¹ åˆ°çš„åˆ†å¸ƒé›†ä¸­åœ¨æ•°æ®åˆ†å¸ƒçš„å‡ ä¸ªæœ‰é™æ¨¡æ€ä¸Šã€‚å› æ­¤ï¼Œå®ƒäº§ç”Ÿçš„ä¸æ˜¯ä¸åŒçš„å›¾åƒï¼Œè€Œæ˜¯ä¸€ç»„æœ‰é™çš„æ ·æœ¬ã€‚","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Paper-åŒ»å­¦å½±åƒ","slug":"Paper-åŒ»å­¦å½±åƒ","permalink":"http://example.com/tags/Paper-%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F/"},{"name":"Paper-ç»¼è¿°æ–‡ç« ","slug":"Paper-ç»¼è¿°æ–‡ç« ","permalink":"http://example.com/tags/Paper-%E7%BB%BC%E8%BF%B0%E6%96%87%E7%AB%A0/"}]},{"title":"PaperReading-BPGAN-ä½¿ç”¨å…‰è°±å½’ä¸€åŒ–å’Œå®šä½çš„å¤šç”Ÿæˆå¤šå¯¹æŠ—ç½‘ç»œè¿›è¡ŒCT-MRIåŒå‘é¢„æµ‹","slug":"paper_BPGAN-ä½¿ç”¨å…‰è°±å½’ä¸€åŒ–å’Œå®šä½çš„å¤šç”Ÿæˆå¤šå¯¹æŠ—ç½‘ç»œè¿›è¡Œct-mriåŒå‘é¢„æµ‹","date":"2023-08-31T14:21:06.390Z","updated":"2024-06-12T15:57:54.671Z","comments":true,"path":"2023/08/31/paper_BPGAN-ä½¿ç”¨å…‰è°±å½’ä¸€åŒ–å’Œå®šä½çš„å¤šç”Ÿæˆå¤šå¯¹æŠ—ç½‘ç»œè¿›è¡Œct-mriåŒå‘é¢„æµ‹/","link":"","permalink":"http://example.com/2023/08/31/paper_BPGAN-%E4%BD%BF%E7%94%A8%E5%85%89%E8%B0%B1%E5%BD%92%E4%B8%80%E5%8C%96%E5%92%8C%E5%AE%9A%E4%BD%8D%E7%9A%84%E5%A4%9A%E7%94%9F%E6%88%90%E5%A4%9A%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C%E8%BF%9B%E8%A1%8Cct-mri%E5%8F%8C%E5%90%91%E9%A2%84%E6%B5%8B/","excerpt":"","text":"BPGAN: Bidirectional CT-to-MRI prediction using multi-generative multi-adversarial nets with spectral normalization and localization 1.æ‘˜è¦ ç£å…±æŒ¯æˆåƒ(MRI)å’Œè®¡ç®—æœºæ–­å±‚æ‰«æ(CT)æ˜¯å¹¿æ³›åº”ç”¨äºä¸´åºŠå’Œç ”ç©¶çš„ç­›æŸ¥ã€è¯Šæ–­å’Œå›¾åƒå¼•å¯¼æ²»ç–—çš„æ£€æµ‹æŠ€æœ¯ã€‚ç„¶è€Œï¼ŒCTåœ¨é‡‡é›†è¿‡ç¨‹ä¸­å¯¹æ‚£è€…æ–½åŠ ç”µç¦»è¾å°„ã€‚ä¸CTç›¸æ¯”ï¼ŒMRIæ›´å®‰å…¨ï¼Œæ²¡æœ‰ä»»ä½•è¾å°„ï¼Œä½†æ›´æ˜‚è´µï¼Œé‡‡é›†æ—¶é—´æ›´é•¿ã€‚å› æ­¤ï¼Œåœ¨æ”¾ç–—è§„åˆ’çš„æƒ…å†µä¸‹ï¼Œæœ‰å¿…è¦ä»åŒä¸€å—è¯•è€…çš„å¦ä¸€ä¸ªç»™å®šçš„æ¨¡æ€å›¾åƒä¸­ä¼°è®¡ä¸€ä¸ªæ¨¡æ€å›¾åƒã€‚è€ƒè™‘åˆ°ç›®å‰MRIå’ŒCTå›¾åƒä¹‹é—´æ²¡æœ‰åŒå‘é¢„æµ‹æ¨¡å‹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŒå‘é¢„æµ‹æ–¹æ³•ï¼Œå³ä½¿ç”¨å¤šç”Ÿæˆå¤šå¯¹æŠ—ç½‘ç»œ(BPGAN)ä»¥æˆå¯¹å’Œéæˆå¯¹çš„æ–¹å¼ä»å¦ä¸€æ¨¡æ€å›¾åƒä¸­é¢„æµ‹ä»»æ„æ¨¡æ€ã€‚åœ¨BPGANä¸­ï¼Œé‡‡ç”¨å¾ªç¯ä¸€è‡´æ€§ç­–ç•¥ï¼Œé€šè¿‡å°†ç›¸åŒçš„ç—…ç†ç‰¹å¾ä»ä¸€ä¸ªåŸŸæŠ•å°„åˆ°å¦ä¸€ä¸ªåŸŸæ¥å­¦ä¹ ä¸¤ä¸ªéçº¿æ€§æ˜ å°„ã€‚åœ¨æŠ€æœ¯ä¸Šï¼Œå¼•å…¥ç—…ç†å…ˆéªŒä¿¡æ¯æ¥çº¦æŸç‰¹å¾ç”Ÿæˆï¼Œä»¥æ”»å‡»ç—…ç†å˜å¼‚çš„æ½œåœ¨é£é™©ï¼Œå¹¶é‡‡ç”¨è¾¹ç¼˜ä¿ç•™åº¦é‡æ¥ä¿ç•™å‡ ä½•ç•¸å˜å’Œè§£å‰–ç»“æ„ã€‚åœ¨ç®—æ³•ä¸Šï¼Œè®¾è®¡äº†è°±å½’ä¸€åŒ–æ¥æ§åˆ¶é‰´åˆ«å™¨çš„æ€§èƒ½ï¼Œä½¿é¢„æµ‹å™¨æ›´å¥½æ›´å¿«åœ°å­¦ä¹ ;æå‡ºäº†å±€éƒ¨åŒ–æ¥å¯¹é¢„æµ‹å™¨æ–½åŠ æ­£åˆ™åŒ–ï¼Œä»¥å‡å°‘æ³›åŒ–è¯¯å·®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒBPGANæ¯”ç›®å‰æœ€å…ˆè¿›çš„æ–¹æ³•äº§ç”Ÿæ›´å¥½çš„é¢„æµ‹ã€‚å…¶ä¸­ï¼ŒBPGANåœ¨ä¸¤ä¸ªåŸºçº¿æ•°æ®é›†ä¸Šçš„MAEå’ŒSSIMçš„å¹³å‡å¢é‡åˆ†åˆ«ä¸º33.2%å’Œ37.4%ï¼ŒSSIMåˆ†åˆ«ä¸º24.5%å’Œ44.6% 2.å¼•è¨€ MRIå’ŒCTåœ¨å„ç§åŒ»ç–—ç—…ä¾‹ä¸­éƒ½æ˜¯é‡è¦çš„å’Œå¹¿æ³›åº”ç”¨çš„æŠ€æœ¯ã€‚ä¸MRIç›¸æ¯”ï¼ŒCTçš„æˆåƒæ—¶é—´æ›´çŸ­ï¼Œç©ºé—´åˆ†è¾¨ç‡æ›´é«˜ï¼Œé€‚ç”¨äºéª¨éª¼å’Œèƒ¸éƒ¨çš„æ£€æµ‹ã€‚ä½†CTè½¯ç»„ç»‡ä¿¡æ¯å¯¹æ¯”åº¦è¾ƒä½ã€‚è€ƒè™‘åˆ°ç”µç¦»è¾å°„å’ŒCTçš„ä¸åŒè€å—æ€§ï¼ŒMRIæ›´é€‚åˆæ­£ç”µå­å‘å°„æ–­å±‚æ‰«æ(PET)ä¸­çš„è¡°å‡æ ¡æ­£(AC)å’Œç°ä»£æ”¾ç–—æ²»ç–—è®¡åˆ’ä¸­çš„å‰‚é‡è®¡ç®—ï¼ŒMRIä¼˜è¶Šçš„è½¯ç»„ç»‡å¯¹æ¯”åº¦æœ‰åŠ©äºç²¾ç¡®æç»˜è‚¿ç˜¤å’Œå±é™©å™¨å®˜ã€‚ä½†MRIä»·æ ¼æ˜‚è´µï¼Œä¸”å‡ºäºæ‚£è€…èˆ’é€‚åº¦å’Œä¾ä»æ€§çš„è€ƒè™‘ï¼Œé‡‡é›†æ—¶é—´è¾ƒé•¿ï¼Œè€Œæ ‡å‡†çš„MRIå¼•å¯¼ä¸´åºŠæ²»ç–—åŒ…æ‹¬CTå’ŒMRIå›¾åƒçš„é‡‡é›†ã€‚å› æ­¤ï¼Œç”±ç›¸åº”çš„å’ŒçœŸå®çš„MRI/CTå›¾åƒå‡†ç¡®åˆæˆçš„æ— åä¼ªCT/MRIå›¾åƒ(pCT/pMRI)ï¼Œåœ¨æ— æ³•è·å¾—çœŸå®CT/MRIä¿¡æ¯çš„æƒ…å†µä¸‹ï¼Œåœ¨ä¸´åºŠåº”ç”¨ä¸­æ˜¯éå¸¸æœ‰ç”¨çš„ã€‚ ä¸ºäº†å‡å°‘ä¸å¿…è¦çš„ç”µç¦»å‰‚é‡å’Œæ‚£è€…çš„é¢å¤–è´¹ç”¨ï¼Œä¸´åºŠä¸Šéœ€è¦ä»å¦ä¸€ä¸ªæ¨¡æ€å›¾åƒä¸­ä¼°è®¡ä¸€ä¸ªæ¨¡æ€å›¾åƒã€‚åœ¨è¿™ä¸€éœ€æ±‚çš„å¯å‘ä¸‹ï¼Œäººä»¬æå‡ºäº†è®¸å¤šåˆ›æ–°æ€§çš„å•å‘é¢„æµ‹æ–¹æ³•ï¼Œä½†å®ç°è¿™ä¸€ç›®æ ‡ä»ç„¶å­˜åœ¨ä¸¤ä¸ªä¸»è¦æŒ‘æˆ˜ 1)å‡ ä¹æ‰€æœ‰çš„é¢„æµ‹ç®—æ³•éƒ½åªèƒ½è¿›è¡Œå•å‘é¢„æµ‹ï¼Œå³ä»ç»™å®šçš„MRIé¢„æµ‹pCTæˆ–ä»ç»™å®šçš„CTé¢„æµ‹pMRI 2)åœ¨åŒå‘é¢„æµ‹ä¸­ï¼Œé¢„æµ‹å™¨å¯èƒ½äº§ç”Ÿç›®æ ‡å›¾åƒä¸­æœªæ˜¾ç¤ºçš„ç‰¹å¾ï¼Œè¿™æ˜¯ä¸€ä¸ªæ½œåœ¨çš„é£é™©ã€‚ ä¸ºäº†è§£å†³è¿™ä¸¤ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ï¼Œéœ€è¦è§£å†³ä¸¤ä¸ªå­é—®é¢˜:é¦–å…ˆï¼Œå­¦ä¹ MRIå’ŒCTåŸŸä¹‹é—´çš„åŒå‘æ˜ å°„;å…¶æ¬¡ï¼Œé¢„æµ‹çš„ä¼ªMRIå’ŒCTæ‰€æè¿°çš„ç—…ç†ä¿¡æ¯åº”ä¸åŸå§‹å›¾åƒæ‰€æè¿°çš„ç—…ç†ä¿¡æ¯ç›¸åŒã€‚CycleGANå’Œconditional GANåœ¨è¿™ä¸¤ä¸ªå­é—®é¢˜ä¸Šå–å¾—äº†å·¨å¤§è¿›å±•ã€‚ç„¶è€Œï¼ŒCycleGANåœ¨å‡ ä½•å˜æ¢æ–¹é¢å­˜åœ¨å›ºæœ‰çš„æ¨¡ç³Šæ€§ã€‚ åŸºäºä»¥ä¸Šåˆ†æï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºå¤šç”Ÿæˆå¤šå¯¹æŠ—ç½‘ç»œ(BPGAN)çš„åŒå‘é¢„æµ‹æ–¹æ³•: (1) æå‡ºäº†ä¸€ç§æ–°çš„åŒå‘é¢„æµ‹æ–¹æ³•ï¼Œä»¥é…å¯¹å’Œä¸é…å¯¹çš„æ–¹å¼ä»å¦ä¸€ä¸ªç»™å®šæ¨¡æ€ä¸­é¢„æµ‹ä»»æ„æ¨¡æ€å›¾åƒï¼Œè¿™æ˜¯è·¨æ¨¡æ€é¢„æµ‹çš„ç¬¬ä¸€ä¸ªç«¯åˆ°ç«¯åŒå‘é¢„æµ‹æ¨¡å‹ã€‚ (2) å¼•å…¥ç—…ç†è¾…åŠ©ä¿¡æ¯çº¦æŸç‰¹å¾ç”Ÿæˆï¼Œæ‰“å‡»ç—…ç†å˜å¼‚çš„æ½œåœ¨é£é™©ï¼Œé‡‡ç”¨å±€éƒ¨é¢„æµ‹å™¨æ¶ˆé™¤é¢„æµ‹å™¨åæ±‚çš„çº¦æŸï¼Œæœç´¢ç»™å®šæ¨¡æ€å›¾åƒå¯¹åº”çš„å…¨å±€åæ ‡ï¼Œé™ä½æ³›åŒ–è¯¯å·®; (3) è®¾è®¡äº†è°±å½’ä¸€åŒ–æ¥æ§åˆ¶é‰´åˆ«å™¨çš„æ€§èƒ½ï¼Œä¿è¯äº†åœ¨æ§åˆ¶Lipschitzç•Œæ–¹é¢çš„ç†è®ºè®ºè¯ï¼Œåœ¨ç¨³å®šæ€§å’Œæ”¶æ•›æ€§æ–¹é¢åšå‡ºäº†é‡å¤§è´¡çŒ®; (4) æ›´å…¨é¢çš„è¯„ä»·ï¼ŒåŒ…æ‹¬å¯¹pCT/pMRIå½±åƒçš„å®¢è§‚è¯„ä»·å’Œå¯¹è¯Šæ–­è´¨é‡çš„ä¸»è§‚è¯„ä»·ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸»è§‚ä¸Šå’Œå®¢è§‚ä¸Šéƒ½å–å¾—äº†ä»¤äººæ»¡æ„çš„é¢„æµ‹ç»“æœã€‚ æœ¬æ–‡çš„å…¶ä½™éƒ¨åˆ†ç»„ç»‡å¦‚ä¸‹:â€¦ 3.æ€»ç»“ æå‡ºäº†ä¸€ç§åŸºäºé«˜æ–¯çš„äº¤å‰æ¨¡æ€åŒ»å­¦å›¾åƒåŒå‘é¢„æµ‹æ–¹æ¡ˆï¼Œè¯¥æ–¹æ¡ˆé‡‡ç”¨å¤šç”Ÿæˆå¤šå¯¹æŠ—ç½‘ç»œè¿›è¡Œå…‰è°±å½’ä¸€åŒ–å’Œå®šä½ã€‚ä¸ºäº†æ¶ˆé™¤ç—…ç†å˜å¼‚çš„æ½œåœ¨é£é™©ï¼Œåœ¨åŒä¸€ç±»ä¸­åŠ å…¥è¾…åŠ©ä¿¡æ¯æ¥ç”Ÿæˆç‰¹å¾ï¼Œå¹¶é‡‡ç”¨å±€éƒ¨å®šä½æ¥ç›´æ¥è®¿é—®å±€éƒ¨å‡ ä½•ï¼Œè€Œä¸æ˜¯åœ¨å…¨å±€GANä¸­åè½¬é¢„æµ‹å™¨ã€‚ç„¶ååˆ©ç”¨å…‰è°±å½’ä¸€åŒ–æ§åˆ¶é‰´åˆ«å™¨çš„æ€§èƒ½ï¼Œé—´æ¥æé«˜äº†é¢„æµ‹å›¾åƒçš„è´¨é‡ã€‚æ­¤å¤–ï¼Œè¾¹ç¼˜ä¿ç•™åº¦é‡ç”¨äºä¿ç•™è§£å‰–ç»“æ„ï¼Œæ€»å˜å¼‚æŸå¤±ç”¨äºæŠ‘åˆ¶è®­ç»ƒè¿‡ç¨‹ä¸­çš„å™ªå£°ã€‚æ€»çš„æ¥è¯´ï¼Œæ‰€æå‡ºçš„BPGANäº§ç”Ÿäº†æœ‰å¸Œæœ›çš„äº¤å‰æ¨¡æ€é¢„æµ‹ç»“æœã€‚ç‰¹åˆ«çš„æ˜¯ï¼Œå®ƒåœ¨åŸºå‡†ä¸Šä¼˜äº30% MAE, 20% SSIM, 20% FSIM, 50% MSIM, 15% GAN-trainå’Œ10% GAN-testçš„å¹³å‡å¢é‡ã€‚ç„¶åï¼Œä¸»ä»»åŒ»å¸ˆçš„ä¸“ä¸šè¯„ä¼°è¿›ä¸€æ­¥è¯æ˜BPGANäº§ç”Ÿäº†ä»¤äººä¿¡æœçš„è¯Šæ–­è´¨é‡ï¼Œè¿™ä¸å¹¿æ³›çš„å®šé‡è¯„ä¼°æ˜¯ä¸€è‡´çš„ã€‚ 4.æ–‡ç« ç¬”è®° ç—…ç†ä¸å˜æ€§ï¼š åœ¨ä¸´åºŠä¸Šï¼ŒåŒä¸€æ‚£è€…çš„åŒä¸€å™¨å®˜çš„ç—…ç†ä¿¡æ¯åœ¨é¢„æµ‹æ—¶åº”è¯¥æ˜¯ç›¸åŒçš„ï¼Œæœ¬æ–‡ç§°ä¹‹ä¸ºç—…ç†ä¸å˜æ€§ã€‚ CycleGANçš„ç¼ºç‚¹ CycleGAN (Zhu et al .ï¼Œ 2017)åœ¨å‡ ä½•å˜æ¢æ–¹é¢å­˜åœ¨å›ºæœ‰çš„æ¨¡ç³Šæ€§ã€‚å…·ä½“æ¥è¯´ï¼ŒCycleGANä¸­å¾ªç¯ä¸€è‡´æ€§çš„æ ¸å¿ƒæ˜¯ä¿è¯GA(GB(x))â†’xå’ŒGB(GA(y))â†’yï¼Œä½†GB(x)â†’yå’ŒGA(y)â†’xä¸èƒ½ä¿è¯å‡ ä½•ç•¸å˜ï¼Œå®ƒä»¬æ˜¯å®Œå…¨é¢„æœŸçš„ã€‚ è°±å½’ä¸€åŒ– å½’ä¸€åŒ–ï¼ˆSpectral Normalizationï¼‰æ˜¯ä¸€ç§åœ¨ç¥ç»ç½‘ç»œä¸­å¸¸ç”¨çš„æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œæ—¨åœ¨ç¨³å®šå’Œæ”¹è¿›ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰å’Œå…¶ä»–æ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ã€‚åœ¨è°±å½’ä¸€åŒ–ä¸­ï¼Œæƒé‡çŸ©é˜µçš„æ¯ä¸€è¡Œéƒ½è¢«çº¦æŸåœ¨å•ä½çƒï¼ˆL2 èŒƒæ•°ä¸º1çš„çƒï¼‰ä¸Šã€‚è¿™æ ·åšçš„ç›®çš„æ˜¯é€šè¿‡é™åˆ¶æƒé‡çš„èŒƒå›´æ¥æ§åˆ¶æ¨¡å‹çš„å¤æ‚åº¦ï¼Œå¹¶æé«˜æ¨¡å‹çš„æ³›åŒ–æ€§èƒ½ã€‚è°±å½’ä¸€åŒ–çš„ä¸»è¦æ­¥éª¤æ˜¯é€šè¿‡è®¡ç®—æƒé‡çŸ©é˜µçš„ç‰¹å¾å€¼åˆ†è§£æ¥ä¼°è®¡æƒé‡çŸ©é˜µçš„æœ€å¤§å¥‡å¼‚å€¼ï¼ˆspectral normï¼‰ã€‚ç„¶åå°†æƒé‡çŸ©é˜µé™¤ä»¥æœ€å¤§å¥‡å¼‚å€¼ä»¥è¿›è¡Œå½’ä¸€åŒ–ã€‚è¿™å¯ä»¥é€šè¿‡è¿­ä»£å¹‚æ³•ï¼ˆpower iterationï¼‰æ¥å®ç°ï¼Œè¿­ä»£å¹‚æ³•é€šè¿‡å¤šæ¬¡è¿­ä»£æƒé‡çŸ©é˜µå’Œå…¶è½¬ç½®çŸ©é˜µçš„ä¹˜ç§¯æ¥é€æ¸é€¼è¿‘æœ€å¤§å¥‡å¼‚å€¼ã€‚è°±å½’ä¸€åŒ–çš„ä¼˜ç‚¹åŒ…æ‹¬ï¼š (1)æ”¹å–„æ¨¡å‹çš„ç¨³å®šæ€§ï¼šé€šè¿‡é™åˆ¶æƒé‡çŸ©é˜µçš„èŒƒå›´ï¼Œè°±å½’ä¸€åŒ–å¯ä»¥é™ä½æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ¢¯åº¦çˆ†ç‚¸å’Œæ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œä»è€Œæé«˜æ¨¡å‹çš„ç¨³å®šæ€§ã€‚ (2)æé«˜ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰çš„è®­ç»ƒæ•ˆæœï¼šè°±å½’ä¸€åŒ–åœ¨ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ç½‘ç»œä¸­åº”ç”¨å¹¿æ³›ï¼Œå¯ä»¥ä½¿GANsçš„è®­ç»ƒæ›´åŠ ç¨³å®šï¼Œç”Ÿæˆçš„æ ·æœ¬è´¨é‡æ›´é«˜ã€‚ (3)ä¸å¢åŠ é¢å¤–çš„æ¨¡å‹å‚æ•°ï¼šä¸å…¶ä»–æ­£åˆ™åŒ–æ–¹æ³•ï¼ˆå¦‚æƒé‡è¡°å‡ï¼‰ç›¸æ¯”ï¼Œè°±å½’ä¸€åŒ–ä¸éœ€è¦å¼•å…¥é¢å¤–çš„è¶…å‚æ•°æˆ–è°ƒæ•´æƒé‡è¡°å‡ç³»æ•°ï¼Œå› æ­¤æ›´æ˜“äºä½¿ç”¨ã€‚ æ€»ä¹‹ï¼Œè°±å½’ä¸€åŒ–æ˜¯ä¸€ç§ç”¨äºæ­£åˆ™åŒ–ç¥ç»ç½‘ç»œçš„æŠ€æœ¯ï¼Œé€šè¿‡é™åˆ¶æƒé‡çŸ©é˜µçš„è°±èŒƒæ•°æ¥æé«˜æ¨¡å‹çš„ç¨³å®šæ€§å’Œæ³›åŒ–æ€§èƒ½ã€‚å®ƒåœ¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œå’Œå…¶ä»–æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­å…·æœ‰é‡è¦çš„åº”ç”¨ä»·å€¼ã€‚ å‡ ç§æŸå¤±: åŒå‘æ¡ä»¶å¯¹æŠ—æ€§æŸå¤±(Bidirectional conditional adversarial loss): è¾¹ç¼˜ä¿æŒæŸå¤±(Edge retention loss):Edge retention lossæ˜¯ä¸€ç§ç”¨äºä¿ç•™åŒ»å­¦å›¾åƒä¸­è¾¹ç¼˜ä¿¡æ¯çš„æŸå¤±å‡½æ•°ï¼Œå®ƒè¢«ç”¨äºè¿™ç¯‡è®ºæ–‡ä¸­çš„åŒ»å­¦å›¾åƒé…å‡†ä»»åŠ¡ã€‚åœ¨åŒ»å­¦å›¾åƒé…å‡†ä»»åŠ¡ä¸­ï¼Œä¿ç•™è¾¹ç¼˜ä¿¡æ¯å¯¹äºä¿æŒå›¾åƒçš„è§£å‰–ç»“æ„éå¸¸é‡è¦ï¼Œå› ä¸ºå®ƒå¯ä»¥å¸®åŠ©åŒ»ç”Ÿæ›´å‡†ç¡®åœ°è¯Šæ–­å’Œæ²»ç–—ç–¾ç—…ã€‚å…·ä½“æ¥è¯´ï¼ŒEdge retention lossçš„è®¡ç®—æ–¹å¼æ˜¯é€šè¿‡è®¡ç®—ç”Ÿæˆçš„å›¾åƒä¸çœŸå®å›¾åƒä¹‹é—´çš„è¾¹ç¼˜ä¿¡æ¯çš„å·®å¼‚æ¥å®ç°çš„ã€‚è¾¹ç¼˜ä¿¡æ¯å¯ä»¥é€šè¿‡è®¡ç®—å›¾åƒçš„æ¢¯åº¦æ¥è·å¾—ï¼Œå› ä¸ºæ¢¯åº¦å¯ä»¥åæ˜ å›¾åƒä¸­åƒç´ å€¼çš„å˜åŒ–ã€‚åœ¨è¿™ç¯‡è®ºæ–‡ä¸­ï¼ŒMatting LaplaciançŸ©é˜µè¢«ç”¨äºè®¡ç®—å›¾åƒçš„æ¢¯åº¦ï¼Œå› ä¸ºå®ƒå¯ä»¥å¸®åŠ©ä¿ç•™å›¾åƒä¸­çš„è¾¹ç¼˜ä¿¡æ¯ã€‚é€šè¿‡è®¡ç®—ç”Ÿæˆçš„å›¾åƒä¸çœŸå®å›¾åƒä¹‹é—´çš„è¾¹ç¼˜ä¿¡æ¯çš„å·®å¼‚ã€‚ å†…å®¹æŸå¤±ï¼ˆContent Lossï¼‰ åœ¨CNNç½‘ç»œä¸­ï¼Œä¸€èˆ¬è®¤ä¸ºè¾ƒä½å±‚çš„ç‰¹å¾æè¿°äº†å›¾åƒçš„å…·ä½“è§†è§‰ç‰¹å¾ï¼ˆå³çº¹ç†ã€é¢œè‰²ç­‰ï¼‰ï¼Œè¾ƒé«˜å±‚çš„ç‰¹å¾åˆ™æ˜¯è¾ƒä¸ºæŠ½è±¡çš„å›¾åƒå†…å®¹æè¿°ã€‚æ‰€ä»¥è¦æ¯”è¾ƒä¸¤å¹…å›¾åƒçš„å†…å®¹ç›¸ä¼¼æ€§ï¼Œå¯ä»¥æ¯”è¾ƒä¸¤å¹…å›¾åƒåœ¨CNNç½‘ç»œä¸­é«˜å±‚ç‰¹å¾çš„ç›¸ä¼¼æ€§ï¼ˆæ¬§å¼è·ç¦»ï¼‰ã€‚ é£æ ¼æŸå¤±ï¼ˆStyle Lossï¼‰ è€Œè¦æ¯”è¾ƒä¸¤å¹…å›¾åƒçš„é£æ ¼ç›¸ä¼¼æ€§ï¼Œåˆ™å¯ä»¥æ¯”è¾ƒå®ƒä»¬åœ¨CNNç½‘ç»œä¸­è¾ƒä½å±‚ç‰¹å¾çš„ç›¸ä¼¼æ€§ã€‚ä¸è¿‡å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä¸èƒ½åƒå†…å®¹ç›¸ä¼¼æ€§è®¡ç®—ä¸€æ ·ï¼Œç®€å•çš„é‡‡ç”¨æ¬§å¼è·ç¦»åº¦é‡ï¼Œå› ä¸ºä½å±‚ç‰¹å¾åŒ…å«è¾ƒå¤šçš„å›¾åƒå±€éƒ¨ç‰¹å¾ï¼ˆå³ç©ºé—´ä¿¡æ¯è¿‡äºæ˜¾è‘—ï¼‰ï¼Œæ¯”å¦‚ä¸¤å¹…é£æ ¼ç›¸ä¼¼ä½†å†…å®¹å®Œå…¨ä¸åŒçš„å›¾åƒï¼Œè‹¥ç›´æ¥è®¡ç®—å®ƒä»¬çš„æ¬§å¼è·ç¦»ï¼Œåˆ™å¯èƒ½ä¼šäº§ç”Ÿè¾ƒå¤§çš„è¯¯å·®ï¼Œè®¤ä¸ºå®ƒä»¬é£æ ¼ä¸ç›¸ä¼¼ã€‚è®ºæ–‡ä¸­ä½¿ç”¨äº†GramçŸ©é˜µï¼Œç”¨äºè®¡ç®—ä¸åŒå“åº”å±‚ä¹‹é—´çš„è”ç³»ï¼Œå³åœ¨ä¿ç•™ä½å±‚ç‰¹å¾çš„åŒæ—¶å»é™¤å›¾åƒå†…å®¹çš„å½±å“ï¼Œåªæ¯”è¾ƒé£æ ¼çš„ç›¸ä¼¼æ€§ã€‚ æ„ŸçŸ¥æŸå¤±perceptual lossï¼ˆVGGæŸå¤±ï¼‰ å¯¹äºå›¾åƒé£æ ¼åŒ–ï¼Œå›¾åƒè¶…åˆ†è¾¨ç‡é‡å»ºç­‰ä»»åŠ¡æ¥è¯´ï¼Œæ—©æœŸéƒ½ä½¿ç”¨äº†å›¾åƒåƒç´ ç©ºé—´çš„L2 lossï¼Œä½†æ˜¯L2 lossä¸äººçœ¼æ„ŸçŸ¥çš„å›¾åƒè´¨é‡å¹¶ä¸åŒ¹é…ï¼Œæ¢å¤å‡ºæ¥çš„å›¾åƒå¾€å¾€ç»†èŠ‚è¡¨ç°ä¸å¥½ã€‚ ç°åœ¨çš„ç ”ç©¶ä¸­ï¼ŒL2 lossé€æ­¥è¢«äººçœ¼æ„ŸçŸ¥lossæ‰€å–ä»£ã€‚äººçœ¼æ„ŸçŸ¥lossä¹Ÿè¢«ç§°ä¸ºperceptual lossï¼ˆæ„ŸçŸ¥æŸå¤±ï¼‰ï¼Œå®ƒä¸MSEï¼ˆL2æŸå¤±ï¼‰é‡‡ç”¨å›¾åƒåƒç´ è¿›è¡Œæ±‚å·®çš„ä¸åŒä¹‹å¤„åœ¨äºæ‰€è®¡ç®—çš„ç©ºé—´ä¸å†æ˜¯å›¾åƒç©ºé—´ã€‚ ç ”ç©¶è€…ä»¬å¸¸ä½¿ç”¨VGGç­‰ç½‘ç»œçš„ç‰¹å¾ï¼Œä»¤Ï†æ¥è¡¨ç¤ºæŸå¤±ç½‘ç»œï¼ŒCjè¡¨ç¤ºç½‘ç»œçš„ç¬¬jå±‚ï¼ŒCjHjWjè¡¨ç¤ºç¬¬jå±‚çš„ç‰¹å¾å›¾çš„å¤§å°ï¼Œæ„ŸçŸ¥æŸå¤±çš„å®šä¹‰ä¸L2 lossåŒæ ·çš„å½¢å¼ï¼Œåªæ˜¯è®¡ç®—çš„ç©ºé—´è¢«è½¬æ¢åˆ°äº†ç‰¹å¾ç©ºé—´ã€‚ TV Loss(Total Variation Loss) å…¨åä¸ºæ€»å˜åˆ†æŸå¤±å‡½æ•°ï¼ŒTV Lossä½œä¸ºä¸€ç§æ­£åˆ™é¡¹é…åˆæŸå¤±å‡½æ•°å»è°ƒèŠ‚ç½‘ç»œå­¦ä¹ ã€‚ å³æ±‚æ¯ä¸€ä¸ªåƒç´ ä¸å…¶ä¸‹æ–¹åƒç´ å’Œå³æ–¹åƒç´ çš„å·®çš„å¹³æ–¹ç›¸åŠ å†å¼€æ ¹å·çš„å’Œã€‚ TVå€¼å’Œå™ªå£°æ˜¯çº¿æ€§ç›¸å…³çš„ï¼Œå™ªå£°è¶Šå¤§TVå€¼ä¹Ÿä¼šè¶Šå¤§ï¼Œæ‰€ä»¥TVå€¼å¯ä»¥ä½œä¸ºåœ¨å›¾åƒå¤åŸæˆ–è¶…åˆ†è¾¨ç­‰ä»»åŠ¡ä¸­çš„ä¸€ç§æŒ‡å¯¼æ­£ä¾§é¡¹ï¼ŒTVlossè¶Šå°åˆ™å›¾åƒå™ªå£°è¶Šå°ï¼Œå›¾åƒæ›´åŠ å¹³æ»‘ã€‚","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Paper-åŒ»å­¦å½±åƒ","slug":"Paper-åŒ»å­¦å½±åƒ","permalink":"http://example.com/tags/Paper-%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F/"}]},{"title":"PaperReading-åŒ»å­¦å½±åƒä¸­çš„æ‰©æ•£æ¨¡å‹:ç»¼åˆç»¼è¿°","slug":"paper_åŒ»å­¦å½±åƒä¸­çš„æ‰©æ•£æ¨¡å‹ ç»¼åˆç»¼è¿°","date":"2023-08-31T14:15:40.207Z","updated":"2024-05-22T02:27:56.921Z","comments":true,"path":"2023/08/31/paper_åŒ»å­¦å½±åƒä¸­çš„æ‰©æ•£æ¨¡å‹ ç»¼åˆç»¼è¿°/","link":"","permalink":"http://example.com/2023/08/31/paper_%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E4%B8%AD%E7%9A%84%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%20%E7%BB%BC%E5%90%88%E7%BB%BC%E8%BF%B0/","excerpt":"","text":"DIFFUSION MODELS IN MEDICAL IMAGING: A COMPREHENSIVE SURVEY 1.æ‘˜è¦ å»å™ªæ‰©æ•£æ¨¡å‹æ˜¯ä¸€ç±»ç”Ÿæˆæ¨¡å‹ï¼Œæœ€è¿‘åœ¨å„ç§æ·±åº¦å­¦ä¹ é—®é¢˜ä¸­å¼•èµ·äº†æå¤§çš„å…´è¶£ã€‚æ‰©æ•£æ¦‚ç‡æ¨¡å‹å®šä¹‰äº†ä¸€ä¸ªæ­£å‘æ‰©æ•£é˜¶æ®µï¼Œåœ¨è¿™ä¸ªé˜¶æ®µä¸­ï¼Œè¾“å…¥æ•°æ®é€šè¿‡åŠ å…¥é«˜æ–¯å™ªå£°åœ¨å‡ ä¸ªæ­¥éª¤ä¸­é€æ¸å—åˆ°æ‰°åŠ¨ï¼Œç„¶åå­¦ä¹ åå‘æ‰©æ•£è¿‡ç¨‹ä»¥ä»æœ‰å™ªå£°çš„æ•°æ®æ ·æœ¬ä¸­æ¢å¤æ‰€éœ€çš„æ— å™ªå£°æ•°æ®ã€‚æ‰©æ•£æ¨¡å‹å› å…¶å¼ºå¤§çš„é£æ ¼è¦†ç›–å’Œç”Ÿæˆæ ·æœ¬çš„è´¨é‡è€Œå¹¿å—æ¬¢è¿ï¼Œå°½ç®¡å®ƒä»¬å·²çŸ¥çš„è®¡ç®—è´Ÿæ‹…ã€‚åˆ©ç”¨è®¡ç®—æœºè§†è§‰çš„è¿›æ­¥ï¼ŒåŒ»å­¦æˆåƒé¢†åŸŸä¹Ÿè¢«è§‚å¯Ÿåˆ°å¯¹æ‰©æ•£æ¨¡å‹çš„å…´è¶£æ—¥ç›Šå¢é•¿ã€‚ä¸ºäº†å¸®åŠ©ç ”ç©¶äººå‘˜æµè§ˆè¿™ä¸€ä¸°å¯Œçš„å†…å®¹ï¼Œæœ¬è°ƒæŸ¥æ—¨åœ¨æä¾›åŒ»å­¦æˆåƒå­¦ç§‘ä¸­æ‰©æ•£æ¨¡å‹çš„å…¨é¢æ¦‚è¿°ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆä»‹ç»æ‰©æ•£æ¨¡å‹å’Œä¸‰ç§é€šç”¨æ‰©æ•£å»ºæ¨¡æ¡†æ¶(å³æ‰©æ•£æ¦‚ç‡æ¨¡å‹ã€å™ªå£°æ¡ä»¶è¯„åˆ†ç½‘ç»œå’Œéšæœºå¾®åˆ†æ–¹ç¨‹)èƒŒåçš„åšå®ç†è®ºåŸºç¡€å’ŒåŸºæœ¬æ¦‚å¿µã€‚ç„¶åï¼Œæˆ‘ä»¬å¯¹åŒ»å­¦é¢†åŸŸçš„æ‰©æ•£æ¨¡å‹è¿›è¡Œäº†ç³»ç»Ÿçš„åˆ†ç±»ï¼Œå¹¶æå‡ºäº†åŸºäºå…¶åº”ç”¨ï¼Œæˆåƒæ–¹å¼ï¼Œæ„Ÿå…´è¶£çš„å™¨å®˜å’Œç®—æ³•çš„å¤šè§†è§’åˆ†ç±»ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ¶µç›–äº†æ‰©æ•£æ¨¡å‹åœ¨åŒ»å­¦é¢†åŸŸçš„å¹¿æ³›åº”ç”¨ï¼ŒåŒ…æ‹¬å›¾åƒåˆ°å›¾åƒçš„è½¬æ¢ã€é‡å»ºã€é…å‡†ã€åˆ†ç±»ã€åˆ†å‰²ã€å»å™ªã€2/3Dç”Ÿæˆã€å¼‚å¸¸æ£€æµ‹å’Œå…¶ä»–ä¸åŒ»å­¦ç›¸å…³çš„æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼ºè°ƒäº†ä¸€äº›é€‰å®šæ–¹æ³•çš„å®é™…ç”¨ä¾‹ï¼Œç„¶åè®¨è®ºäº†æ‰©æ•£æ¨¡å‹åœ¨åŒ»å­¦é¢†åŸŸçš„å±€é™æ€§ï¼Œå¹¶æå‡ºäº†æ»¡è¶³è¯¥é¢†åŸŸéœ€æ±‚çš„å‡ ä¸ªæ–¹å‘ã€‚æœ€åï¼Œæˆ‘ä»¬åœ¨GitHubä¸Šæ”¶é›†äº†æ¦‚è¿°çš„ç ”ç©¶åŠå…¶å¯ç”¨çš„å¼€æºå®ç°ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯å®šæœŸæ›´æ–°å…¶ä¸­çš„ç›¸å…³æœ€æ–°è®ºæ–‡ã€‚ 2.å¼•è¨€ ï¼ˆ1ï¼‰åœ¨è¿‡å»åå¹´ä¸­ï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œçš„ç”Ÿæˆå»ºæ¨¡ä¸€ç›´æ˜¯æ·±åº¦å­¦ä¹ çš„ä¸»å¯¼åŠ›é‡ã€‚è‡ªå…¶å‡ºç°ä»¥æ¥ï¼Œç”Ÿæˆæ¨¡å‹åœ¨å›¾åƒã€éŸ³é¢‘ã€æ–‡æœ¬å’Œç‚¹äº‘ç­‰å„ä¸ªé¢†åŸŸäº§ç”Ÿäº†å·¨å¤§çš„å½±å“ã€‚ï¼ˆ2ï¼‰åœ¨è¿‡å»çš„å‡ å¹´é‡Œï¼Œç”±äºä¸€èˆ¬æ·±åº¦å­¦ä¹ æ¶æ„çš„å‘å±•ï¼Œäººä»¬å¯¹ç”Ÿæˆæ¨¡å‹çš„å…´è¶£é‡æ–°ç‡ƒèµ·ï¼Œæ­ç¤ºäº†è§†è§‰ä¿çœŸåº¦å’Œé‡‡æ ·é€Ÿåº¦çš„æé«˜ã€‚å…·ä½“æ¥è¯´ï¼Œå·²ç»å‡ºç°äº†ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GANs)ã€å˜åˆ†è‡ªç¼–ç å™¨(VAEs)å’Œå½’ä¸€åŒ–æµã€‚é™¤æ­¤ä¹‹å¤–ï¼ŒåŸºäºæ‰©æ•£è¿‡ç¨‹çš„ç”Ÿæˆæ¨¡å‹ä¸ºç°æœ‰çš„VAEsã€EBMsã€ganå’Œè§„èŒƒåŒ–æµæä¾›äº†ä¸€ç§æ›¿ä»£æ–¹æ¡ˆï¼Œè¿™äº›æ¨¡å‹ä¸éœ€è¦å¯¹åéªŒåˆ†å¸ƒè¿›è¡Œå¯¹é½ã€ä¼°è®¡éš¾ä»¥å¤„ç†çš„é…åˆ†å‡½æ•°ã€å¼•å…¥é¢å¤–çš„åˆ¤åˆ«å™¨ç½‘ç»œæˆ–åˆ†åˆ«æ”¾ç½®ç½‘ç»œçº¦æŸã€‚ï¼ˆ3ï¼‰è¿„ä»Šä¸ºæ­¢ï¼Œå·²ç»å‘ç°æ‰©æ•£æ¨¡å‹åœ¨è®¸å¤šé¢†åŸŸéƒ½å¾ˆæœ‰ç”¨ï¼Œä»ç”Ÿæˆå»ºæ¨¡ä»»åŠ¡(å¦‚å›¾åƒç”Ÿæˆã€å›¾åƒè¶…åˆ†è¾¨ç‡ã€å›¾åƒç»˜åˆ¶)åˆ°åˆ¤åˆ«ä»»åŠ¡(å¦‚å›¾åƒåˆ†å‰²ã€åˆ†ç±»å’Œå¼‚å¸¸æ£€æµ‹)ã€‚ï¼ˆ4ï¼‰æœ€è¿‘ï¼ŒåŒ»å­¦å½±åƒé¢†åŸŸåŸºäºæ‰©æ•£çš„æŠ€æœ¯æ•°é‡å‘ˆæŒ‡æ•°çº§å¢é•¿ã€‚æˆ‘ä»¬çš„ä¸»è¦è´¡çŒ®åŒ…æ‹¬: 1ï¼‰æ˜¯ç¬¬ä¸€ç¯‡å…¨é¢æ¶µç›–æ‰©æ•£æ¨¡å‹åœ¨åŒ»å­¦æˆåƒé¢†åŸŸåº”ç”¨çš„è°ƒæŸ¥è®ºæ–‡ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†å…¨é¢æ¦‚è¿°æ‰€æœ‰å¯ç”¨çš„ç›¸å…³è®ºæ–‡(ç›´åˆ°2022å¹´10æœˆ)ï¼Œå¹¶å±•ç¤º2023å¹´4æœˆä¹‹å‰çš„ä¸€äº›æœ€æ–°æŠ€æœ¯ã€‚ 2ï¼‰æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªåŒ»å­¦ç•Œæ‰©æ•£æ¨¡å‹çš„å¤šè§†è§’åˆ†ç±»ï¼Œä¸ºæ‰©æ•£æ¨¡å‹åŠå…¶åº”ç”¨çš„ç ”ç©¶æä¾›äº†ä¸€ä¸ªç³»ç»Ÿçš„åˆ†ç±»ã€‚æˆ‘ä»¬å°†ç°æœ‰çš„æ‰©æ•£æ¨¡å‹åˆ†ä¸ºä¸¤ç±»:åŸºäºå˜åˆ†çš„æ¨¡å‹å’ŒåŸºäºåˆ†æ•°çš„æ¨¡å‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†æ‰©æ•£æ¨¡å‹çš„åº”ç”¨åˆ†ä¸ºä¹ç±»:å›¾åƒåˆ°å›¾åƒçš„ç¿»è¯‘ã€é‡å»ºã€é…å‡†ã€åˆ†ç±»ã€åˆ†å‰²ã€å»å™ªã€å›¾åƒç”Ÿæˆã€å¼‚å¸¸æ£€æµ‹å’Œå…¶ä»–åº”ç”¨ã€‚ 3ï¼‰æˆ‘ä»¬æ²¡æœ‰å°†æ³¨æ„åŠ›é™åˆ¶åœ¨åº”ç”¨ä¸Šï¼Œå¹¶æä¾›äº†ä¸€ä¸ªæ–°çš„åˆ†ç±»æ³•ï¼Œå…¶ä¸­æ¯ç¯‡è®ºæ–‡åˆ†åˆ«æ ¹æ®æ‰€æå‡ºçš„ç®—æ³•ä»¥åŠç›¸å…³å™¨å®˜å’Œæˆåƒæ–¹å¼è¿›è¡Œäº†å¹¿æ³›çš„åˆ†ç±»ã€‚ 3ï¼‰æœ€åï¼Œæˆ‘ä»¬è®¨è®ºäº†æŒ‘æˆ˜å’Œå¼€æ”¾çš„é—®é¢˜ï¼Œå¹¶ç¡®å®šäº†æ–°çš„è¶‹åŠ¿ï¼Œæå‡ºäº†å…³äºæ‰©æ•£æ¨¡å‹åœ¨åŒ»ç–—é¢†åŸŸçš„ç®—æ³•å’Œåº”ç”¨çš„æœªæ¥å‘å±•çš„å¼€æ”¾é—®é¢˜ æœ¬æ¬¡è°ƒæŸ¥çš„åŠ¨æœºå’Œç‹¬ç‰¹æ€§ã€‚ç”Ÿæˆæ–¹æ³•åœ¨åŒ»å­¦æˆåƒé¢†åŸŸå–å¾—äº†é‡å¤§è¿›å±•ï¼Œå…¶ä¸­ä¸€äº›è®ºæ–‡åªå…³æ³¨ç‰¹å®šçš„åº”ç”¨ï¼Œè€Œå¦ä¸€äº›åˆ™ä¸“æ³¨äºç‰¹å®šçš„å›¾åƒå½¢æ€ã€‚å°½ç®¡åœ¨è¿™ä¸€é¢†åŸŸå¾—åˆ°å……åˆ†å‘å±•ä¹‹å‰å°±å·²ç»å‘è¡¨äº†ç»¼è¿°æ–‡ç« ï¼Œä½†è‡ªé‚£æ—¶ä»¥æ¥ï¼ŒåŒ»å­¦é¢†åŸŸå·²ç»å–å¾—äº†è®¸å¤šè¿›å±•ã€‚å¦ä¸€æ–¹é¢ï¼Œè¿™äº›è°ƒæŸ¥éƒ½æ²¡æœ‰å…³æ³¨æ‰©æ•£æ¨¡å‹åœ¨åŒ»å­¦æˆåƒä¸­çš„åº”ç”¨ï¼Œè¿™æ˜¯æ¨åŠ¨è¿™ä¸€ç ”ç©¶æ–¹å‘å‘å‰å‘å±•çš„æ ¸å¿ƒæ–¹é¢ã€‚å› æ­¤ï¼Œè¿™äº›è°ƒæŸ¥ç•™ä¸‹äº†æ˜æ˜¾çš„ç©ºç™½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ç›¸ä¿¡åŒ»å­¦ç•Œå¯ä»¥é€šè¿‡å›é¡¾æˆ‘ä»¬çš„è°ƒæŸ¥æä¾›çš„æ‰©æ•£æ¨¡å‹çš„è¿‡å»å’Œæœªæ¥çš„ç ”ç©¶æ–¹å‘ï¼Œä»è§†è§‰æ‰©æ•£æ¨¡å‹çš„æˆåŠŸäº§å“ä¸­è·å¾—å¯ç¤ºã€‚ æœç´¢ç­–ç•¥ã€‚æˆ‘ä»¬æœç´¢äº†DBLPã€Google Scholarå’ŒArxiv Sanity Preserverï¼Œä½¿ç”¨å®šåˆ¶çš„æœç´¢æŸ¥è¯¢ï¼Œå› ä¸ºå®ƒä»¬å…è®¸å®šåˆ¶æœç´¢æŸ¥è¯¢ï¼Œå¹¶æä¾›æ‰€æœ‰å­¦æœ¯å‡ºç‰ˆç‰©çš„åˆ—è¡¨:åŒè¡Œè¯„è®®çš„æœŸåˆŠè®ºæ–‡æˆ–åœ¨ä¼šè®®æˆ–ç ”è®¨ä¼šè®ºæ–‡é›†ä¸­å‘è¡¨çš„è®ºæ–‡ï¼ŒéåŒè¡Œè¯„è®®çš„è®ºæ–‡å’Œé¢„å°æœ¬ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬æ ¹æ®å¯¹å…¶æ–°é¢–æ€§ã€è´¡çŒ®ã€æ„ä¹‰çš„ä»”ç»†è¯„ä¼°ï¼Œä»¥åŠæ˜¯å¦ä¸ºåŒ»å­¦æˆåƒé¢†åŸŸçš„ç¬¬ä¸€ç¯‡ä»‹ç»è®ºæ–‡ï¼Œé€‰æ‹©äº†è®ºæ–‡è¿›è¡Œè¯¦ç»†æ£€æŸ¥ã€‚ è®ºæ–‡çš„ç»„ç»‡ã€‚ 3.è®ºæ–‡ç»“æ„ ç†è®º 2.1 æ‰©æ•£æ¨¡å‹åœ¨å“ªé‡Œé€‚åˆç”Ÿæˆå¼å­¦ä¹ ? 2.2 å˜åˆ†è§†è§’ 2.2.1 å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹(ddpm) 2.3 åˆ†æ•°è§†è§’ 2.3.1 å™ªå£°æ¡ä»¶è¯„åˆ†ç½‘ç»œ(ncsn) 2.3.2 éšæœºå¾®åˆ†æ–¹ç¨‹(SDEs) ä¸´åºŠé‡è¦æ€§ åº”ç”¨ä¸­çš„æ‰©æ•£æ¨¡å‹ 4.1 å›¾åƒåˆ°å›¾åƒçš„è½¬æ¢ 4.2 é‡å»º 4.3 é…å‡† 4.4 åˆ†ç±» 4.5 åˆ†å‰² 4.6 å»å™ª 4.7 å›¾åƒç”Ÿæˆ 4.8 å¼‚å¸¸æ£€æµ‹ 4.9 å…¶ä»–åº”ç”¨å’Œå¤šä»»åŠ¡ 4.10 å¯¹æ¯”æ¦‚è¿° æœªæ¥æ–¹å‘å’Œå¼€æ”¾æŒ‘æˆ˜ 4.æ€»ç»“ æœ¬æ–‡ç»¼è¿°äº†æ‰©æ•£æ¨¡å‹çš„ç›¸å…³æ–‡çŒ®ï¼Œé‡ç‚¹ä»‹ç»äº†æ‰©æ•£æ¨¡å‹åœ¨åŒ»å­¦æˆåƒé¢†åŸŸçš„åº”ç”¨ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ç ”ç©¶äº†æ‰©æ•£æ¨¡å‹åœ¨å¼‚å¸¸æ£€æµ‹ã€åŒ»å­¦å›¾åƒåˆ†å‰²ã€å»å™ªã€åˆ†ç±»ã€é‡å»ºã€é…å‡†ã€ç”Ÿæˆç­‰ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚ç‰¹åˆ«æ˜¯ï¼Œå¯¹äºè¿™äº›åº”ç”¨ç¨‹åºä¸­çš„æ¯ä¸€ä¸ªï¼Œæˆ‘ä»¬éƒ½ä»ä¸åŒçš„è§’åº¦æä¾›äº†æ ¸å¿ƒæŠ€æœ¯çš„åˆ†ç±»å’Œé«˜çº§æŠ½è±¡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åŸºäºæŠ€æœ¯å¯¹ç°æœ‰æ¨¡å‹è¿›è¡Œäº†è¡¨å¾ï¼Œå…¶ä¸­æˆ‘ä»¬ç¡®å®šäº†åŸºäºddpm, ncsnå’ŒSDEsçš„æ‰©æ•£å»ºæ¨¡çš„ä¸‰ç§ä¸»è¦å…¬å¼ã€‚æœ€åï¼Œæˆ‘ä»¬æ¦‚è¿°äº†æœªæ¥ç ”ç©¶çš„å¯èƒ½é€”å¾„ã€‚ è™½ç„¶æˆ‘ä»¬çš„è°ƒæŸ¥å¼ºè°ƒäº†åŒ»å­¦æˆåƒä¸­åŸºäºæ‰©æ•£çš„æŠ€æœ¯çš„å¿«é€Ÿå¢é•¿ï¼Œä½†æˆ‘ä»¬ä¹Ÿæ‰¿è®¤ï¼Œè¯¥é¢†åŸŸä»å¤„äºæ—©æœŸé˜¶æ®µï¼Œå¯èƒ½ä¼šå‘ç”Ÿå˜åŒ–ã€‚éšç€æ‰©æ•£æ¨¡å‹è¶Šæ¥è¶Šå—æ¬¢è¿ï¼Œåœ¨è¿™ä¸€é¢†åŸŸçš„ç ”ç©¶ä¹Ÿè¶Šæ¥è¶Šå¤šï¼Œæˆ‘ä»¬çš„è°ƒæŸ¥ä¸ºå¸Œæœ›åœ¨å·¥ä½œä¸­ä½¿ç”¨è¿™äº›æ¨¡å‹çš„ç ”ç©¶äººå‘˜å’Œä»ä¸šè€…æä¾›äº†ä¸€ä¸ªé‡è¦çš„èµ·ç‚¹å’Œå‚è€ƒã€‚æˆ‘ä»¬å¸Œæœ›è¿™é¡¹è°ƒæŸ¥å°†æ¿€å‘è¿›ä¸€æ­¥çš„å…´è¶£å’Œæ¢ç´¢æ‰©æ•£æ¨¡å‹åœ¨åŒ»å­¦é¢†åŸŸçš„æ½œåŠ›ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæœ¬è°ƒæŸ¥ä¸­å¼•ç”¨çš„ä¸€äº›è®ºæ–‡æ˜¯é¢„å°æœ¬ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å°½ä¸€åˆ‡åŠªåŠ›åªåŒ…æ‹¬æ¥è‡ªä¿¡èª‰è‰¯å¥½çš„æ¥æºçš„é«˜è´¨é‡ç ”ç©¶ï¼Œæˆ‘ä»¬ç›¸ä¿¡ï¼ŒåŒ…æ‹¬é¢„å°æœ¬æä¾›äº†å¯¹è¿™ä¸ªå¿«é€Ÿå‘å±•çš„é¢†åŸŸå½“å‰æœ€å…ˆè¿›æŠ€æœ¯çš„å…¨é¢æ¦‚è¿°ã€‚æ€»çš„æ¥è¯´ï¼Œæˆ‘ä»¬ç›¸ä¿¡æˆ‘ä»¬çš„è°ƒæŸ¥ä¸ºæ‰©æ•£æ¨¡å‹åœ¨åŒ»å­¦æˆåƒä¸­çš„åº”ç”¨æä¾›äº†æœ‰ä»·å€¼çš„è§è§£ï¼Œå¹¶çªå‡ºäº†æœªæ¥ç ”ç©¶çš„æœ‰å‰é€”çš„é¢†åŸŸã€‚","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Paper-åŒ»å­¦å½±åƒ","slug":"Paper-åŒ»å­¦å½±åƒ","permalink":"http://example.com/tags/Paper-%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F/"},{"name":"Paper-ç»¼è¿°æ–‡ç« ","slug":"Paper-ç»¼è¿°æ–‡ç« ","permalink":"http://example.com/tags/Paper-%E7%BB%BC%E8%BF%B0%E6%96%87%E7%AB%A0/"}]},{"title":"PaperReading-ç”¨äºåŒ»å­¦å›¾åƒåˆ†ç±»çš„åŒåˆ¶å¯¼æ‰©æ•£ç½‘ç»œ","slug":"paper_ç”¨äºåŒ»å­¦å›¾åƒåˆ†ç±»çš„åŒåˆ¶å¯¼æ‰©æ•£ç½‘ç»œ","date":"2023-08-31T14:15:40.186Z","updated":"2024-05-21T12:19:54.600Z","comments":true,"path":"2023/08/31/paper_ç”¨äºåŒ»å­¦å›¾åƒåˆ†ç±»çš„åŒåˆ¶å¯¼æ‰©æ•£ç½‘ç»œ/","link":"","permalink":"http://example.com/2023/08/31/paper_%E7%94%A8%E4%BA%8E%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%9A%84%E5%8F%8C%E5%88%B6%E5%AF%BC%E6%89%A9%E6%95%A3%E7%BD%91%E7%BB%9C/","excerpt":"","text":"DiffMIC Dual-Guidance Diffusion Network for Medical Image Classification 1.æ‘˜è¦ è¿‘å¹´æ¥ï¼Œæ‰©æ•£æ¦‚ç‡æ¨¡å‹åœ¨ç”Ÿæˆå›¾åƒå»ºæ¨¡ä¸­è¡¨ç°å‡ºäº†æ˜¾è‘—çš„æ€§èƒ½ï¼Œå¼•èµ·äº†è®¡ç®—æœºè§†è§‰ç•Œçš„å¹¿æ³›å…³æ³¨ã€‚ç„¶è€Œï¼Œå°½ç®¡å¤§é‡åŸºäºæ‰©æ•£çš„ç ”ç©¶é›†ä¸­åœ¨ç”Ÿæˆä»»åŠ¡ä¸Šï¼Œä½†å¾ˆå°‘æœ‰ç ”ç©¶å°†æ‰©æ•£æ¨¡å‹åº”ç”¨äºä¸€èˆ¬åŒ»å­¦å›¾åƒåˆ†ç±»ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ç¬¬ä¸€ä¸ªåŸºäºæ‰©æ•£çš„æ¨¡å‹(ç§°ä¸ºDiffMIC)ï¼Œé€šè¿‡æ¶ˆé™¤åŒ»å­¦å›¾åƒä¸­çš„æ„å¤–å™ªå£°å’Œæ‰°åŠ¨å¹¶é²æ£’åœ°æ•è·è¯­ä¹‰è¡¨ç¤ºæ¥è§£å†³ä¸€èˆ¬åŒ»å­¦å›¾åƒåˆ†ç±»é—®é¢˜ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§åŒæ¡ä»¶å¼•å¯¼ç­–ç•¥ï¼Œè¯¥ç­–ç•¥å°†æ¯ä¸ªæ‰©æ•£æ­¥éª¤è®¾å®šä¸ºå¤šä¸ªç²’åº¦ï¼Œä»¥æé«˜é€æ­¥çš„åŒºåŸŸæ³¨æ„åŠ›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºåœ¨æ‰©æ•£å‰å‘è¿‡ç¨‹ä¸­é€šè¿‡å¼ºåˆ¶æœ€å¤§å‡å€¼å·®å¼‚æ­£åˆ™åŒ–æ¥å­¦ä¹ æ¯ä¸ªç²’åº¦çš„äº’ä¿¡æ¯ã€‚æˆ‘ä»¬è¯„ä¼°äº†DiffMICåœ¨ä¸‰ç§ä¸åŒå›¾åƒæ¨¡å¼ä¸‹çš„åŒ»å­¦åˆ†ç±»ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ï¼ŒåŒ…æ‹¬è¶…å£°å›¾åƒä¸Šçš„èƒç›˜æˆç†Ÿåº¦åˆ†çº§ã€çš®è‚¤é•œå›¾åƒä¸Šçš„çš®è‚¤ç—…å˜åˆ†çº§å’Œçœ¼åº•å›¾åƒä¸Šçš„ç³–å°¿ç—…è§†ç½‘è†œç—…å˜åˆ†çº§ã€‚æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒDiffMICåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œè¡¨æ˜äº†æ‰€æå‡ºæ¨¡å‹çš„é€šç”¨æ€§å’Œæœ‰æ•ˆæ€§ã€‚ 2.å¼•è¨€ åŒ»å­¦å›¾åƒåˆ†æä¸å¯æˆ–ç¼ºï¼ŒåŒ»å­¦å›¾åƒåˆ†ç±»æ˜¯åŒ»å­¦å›¾åƒåˆ†æçš„ä¸€ä¸ªåŸºæœ¬æ­¥éª¤ã€‚æ·±åº¦å­¦ä¹ æ–¹æ³•å¯ä»¥å¸®åŠ©åŒ»ç”Ÿè§£è¯»åŒ»å­¦å›¾åƒï¼Œè¿™äº›æ–¹æ³•æœ‰å¯èƒ½å‡å°‘äººå·¥åˆ†ç±»æ‰€éœ€çš„æ—¶é—´å’Œç²¾åŠ›ï¼Œå¹¶æé«˜ç»“æœçš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚ç„¶è€Œï¼Œç”±äºå­˜åœ¨å„ç§æ¨¡ç³Šç—…å˜å’Œç»†ç²’åº¦ç»„ç»‡ï¼Œå¦‚è¶…å£°(US)ã€çš®è‚¤é•œå’Œçœ¼åº•å›¾åƒï¼Œå„ç§å½¢å¼çš„åŒ»å­¦å›¾åƒä»ç„¶å¯¹ç°æœ‰æ–¹æ³•æå‡ºæŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œåœ¨ç¡¬ä»¶é™åˆ¶ä¸‹ç”ŸæˆåŒ»å­¦å›¾åƒå¯èƒ½ä¼šå¯¼è‡´å™ªå£°å’Œæ¨¡ç³Šæ•ˆæœï¼Œä»è€Œé™ä½å›¾åƒè´¨é‡ï¼Œå› æ­¤éœ€è¦æ›´æœ‰æ•ˆçš„ç‰¹å¾è¡¨ç¤ºå»ºæ¨¡ä»¥å®ç°é²æ£’åˆ†ç±»ã€‚ æœ€è¿‘ï¼Œå»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆå’Œåˆæˆä»»åŠ¡ä¸­å–å¾—äº†ä¼˜å¼‚çš„æ•ˆæœã€‚è™½ç„¶æœ‰ä¸€äº›å…ˆé©±ä½œå“è¯•å›¾å°†æ‰©æ•£æ¨¡å‹ç”¨äºå›¾åƒåˆ†å‰²å’Œç›®æ ‡æ£€æµ‹ä»»åŠ¡ï¼Œä½†å…¶åœ¨é«˜çº§è§†è§‰æ–¹é¢çš„æ½œåŠ›å°šæœªå¾—åˆ°å……åˆ†æŒ–æ˜ã€‚ æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºæ‰©æ•£å»å™ªçš„æ¨¡å‹DiffMICï¼Œç”¨äºå‡†ç¡®åˆ†ç±»ä¸åŒçš„åŒ»å­¦å›¾åƒæ¨¡æ€ã€‚ ï¼ˆ1ï¼‰æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œæˆ‘ä»¬æ˜¯ç¬¬ä¸€ä¸ªæå‡ºåŸºäºæ‰©æ•£çš„ä¸€èˆ¬åŒ»å­¦å›¾åƒåˆ†ç±»æ¨¡å‹ã€‚ç”±äºåŒ»å­¦å›¾åƒçš„æ‰©æ•£è¿‡ç¨‹æ˜¯éšæœºçš„ï¼Œå› æ­¤æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥é€‚å½“åœ°æ¶ˆé™¤åŒ»å­¦å›¾åƒä¸­çš„ä¸è‰¯å™ªå£°ã€‚ ï¼ˆ2ï¼‰ç‰¹åˆ«åœ°ï¼Œæˆ‘ä»¬å¼•å…¥äº†åŒç²’åº¦æ¡ä»¶æŒ‡å¯¼(DCG)ç­–ç•¥æ¥æŒ‡å¯¼å»å™ªè¿‡ç¨‹ï¼Œåœ¨æ‰©æ•£è¿‡ç¨‹ä¸­ä½¿ç”¨å…¨å±€å’Œå±€éƒ¨å…ˆéªŒæ¥è°ƒèŠ‚æ¯ä¸€æ­¥ã€‚é€šè¿‡åœ¨è¾ƒå°çš„æ–‘å—ä¸Šè¿›è¡Œæ‰©æ•£è¿‡ç¨‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥åŒºåˆ†å…·æœ‰ç»†ç²’åº¦èƒ½åŠ›çš„å…³é”®ç»„ç»‡ã€‚ ï¼ˆ3ï¼‰æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ç‰¹å®šæ¡ä»¶çš„æœ€å¤§å¹³å‡å·®å¼‚(MMD)æ­£åˆ™åŒ–æ¥å­¦ä¹ æ¯ä¸ªç²’åº¦æ½œåœ¨ç©ºé—´ä¸­çš„äº’ä¿¡æ¯ï¼Œä½¿ç½‘ç»œèƒ½å¤Ÿå»ºæ¨¡æ•´ä¸ªå›¾åƒå’Œè¡¥ä¸å…±äº«çš„é²æ£’ç‰¹å¾è¡¨ç¤ºã€‚ ï¼ˆ4ï¼‰æˆ‘ä»¬è¯„ä¼°äº†DiffMICåœ¨èƒç›˜æˆç†Ÿåº¦åˆ†çº§ã€çš®è‚¤ç—…å˜åˆ†çº§å’Œç³–å°¿ç—…è§†ç½‘è†œç—…å˜åˆ†çº§ä¸‰ä¸ªäºŒç»´åŒ»å­¦å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„åŸºäºæ‰©æ•£çš„åˆ†ç±»æ–¹æ³•åœ¨æ‰€æœ‰ä¸‰ä¸ªä»»åŠ¡ä¸Šéƒ½ä¸€è‡´ä¸”æ˜¾è‘—åœ°è¶…è¿‡äº†æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚ 3.æ€»ç»“ æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£çš„åŒ»å­¦å›¾åƒåˆ†ç±»ç½‘ç»œ(DiffMIC)ã€‚æˆ‘ä»¬çš„DiffMICçš„ä¸»è¦æ€æƒ³æ˜¯åœ¨æ™®é€šDDPMä¸Šå¼•å…¥åŒç²’åº¦æ¡ä»¶æŒ‡å¯¼ï¼Œå¹¶å¼ºåˆ¶æ‰§è¡Œç‰¹å®šäºæ¡ä»¶çš„MMDæ­£åˆ™åŒ–ä»¥æé«˜åˆ†ç±»æ€§èƒ½ã€‚åœ¨ä¸‰ä¸ªä¸åŒå›¾åƒæ¨¡å¼çš„åŒ»å­¦å›¾åƒåˆ†ç±»æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„ç½‘ç»œæ¯”æœ€å…ˆè¿›çš„æ–¹æ³•å…·æœ‰æ›´å¥½çš„æ€§èƒ½ã€‚ä½œä¸ºç¬¬ä¸€ä¸ªåŸºäºæ‰©æ•£çš„ä¸€èˆ¬åŒ»å­¦å›¾åƒåˆ†ç±»æ¨¡å‹ï¼Œæˆ‘ä»¬çš„DiffMICæœ‰å¯èƒ½æˆä¸ºè¯¥é¢†åŸŸæœªæ¥ç ”ç©¶çš„åŸºæœ¬åŸºçº¿ 4.æ–‡ç« ç¬”è®° é€šè¿‡æœ‰é™çš„è·¨æ¨¡æ€ä¿¡æ¯ç”Ÿæˆçš„åŒ»å­¦å›¾åƒå¯èƒ½ä¼šå¯¼è‡´å™ªå£°å’Œæ¨¡ç³Šæ•ˆæœï¼Œä»è€Œé™ä½è¯Šæ–­å‡†ç¡®æ€§ï¼Œå› æ­¤éœ€è¦æ›´æœ‰æ•ˆçš„ç‰¹å¾è¡¨ç¤ºå»ºæ¨¡ä»¥å®ç°é²æ£’åˆ†ç±»","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Paper-åŒ»å­¦å½±åƒ","slug":"Paper-åŒ»å­¦å½±åƒ","permalink":"http://example.com/tags/Paper-%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F/"}]},{"title":"PaperReading-å¤šæ¨¡æ€åŒ»å­¦å›¾åƒèåˆæŠ€æœ¯ç»¼è¿°","slug":"paper_å¤šæ¨¡æ€åŒ»å­¦å›¾åƒèåˆæŠ€æœ¯ç»¼è¿°","date":"2023-08-30T04:42:18.434Z","updated":"2024-05-22T02:28:01.207Z","comments":true,"path":"2023/08/30/paper_å¤šæ¨¡æ€åŒ»å­¦å›¾åƒèåˆæŠ€æœ¯ç»¼è¿°/","link":"","permalink":"http://example.com/2023/08/30/paper_%E5%A4%9A%E6%A8%A1%E6%80%81%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/","excerpt":"","text":"A Review of Multimodal Medical Image Fusion Techniques 1.æ‘˜è¦ åŒ»å­¦å›¾åƒèåˆæ˜¯å°†æ¥è‡ªå¤šç§æˆåƒæ–¹å¼çš„å¤šå¹…å›¾åƒè¿›è¡Œèåˆï¼Œå¾—åˆ°ä¿¡æ¯é‡å¤§çš„èåˆå›¾åƒï¼Œä»¥æé«˜åŒ»å­¦å›¾åƒçš„ä¸´åºŠé€‚ç”¨æ€§çš„è¿‡ç¨‹ã€‚æœ¬æ–‡å¯¹å¤šæ¨¡æ€åŒ»å­¦å›¾åƒèåˆæ–¹æ³•è¿›è¡Œäº†ç»¼è¿°ï¼Œé‡ç‚¹ä»‹ç»äº†è¯¥é¢†åŸŸçš„æœ€æ–°è¿›å±•ï¼ŒåŒ…æ‹¬:(1)å½“å‰çš„èåˆæ–¹æ³•ï¼ŒåŒ…æ‹¬åŸºäºæ·±åº¦å­¦ä¹ çš„èåˆæ–¹æ³•;(2)åŒ»å­¦å›¾åƒèåˆçš„æˆåƒæ–¹å¼;(3)ä¸»è¦æ•°æ®é›†ä¸ŠåŒ»å­¦å›¾åƒèåˆçš„æ€§èƒ½åˆ†æã€‚æœ€åï¼Œæœ¬æ–‡çš„ç»“è®ºæ˜¯ï¼Œç›®å‰å¤šæ¨¡æ€åŒ»å­¦å›¾åƒèåˆçš„ç ”ç©¶æˆæœè¾ƒä¸ºæ˜¾è‘—ï¼Œå‘å±•è¶‹åŠ¿å‘ˆä¸Šå‡è¶‹åŠ¿ï¼Œä½†ç ”ç©¶é¢†åŸŸå­˜åœ¨è¯¸å¤šæŒ‘æˆ˜ã€‚ 2.å¼•è¨€ å¤šæ¨¡æ€åŒ»å­¦å›¾åƒèåˆè¢«å¹¿æ³›ç ”ç©¶ã€‚ åŒ»å­¦å›¾åƒèåˆé€šè¿‡èåˆåŒä¸€éƒ¨ä½çš„ä¸åŒæˆåƒä¿¡æ¯ä»¥è·å¾—æ›´å¥½çš„å¯¹æ¯”åº¦ï¼Œèåˆè´¨é‡å’Œæ„ŸçŸ¥ä½“éªŒã€‚èåˆç»“æœåº”æ»¡è¶³ä»¥ä¸‹æ¡ä»¶ï¼š (a)èåˆåçš„å›¾åƒåº”å®Œå…¨ä¿ç•™æºå›¾åƒçš„ä¿¡æ¯; (b)èåˆåçš„å›¾åƒä¸åº”äº§ç”Ÿä»»ä½•åˆæˆä¿¡æ¯ï¼Œå¦‚ä¼ªå½±; Â©åº”é¿å…ä¸è‰¯çŠ¶æ€ï¼Œå¦‚è¯¯ç™»è®°å’Œå™ªéŸ³ ä¼ ç»Ÿçš„åŒ»å­¦å›¾åƒèåˆæ–¹æ³•åˆ†ä¸ºç©ºé—´åŸŸå’Œå˜æ¢åŸŸã€‚éšç€æ·±åº¦å­¦ä¹ çƒ­æ½®çš„åˆ°æ¥ï¼Œå‡ºç°äº†åŸºäºæ·±åº¦å­¦ä¹ çš„åŒ»å­¦å›¾åƒèåˆæ–¹æ³•ï¼Œä½†åªæœ‰CNNå’ŒU-Netç½‘ç»œå¾—åˆ°äº†åº”ç”¨ æœ¬æ–‡ç»“åˆè¿‘å¹´æ¥åŒ»å­¦å›¾åƒèåˆçš„ç›¸å…³è®ºæ–‡ï¼Œå¯¹è¯¥é¢†åŸŸçš„ç ”ç©¶è¿›å±•åŠæœªæ¥å‘å±•è¿›è¡Œç»¼è¿°ï¼Œåˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š (1)å¯¹å½“å‰èåˆæ–¹æ³•çš„ä»‹ç» (2)å¤šæ¨¡æ€èåˆçš„æ¨¡å¼ (3)å¯¹åŒä¸€æ•°æ®åº“ä¸­å…·æœ‰ç›¸åŒè¯„ä»·æŒ‡æ ‡çš„ä¸åŒåŒ»å­¦å›¾åƒèåˆæ–¹æ³•çš„æ•°æ®è¿›è¡Œæ¯”è¾ƒ (4)è®¨è®ºåŒ»å­¦å›¾åƒèåˆæ–¹æ³•é¢ä¸´çš„æŒ‘æˆ˜å’Œæœªæ¥çš„ç ”ç©¶è¶‹åŠ¿ 3.æ€»ç»“ åŒ»å­¦å›¾åƒèåˆæ–¹æ³•å­˜åœ¨çš„é—®é¢˜ï¼š åŒ»å­¦å›¾åƒèåˆçš„è¯„ä»·æŒ‡æ ‡å¤šï¼Œè¯„ä»·æŒ‡æ ‡çš„éå”¯ä¸€æ€§é™åˆ¶äº†è¯„ä»·æŒ‡æ ‡çš„åº”ç”¨å‰æ™¯ åŒ»å­¦å›¾åƒèåˆçš„åˆ›æ–°æ€§ä½ï¼Œèåˆç»“æœä¸­å­˜åœ¨çš„é¢œè‰²å¤±çœŸã€ç‰¹å¾ä¿¡æ¯æå–ç­‰é—®é¢˜åªæ˜¯å¾—åˆ°äº†æ”¹å–„ï¼Œè€Œæ²¡æœ‰å®Œå…¨è§£å†³ã€‚å…¶ä¸­æ·±åº¦å­¦ä¹ æé«˜äº†èåˆçš„æ•ˆæœï¼Œä½†ç ”ç©¶ä¹Ÿå­˜åœ¨å¦‚ä¸‹é—®é¢˜ï¼š ï¼ˆ1ï¼‰å¦‚ä½•è·å–æµ·é‡çš„æ•°æ®é›† ï¼ˆ2ï¼‰å¦‚ä½•ç®€åŒ–è®­ç»ƒæ¨¡å‹æˆ–æå‡ºæ–°çš„è®­ç»ƒæ¨¡å‹ ï¼ˆ3ï¼‰éƒ¨åˆ†èåˆæ–¹æ³•ä¾èµ–äºç²¾ç¡®çš„å›¾åƒé…å‡†ï¼Œç‹¬ç«‹æ€§å° ä¸åŒä¼ æ„Ÿå™¨è·å–çš„åŒ»å­¦å›¾åƒä¿¡æ¯å­˜åœ¨å·®å¼‚ã€‚ç›®å‰çš„ç ”ç©¶çƒ­ç‚¹æ˜¯ä¸¤æ¨¡èåˆï¼Œè€Œä¸‰æ¨¡èåˆçš„ç ”ç©¶å¾ˆå°‘ã€‚ 4.æ–‡ç« ç¬”è®° U-Netæ˜¯åŸºäºå…¨å·ç§¯ç¥ç»ç½‘ç»œæ”¹è¿›çš„ï¼Œä½¿ç”¨æ•°æ®å¢å¼ºå¯ä»¥è®­ç»ƒå°‘é‡çš„æ ·æœ¬ã€‚è¿™ä¸€ä¼˜ç‚¹æ­£å¥½å¼¥è¡¥äº†åŒ»å­¦å›¾åƒæ•°æ®æ ·æœ¬é‡å°çš„ç¼ºç‚¹ CNNæ˜¯åŒ»å­¦é¢†åŸŸçš„æ–°æŒ‘æˆ˜;ä¸»è¦åŸå› æ˜¯(a)éœ€è¦å¤§é‡å¸¦æ³¨é‡Šçš„è®­ç»ƒé›†æ•°æ®ï¼Œ(b)è®­ç»ƒæ—¶é—´é•¿ï¼ŒÂ©æ”¶æ•›é—®é¢˜å¤æ‚ï¼Œè¿‡æ‹Ÿåˆéœ€è¦åå¤è°ƒæ•´ã€‚","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Paper-åŒ»å­¦å½±åƒ","slug":"Paper-åŒ»å­¦å½±åƒ","permalink":"http://example.com/tags/Paper-%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F/"},{"name":"Paper-ç»¼è¿°æ–‡ç« ","slug":"Paper-ç»¼è¿°æ–‡ç« ","permalink":"http://example.com/tags/Paper-%E7%BB%BC%E8%BF%B0%E6%96%87%E7%AB%A0/"}]},{"title":"PaperReading-ç»¼è¿°-MRIä¸PETäº¤å‰æ¨¡æ€åˆæˆç ”ç©¶è¿›å±•","slug":"paper_MRIä¸PETäº¤å‰æ¨¡æ€åˆæˆç ”ç©¶è¿›å±•","date":"2023-08-30T04:42:17.929Z","updated":"2024-05-22T02:27:47.603Z","comments":true,"path":"2023/08/30/paper_MRIä¸PETäº¤å‰æ¨¡æ€åˆæˆç ”ç©¶è¿›å±•/","link":"","permalink":"http://example.com/2023/08/30/paper_MRI%E4%B8%8EPET%E4%BA%A4%E5%8F%89%E6%A8%A1%E6%80%81%E5%90%88%E6%88%90%E7%A0%94%E7%A9%B6%E8%BF%9B%E5%B1%95/","excerpt":"","text":"A Review on Cross-modality Synthesis from MRI to PET 1.æ‘˜è¦ éšç€æ—¶é—´çš„æ¨ç§»ï¼ŒåŒ»å­¦å½±åƒåˆæˆè¶Šæ¥è¶Šå—æ¬¢è¿ã€‚åœ¨å„å…·ç‰¹è‰²çš„æˆåƒæŠ€æœ¯ä¸­ï¼ŒMRIå’ŒPETåœ¨åŒ»ç–—é¢†åŸŸæœ‰ç€é‡è¦çš„æ„ä¹‰ã€‚ä½†ç”±äºPETçš„æŸäº›å±€é™æ€§ï¼Œå¦‚è´¹ç”¨ã€è¾å°„æš´éœ²å’Œç¼ºä¹å¯ç”¨æ€§ï¼Œäººä»¬å€¾å‘äºé‡‡ç”¨è·¨æ¨¡æ€åˆæˆçš„æ–¹æ³•ã€‚æ·±åº¦å­¦ä¹ ä¸ºè¯¥é¢†åŸŸæ¨¡å‹çš„å‘å±•é“ºå¹³äº†é“è·¯ï¼Œå®Œæˆäº†è·¨æ¨¡æ€åˆæˆä»»åŠ¡ã€‚ä½¿ç”¨è¿™äº›æ¨¡å‹åˆæˆç”Ÿç‰©åŒ»å­¦å›¾åƒå¯ä»¥èŠ‚çœæ‚£è€…çš„æ—¶é—´ã€é‡‘é’±å’Œç²¾åŠ›ï¼Œå¹¶æ”¹å–„ç–¾ç—…è¯Šæ–­ã€‚æœ¬æ–‡æ—¨åœ¨æ€»ç»“ä»¥MRI-PETäº¤å‰æ¨¡æ€åˆæˆä¸ºæœ€ç»ˆç›®æ ‡çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ 2.å¼•è¨€ åŒ»å­¦æˆåƒæŠ€æœ¯åœ¨åŒ»ç–—ä¿å¥é¢†åŸŸå‘æŒ¥äº†æ˜¾è‘—çš„ä½œç”¨,æ¯ç§ç±»å‹çš„æˆåƒæŠ€æœ¯éƒ½æä¾›äº†ä¸€äº›äººä½“è§£å‰–æˆ–åŠŸèƒ½ä¿¡æ¯ï¼Œè¿™æ„å‘³ç€åƒMRå’ŒPETè¿™æ ·çš„å¤šæ¨¡æ€ç”Ÿç‰©åŒ»å­¦å›¾åƒå°†æä¾›è¡¥å……ä¿¡æ¯ï¼Œä»è€Œå®ç°ç»†è‡´å’Œå¿«é€Ÿçš„è¯Šæ–­ã€‚ ç£å…±æŒ¯æˆåƒ(MRI)å’Œæ­£ç”µå­å‘å°„æ–­å±‚æ‰«æ(PET)è¿™ä¸¤ç§æ‰«æåœ¨ä¸€èµ·ä½¿ç”¨æ—¶å¯ä»¥æä¾›è¡¥å……ä¿¡æ¯ï¼Œå¸®åŠ©åŒ»ç”Ÿåšå‡ºå¼ºæœ‰åŠ›çš„ä¸´åºŠåˆ¤æ–­ï¼Œä½†æ˜¯æ¯ä¸ªæ‚£è€…åŒæ—¶æ‹¥æœ‰è¿™ä¸¤ç§æ‰«æçš„å¯èƒ½æ€§å¾ˆä½ï¼Œè¿™æœ‰å¤šç§åŸå›  1)PETæ¨¡å¼çš„å¯ç”¨æ€§æœ‰é™ã€‚å‘å±•ä¸­å›½å®¶çš„å¤§å¤šæ•°åŒ»ç–—ä¸­å¿ƒä¸æä¾›PETæ‰«æã€‚ 2)ä¸MRIç›¸æ¯”ï¼ŒPETæ˜¯ä¸€ç§æ˜‚è´µçš„æ–¹å¼ã€‚ 3) PETä¸­æ”¾å°„æ€§ç¤ºè¸ªå‰‚çš„ä½¿ç”¨ï¼Œå¢åŠ äº†ç»ˆç”Ÿç™Œç—‡é£é™©ã€‚ å°½ç®¡å­˜åœ¨è¿™äº›éšœç¢ï¼Œä½†PETç”±äºå…¶ç‹¬ç‰¹çš„åˆ†å­æˆåƒç‰¹æ€§æ˜¯å¿…ä¸å¯å°‘çš„ã€‚è€Œæ ¸ç£å…±æŒ¯æˆåƒä½œä¸ºä¸€ç§æ›´å®‰å…¨çš„æˆåƒæ–¹å¼ï¼Œåœ¨è¿™äº›é™åˆ¶æ–¹é¢å…·æœ‰ä¼˜åŠ¿ã€‚å› æ­¤ï¼Œä¸ºäº†æœ‰æ•ˆè§£å†³è¿™ä¸€é—®é¢˜ï¼Œé‡‡ç”¨äº†è·¨æ¨¡æ€åˆæˆç­–ç•¥ã€‚ è·¨æ¨¡æ€åˆæˆæ˜¯åœ¨æºæ¨¡æ€ä¸‹è¯„ä¼°åŒä¸€å—è¯•è€…çš„ç›®æ ‡æ¨¡æ€å›¾åƒçš„è¿‡ç¨‹ï¼Œå³åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­æ˜¯MR-to-PETã€‚è¯¥æ–¹æ³•ä¸ä»…å…‹æœäº†PETçš„åˆ’ç•Œå› ç´ ï¼Œè€Œä¸”ç®€åŒ–äº†æ‚£è€…çš„æ²»ç–—ï¼Œå‡å°‘äº†æ‚£è€…çš„æ•´ä½“æ‰«ææ—¶é—´ï¼Œå‡å°‘äº†è¯Šæ‰€å’ŒåŒ»é™¢çš„å·¥ä½œé‡ï¼Œæé«˜äº†ç–¾ç—…é¢„æµ‹çš„å‡†ç¡®æ€§ï¼Œå¹¶ä¸”å¯ä»¥ä¸ºåŒ»å­¦æˆåƒæ•°æ®é›†åšå‡ºè´¡çŒ®ã€‚ç®€è€Œè¨€ä¹‹ï¼Œå®ƒèŠ‚çœäº†äººä»¬çš„æ—¶é—´ã€é‡‘é’±å’Œç²¾åŠ›ã€‚ä»è€Œæ”¹å–„ç¤¾ä¼šçš„å¥åº·å’Œç”Ÿæ´»ã€‚ å±äºåŒä¸€å—è¯•è€…çš„MRå’ŒPETæ‰«æå…·æœ‰ä¸åŒçš„å¤–è§‚ï¼Œè¿™ä½¿å¾—å­¦ä¹ è·¨åŸŸæ˜ å°„æˆä¸ºä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚æ·±åº¦å­¦ä¹ å·²è¢«è®¤ä¸ºæ˜¯å®ç°è®¡ç®—æœºè§†è§‰ä»»åŠ¡çš„é‡è¦æŠ€æœ¯ã€‚éšç€GANçš„ä½“ç³»ç»“æ„åŠå…¶å˜ä½“å¾—åˆ°äº†å¹¿æ³›çš„è®¤å¯,åœ¨å®Œæˆè·¨æ¨¡æ€åˆæˆæ—¶ï¼ŒåŒæ ·åˆ›å»ºäº†åŸºäºGANçš„æ¨¡å‹ åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ€»ç»“äº†ç°æœ‰çš„ç”¨äºMRI-PETäº¤å‰æ¨¡æ€åˆæˆçš„åŸºäºæ·±åº¦å­¦ä¹ çš„æ¨¡å‹ã€‚ 3.è®ºæ–‡ç»“æ„ 1)æ–‡çŒ®è°ƒæŸ¥ A.åŸºäºæ·±åº¦å­¦ä¹ çš„å½±åƒæ•°æ®è¡¥å…¨æ”¹å–„è„‘éƒ¨ç–¾ç—…è¯Šæ–­ æœ¬æ–‡ä½¿ç”¨3D CNNæ¥ä¼°è®¡ç¼ºå¤±æ•°æ®ã€‚è¯¥æ¨¡å‹ä»¥MRIä¸ºè¾“å…¥ï¼Œé¢„æµ‹ç›¸åº”çš„PETã€‚ B. MRIåˆ°FDG-PET:ä½¿ç”¨3D U-Netè¿›è¡Œå¤šæ¨¡æ€é˜¿å°”èŒ¨æµ·é»˜ç—…åˆ†ç±»çš„è·¨æ¨¡æ€åˆæˆ æœ¬æ–‡é‡‡ç”¨ä¸‰ç»´U-Netæ¨¡å‹æ¥æ•æ‰è¿™äº›æ¨¡æ€ä¹‹é—´çš„éå±€éƒ¨ç›¸å…³å’Œéçº¿æ€§å…³ç³»ã€‚ C. åˆæˆPETä»PETä½¿ç”¨å‘¨æœŸä¸€è‡´çš„ç”Ÿæˆå¯¹æŠ—ç½‘ç»œç”¨äºé˜¿å°”èŒ¨æµ·é»˜ç—…è¯Šæ–­ æœ¬æ–‡å¼€å‘äº†ä¸€ä¸ªä¸¤é˜¶æ®µçš„æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åœ¨åˆçº§é˜¶æ®µä½¿ç”¨å‘¨æœŸä¸€è‡´çš„GAN (3DcGAN)è¿›è¡Œmri -PETåˆæˆï¼Œåœ¨åç»­é˜¶æ®µæ„å»ºç”¨äºADè¯Šæ–­çš„åˆ†ç±»æ–¹æ³•(LM3 IL)ã€‚ D.ç”¨pix2pixä»MRIæ¨æ–­PET ä¸ºäº†æœ‰ä¸€ä¸ªå…±åŒçš„æ¡†æ¶ï¼Œå¼•å…¥äº†pix2pix GANï¼Œæœ¬æ–‡ä½¿ç”¨ç›¸åŒçš„æ¶æ„æ¥æ¼”ç¤ºä½¿ç”¨æˆå¯¹æ•°æ®é›†çš„MRIåˆ°PETç¿»è¯‘ä»»åŠ¡ã€‚ E.ä½¿ç”¨ä¸åŒå½’ä¸€åŒ–çš„å¯¹æŠ—U-Netä»MRIåˆ°PETçš„äº¤å‰æ¨¡æ€åˆæˆ ä¸ºäº†å‡å°‘å†…éƒ¨åå˜åç§»é—®é¢˜å’Œå¯¹æ•°æ®é›†ä¸­èŒƒå›´æ›´å¹¿çš„ç‰¹å¾çš„åå€šï¼Œæ·±åº¦ç½‘ç»œé‡‡ç”¨äº†å½’ä¸€åŒ–æŠ€æœ¯ã€‚æœ¬æ–‡æŒ‡å‡ºäº†BNçš„æŸäº›ç¼ºç‚¹ï¼Œç”¨å„ç§å½’ä¸€åŒ–æ–¹æ³•å¯¹å¯¹æŠ—U-Netæ¨¡å‹è¿›è¡Œäº†å®éªŒï¼Œä»¥æ‰¾å‡ºå…¶ä¸­æœ€é€‚åˆè¯¥è·¨æ¨¡æ€ç»¼åˆä»»åŠ¡çš„æ–¹æ³•ã€‚ä¸ºäº†è§£å†³æ‰¹é‡å½’ä¸€åŒ–ä¸­ç”Ÿç‰©åŒ»å­¦å›¾åƒçš„ç¨€å°‘æ€§ä¸å°æ‰¹é‡å¤§å°è¦æ±‚ä¹‹é—´çš„çŸ›ç›¾ï¼Œé‡‡ç”¨æ‰¹èŒƒæ•°(Batch Norm, BN)ã€å±‚èŒƒæ•°(Layer Norm, LN)ã€å®ä¾‹èŒƒæ•°(Instance Norm, in)å’Œç»„èŒƒæ•°(Group Norm, GN)å››ç§å½’ä¸€åŒ–æ–¹æ³•ï¼Œå¯¹ä¸åŒå°æ‰¹é‡å¤§å°çš„å¯¹æŠ—U-Netçš„æ€§èƒ½è¿›è¡Œäº†è¯„ä»·ã€‚å®šé‡ç»“æœè¡¨æ˜ï¼ŒINå¯¹æ‰€æœ‰æ ·æœ¬çš„æ¯ä¸ªé€šé“ç›¸å¯¹äºè¯¥é€šé“çš„å‡å€¼å’Œæ ‡å‡†å·®è¿›è¡Œæ ‡å‡†åŒ–ï¼Œæ¯”å…¶ä»–å½’ä¸€åŒ–æŠ€æœ¯å…·æœ‰æ›´å¥½çš„æ€§èƒ½ã€‚ F.åŸºäºæ¡ä»¶æµçš„æ¨¡æ€è¿ç§»ç”Ÿæˆæ¨¡å‹ G.åŒå‘æ˜ å°„ç”Ÿæˆå¯¹æŠ—ç½‘ç»œç”¨äºè„‘MRåˆ°PETåˆæˆ è¿™é¡¹å·¥ä½œæå‡ºäº†ä¸€ç§ç±»ä¼¼äºCGANçš„æ–¹æ³•ï¼Œåœ¨è¿™ç§æ–¹æ³•ä¸­ï¼Œå®ƒè¢«ç«¯åˆ°ç«¯åœ°æŒ‡å¯¼ï¼Œæœ€ç»ˆç›®æ ‡æ˜¯ADåˆ†ç±»ã€‚å½“ä½¿ç”¨åˆ†ç±»ç›®æ ‡è¿›è¡Œè®­ç»ƒæ—¶ï¼Œå¯èƒ½ä¼šå½±å“ç”Ÿæˆè¯­ç”¨å›¾åƒçš„æ€§èƒ½ã€‚è¿™ä¸€é™åˆ¶æ˜¯å…‹æœè‡ªé€‚åº”å¾®è°ƒGANæŸè€—å’Œåˆ†ç±»æŸè€—ã€‚åŒæ—¶ï¼Œé€šè¿‡æŸå¤±å¾®è°ƒä½¿ä¸€èˆ¬GANè®­ç»ƒå˜å¾—ç¨³å®šã€‚ I.FREA-Unet:æ¨¡æ€ä¼ è¾“çš„é¢‘ç‡æ„ŸçŸ¥U-net æœ¬æ–‡æ³¨æ„åˆ°PETæ‰«æä¸­å­˜åœ¨ä¸åŒçš„é¢‘ç‡å°ºåº¦ä»¥åŠæ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­æ³¨æ„å­¦ä¹ çš„æœ¬è´¨ï¼Œæå‡ºäº†ç«¯åˆ°ç«¯çš„é¢‘ç‡æ„ŸçŸ¥U-netæ¨¡å‹ã€‚ä¸ºäº†åæ˜ åˆæˆPETä¸çœŸå®PETçš„ä¸åŒé¢‘ç‡å°ºåº¦ï¼Œè¯¥æ¨¡å‹åœ¨è§£ç éƒ¨åˆ†ä»ä¸¤ä¸ªä¸åŒçš„å±‚è·å¾—ä½é¢‘å’Œé«˜é¢‘PETå›¾åƒï¼Œå¹¶åœ¨æ¯ä¸€å±‚ä¸Šé™„åŠ ä¸€ä¸ªå¯è®­ç»ƒçš„æ³¨æ„æ¨¡å—ã€‚æ ¹æ®æœ¬æ–‡çš„å®šä¹‰ï¼Œä½é¢‘/é«˜é¢‘å±‚çš„æ³¨æ„åŠ›æ˜¯æŒ‡ä»é¢‘ç‡å±‚æå–çš„æ¿€æ´»å›¾ä¸U-netè§£ç è·¯å¾„ä¸­å‰ä¸€å±‚åˆ°æœ€åä¸€å±‚çš„äº§å‡ºä¹‹é—´çš„å…¼å®¹æ€§åˆ†æ•°ã€‚ç„¶ååœ¨é¢‘ç‡å°ºåº¦å±‚ä¸­ä½¿ç”¨è¿™äº›åˆ†æ•°æ¥çªå‡ºç›¸å…³ç‰¹å¾ã€‚å°†è·å¾—çš„ä½é¢‘/é«˜é¢‘å±‚çš„è¾“å‡ºèåˆå¹¶é¦ˆé€åˆ°æœ€åä¸€ä¸ªè§£ç å™¨å±‚ï¼Œä»¥ç”Ÿæˆæœ€ç»ˆçš„çœŸå®PETå›¾åƒã€‚åˆ©ç”¨ä»æ³¨æ„åŠ›æ¨¡å—è·å¾—çš„ä¸åŒæƒé‡åˆ†åˆ«ä¼˜åŒ–ä½/é«˜é¢‘å°ºåº¦ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆæ›´ç²¾ç¡®çš„åˆæˆPETï¼Œå…·æœ‰æ›´é«˜çš„åˆ†è¾¨ç‡å’Œä¿ç•™çš„å™¨å®˜ç»“æ„å’Œåˆ†è¾¨ç‡ã€‚ 2)æ¯”è¾ƒ 4.æ€»ç»“ PETæ•°æ®çš„ç¼ºä¹ä¸€ç›´æ˜¯ç–¾ç—…å‡†ç¡®è¯Šæ–­çš„éšœç¢ã€‚è·¨æ¨¡æ€ç»¼åˆæ–¹æ³•æ˜¯è§£å†³è¿™ä¸€é—®é¢˜çš„æœ‰æ•ˆæ–¹æ³•ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ€»ç»“äº†ä¸ºå®ç°MRI-PETäº¤å‰æ¨¡æ€åˆæˆä»»åŠ¡è€Œå¼€å‘çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¹¶å¯¹è¿™äº›æ¨¡å‹è¿›è¡Œäº†æ¯”è¾ƒã€‚å¯ä»¥çœ‹å‡ºï¼Œç”±äºGANåœ¨å›¾åƒåˆæˆä»»åŠ¡ä¸­çš„å‡ºè‰²æ€§èƒ½ï¼Œå¤§å¤šæ•°éƒ½æå‡ºäº†åŸºäºGANçš„æ¶æ„ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ç®€è¦æ¦‚è¿°äº†æ•°æ®é›†å’Œç”¨äºè¯„ä¼°åˆæˆPETå›¾åƒçš„å¸¸ç”¨å®šé‡çŸ©é˜µã€‚ 5.æ–‡ç« ç¬”è®° MRIå’ŒPETçš„åŸºæœ¬åŸç†çš„å™è¿°ï¼š ç£å…±æŒ¯æˆåƒ(MRI)æ˜¯ä¸€ç§åˆ©ç”¨ç£åœºå’Œæ— çº¿ç”µæ³¢å¯¹äººä½“å†…éƒ¨å™¨å®˜è¿›è¡Œæˆåƒçš„ç»“æ„æ–¹å¼ã€‚è¿™ç§éä¾µå…¥æ€§è¯Šæ–­å·¥å…·æµ‹é‡æ‰€éœ€èº«ä½“éƒ¨ä½çš„è§£å‰–ç»“æ„ã€‚è€Œæ­£ç”µå­å‘å°„æ–­å±‚æ‰«æ(PET)æ˜¯ä¸€ç§åŠŸèƒ½æ¨¡å¼ï¼Œä½¿ç”¨æ”¾å°„æ€§ç¤ºè¸ªå‰‚æ¥é‡åŒ–äººä½“ç»„ç»‡å’Œå™¨å®˜ä¸­çš„ä»£è°¢æ´»åŠ¨ã€‚ UNetä¼˜ç‚¹ï¼š ç å™¨å’Œè§£ç å™¨ç½‘ç»œä¹‹é—´çš„è·³è·ƒè¿æ¥æœ‰åŠ©äºä¿ç•™è¾“å‡ºå›¾åƒä¸­çš„ç©ºé—´/å®šä½ä¿¡æ¯ï¼Œå¹¶ä½¿ç”¨äºŒå€¼äº¤å‰ç†µä½œä¸ºæŸå¤±å‡½æ•°ï¼Œæœ‰åŠ©äºç”Ÿæˆå¹³æ»‘è¾“å‡ºã€‚ U-Netæ¶æ„ä»¥å…¶é€šè¿‡è·³è¿‡è¿æ¥å°†ä½çº§ç‰¹å¾ä»ç¼–ç å™¨ä¼ è¾“åˆ°è§£ç å™¨çš„èƒ½åŠ›è€Œé—»åï¼Œåœ¨è¿™ä¸€è¿‡ç¨‹ä¸­å¯¹äºä¿ç•™MRå’ŒPETåˆ‡ç‰‡ä¹‹é—´å¸¸è§çš„ä½çº§ç‰¹å¾éå¸¸é‡è¦ è¯„ä¼°åˆæˆåŒ»å­¦å›¾åƒçš„æ ‡å‡†: â€¢ Mean Absolute Error (MAE) â€¢ Mean Squared Error (MSE) â€¢ Peak Signal-to-Noise Ratio (PSNR) â€¢ Structure Similarity Index (SSIM) â€¢ Multi-Scale Structural Similarity (MS-SSIM) â€¢ Frechet Inception Distance (FID) æ³¨æ„åŠ›çš„ä¼˜ç‚¹: æ³¨æ„åŠ›å­¦ä¹ èƒŒåçš„ä¸»è¦æ€æƒ³æ˜¯æ›´å¤šåœ°å…³æ³¨ä¸ä»»åŠ¡ç›¸å…³çš„ç‰¹å¾ï¼Œè€Œä¸æ˜¯ç®€å•åœ°å¹³ç­‰åœ°å…³æ³¨å›¾åƒçš„æ‰€æœ‰éƒ¨åˆ†ã€‚","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Paper-åŒ»å­¦å½±åƒ","slug":"Paper-åŒ»å­¦å½±åƒ","permalink":"http://example.com/tags/Paper-%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F/"},{"name":"Paper-ç»¼è¿°æ–‡ç« ","slug":"Paper-ç»¼è¿°æ–‡ç« ","permalink":"http://example.com/tags/Paper-%E7%BB%BC%E8%BF%B0%E6%96%87%E7%AB%A0/"}]},{"title":"PaperReading-åŸºäºä¸å®Œæ•´å¤šæ¨¡æ€æ•°æ®ä»¥è¯Šæ–­å¯¼å‘ç¥ç»å›¾åƒåˆæˆçš„ç–¾ç—…å›¾åƒç‰¹å¼‚æ€§å­¦ä¹ ","slug":"paper_åŸºäºä¸å®Œæ•´å¤šæ¨¡æ€æ•°æ®ä»¥è¯Šæ–­å¯¼å‘ç¥ç»å›¾åƒåˆæˆçš„ç–¾ç—…å›¾åƒç‰¹å¼‚æ€§å­¦ä¹ ","date":"2023-08-30T04:42:17.921Z","updated":"2024-05-21T12:18:43.292Z","comments":true,"path":"2023/08/30/paper_åŸºäºä¸å®Œæ•´å¤šæ¨¡æ€æ•°æ®ä»¥è¯Šæ–­å¯¼å‘ç¥ç»å›¾åƒåˆæˆçš„ç–¾ç—…å›¾åƒç‰¹å¼‚æ€§å­¦ä¹ /","link":"","permalink":"http://example.com/2023/08/30/paper_%E5%9F%BA%E4%BA%8E%E4%B8%8D%E5%AE%8C%E6%95%B4%E5%A4%9A%E6%A8%A1%E6%80%81%E6%95%B0%E6%8D%AE%E4%BB%A5%E8%AF%8A%E6%96%AD%E5%AF%BC%E5%90%91%E7%A5%9E%E7%BB%8F%E5%9B%BE%E5%83%8F%E5%90%88%E6%88%90%E7%9A%84%E7%96%BE%E7%97%85%E5%9B%BE%E5%83%8F%E7%89%B9%E5%BC%82%E6%80%A7%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"Disease-Image-Specific Learning for Diagnosis-Oriented Neuroimage Synthesis With Incomplete Multi-Modality Data 1.æ‘˜è¦ åœ¨å¤šæºæ•°æ®çš„åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œæ•°æ®ä¸å®Œæ•´æ˜¯ä¸€ä¸ªæ™®éå­˜åœ¨çš„é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤šæ¨¡æ€ç¥ç»å›¾åƒçš„ç–¾ç—…è¯Šæ–­ä¸­ï¼Œä¸ºäº†è·Ÿè¸ªè¿™ä¸€é—®é¢˜ï¼Œäººä»¬æå‡ºäº†ä¸€äº›æ–¹æ³•ï¼Œé€šè¿‡è¾“å…¥ç¼ºå¤±çš„ç¥ç»å›¾åƒæ¥åˆ©ç”¨æ‰€æœ‰å¯ç”¨çš„è¢«è¯•ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸å°†å›¾åƒåˆæˆå’Œç–¾ç—…è¯Šæ–­è§†ä¸ºä¸¤ä¸ªç‹¬ç«‹çš„ä»»åŠ¡ï¼Œä»è€Œå¿½ç•¥äº†ä¸åŒæ¨¡æ€æ‰€ä¼ è¾¾çš„ç‰¹å¼‚æ€§ï¼Œå³ä¸åŒæ¨¡æ€å¯èƒ½çªå‡ºå¤§è„‘ä¸­ä¸åŒçš„ç–¾ç—…ç›¸å…³åŒºåŸŸã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç–¾ç—…å›¾åƒç‰¹å¼‚æ€§æ·±åº¦å­¦ä¹ (DSDL)æ¡†æ¶ï¼Œç”¨äºä½¿ç”¨ä¸å®Œæ•´å¤šæ¨¡æ€ç¥ç»å›¾åƒç”¨äºè”åˆç¥ç»å›¾åƒåˆæˆå’Œç–¾ç—…è¯Šæ–­ã€‚å…·ä½“è€Œè¨€ï¼Œä»¥æ¯æ¬¡å…¨è„‘æ‰«æä¸ºè¾“å…¥ï¼Œæˆ‘ä»¬é¦–å…ˆè®¾è®¡äº†ä¸€ä¸ªå¸¦æœ‰ç©ºé—´ä½™å¼¦æ¨¡å—çš„ç–¾ç—…å›¾åƒç‰¹å¼‚æ€§ç½‘ç»œ(DSNet)ï¼Œä»¥éšå¼å»ºæ¨¡ç–¾ç—…å›¾åƒç‰¹å¼‚æ€§ã€‚ç„¶åï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªç‰¹å¾ä¸€è‡´æ€§ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(FGAN)æ¥è¡¥å…¨ç¼ºå¤±çš„ç¥ç»å›¾åƒï¼Œå…¶ä¸­åˆæˆå›¾åƒçš„ç‰¹å¾æ˜ å°„(ç”±DSNetç”Ÿæˆ)ä¸å…¶å„è‡ªçš„çœŸå®å›¾åƒè¢«é¼“åŠ±ä¿æŒä¸€è‡´ï¼ŒåŒæ—¶ä¿ç•™ç–¾ç—…å›¾åƒç‰¹å®šä¿¡æ¯ã€‚ç”±äºæˆ‘ä»¬çš„FGANä¸DSNetç›¸å…³ï¼Œç¼ºå¤±çš„ç¥ç»å›¾åƒå¯ä»¥ä»¥è¯Šæ–­ä¸ºå¯¼å‘çš„æ–¹å¼åˆæˆã€‚åœ¨ä¸‰ä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸ä»…å¯ä»¥ç”Ÿæˆåˆç†çš„ç¥ç»å›¾åƒï¼Œè€Œä¸”åœ¨é˜¿å°”èŒ¨æµ·é»˜ç—…è¯†åˆ«å’Œè½»åº¦è®¤çŸ¥éšœç¢è½¬æ¢é¢„æµ‹ä¸¤é¡¹ä»»åŠ¡ä¸Šéƒ½å–å¾—äº†è¾ƒå¥½çš„æ•ˆæœ 2.å¼•è¨€ å¤šæ¨¡æ€ç¥ç»å½±åƒå­¦æ•°æ®å·²è¢«è¯æ˜å¯ä»¥æä¾›äº’è¡¥ä¿¡æ¯ï¼Œä»¥æé«˜ç–¾ç—…çš„çš„è®¡ç®—æœºè¾…åŠ©è¯Šæ–­æ€§èƒ½ã€‚æ•°æ®ç¼ºå¤±é—®é¢˜ä¸€ç›´æ˜¯ä½¿ç”¨å¤šæ¨¡æ€ç¥ç»æˆåƒæ•°æ®è¿›è¡Œè„‘ç–¾ç—…è‡ªåŠ¨è¯Šæ–­çš„å¸¸è§æŒ‘æˆ˜ã€‚ ä¼ ç»Ÿæ–¹æ³•åªä½¿ç”¨æ¨¡æ€å®Œæ•´çš„è¢«è¯•è€Œä¸¢å¼ƒæ¨¡æ€ä¸å®Œæ•´çš„è¢«è¯•ï¼Œè¿™ç§ç­–ç•¥å‡å°‘äº†è®­ç»ƒæ ·æœ¬æ•°é‡ï¼Œå¿½ç•¥äº†æ•°æ®ç¼ºå¤±å—è¯•è€…æä¾›çš„æœ‰ç”¨ä¿¡æ¯ï¼Œä»è€Œé™ä½äº†è¯Šæ–­æ€§èƒ½ã€‚å·²ç»æå‡ºäº†å‡ ç§æ•°æ®è¾“å…¥æ–¹æ³•ï¼Œåˆ©ç”¨æ•°æ®å®Œæ•´å—è¯•è€…çš„ç‰¹å¾æ¥ä¼°è®¡ç¼ºå¤±æ•°æ®å—è¯•è€…çš„æ‰‹å·¥ç‰¹å¾ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•ä¾èµ–äºæ‰‹å·¥åˆ¶ä½œçš„å›¾åƒç‰¹å¾ï¼Œå¯èƒ½æ— æ³•åŒºåˆ†è„‘éƒ¨ç–¾ç—…çš„è¯Šæ–­ï¼Œä»è€Œå¯¼è‡´æ¬¡ä¼˜çš„å­¦ä¹ æ€§èƒ½ã€‚ æ›´æœ‰å¸Œæœ›çš„æ›¿ä»£æ–¹æ³•æ˜¯é€šè¿‡æ·±åº¦å­¦ä¹ ç›´æ¥ä¼°è®¡ç¼ºå¤±æ•°æ®ã€‚ç„¶è€Œä¹‹å‰çš„æ–¹æ³•å¹³ç­‰åœ°å¤„ç†æ¯ä¸ªè„‘å®¹é‡ä¸­çš„æ‰€æœ‰ä½“ç´ ï¼Œä»è€Œå¿½ç•¥äº†å¤šæ¨¡æ€ç¥ç»æˆåƒæ•°æ®ä¸­ä¼ è¾¾çš„ç–¾ç—…å›¾åƒç‰¹å¼‚æ€§ã€‚ç–¾ç—…å›¾åƒçš„ç‰¹å¼‚æ€§æ˜¯åŒé‡çš„ï¼š ï¼ˆ1ï¼‰å¹¶ä¸æ˜¯MRI/PETæ‰«æçš„æ‰€æœ‰åŒºåŸŸéƒ½ä¸ç‰¹å®šçš„è„‘éƒ¨ç–¾ç—…æœ‰å…³ ï¼ˆ2ï¼‰ä¸ç–¾ç—…ç›¸å…³çš„å¤§è„‘åŒºåŸŸå¯èƒ½åœ¨ä¸åŒæ¨¡æ€ä¸­æ˜¯æœ‰å·®åˆ«çš„ å¯¹äºç¬¬ä¸€ä¸ªæ–¹é¢ï¼Œç°æœ‰çš„æ·±åº¦å­¦ä¹ æ–¹æ³•é€šå¸¸åœ¨å›¾åƒåˆæˆè¿‡ç¨‹ä¸­å¹³ç­‰å¯¹å¾…æ‰€æœ‰å¤§è„‘åŒºåŸŸï¼ŒæŸäº›åŒºåŸŸä¸ç–¾ç—…æ˜¯é«˜åº¦ç›¸å…³çš„ç›¸æ¯”äºå…¶ä»–åŒºåŸŸã€‚å¯¹äºç¬¬äºŒä¸ªæ–¹é¢ï¼Œç°æœ‰æ–¹æ³•ç›´æ¥åŸºäºå¦ä¸€ç§æ¨¡æ€å›¾åƒåˆæˆä¸€ç§æ¨¡æ€å›¾åƒï¼Œè€Œä¸è€ƒè™‘ç–¾ç—…ç›¸å…³åŒºåŸŸçš„æ¨¡æ€å·®è·ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå·²æœ‰ç ”ç©¶è¡¨æ˜ï¼Œç–¾ç—…è¯Šæ–­æ¨¡å‹å¯ä»¥é€šè¿‡æ„Ÿå…´è¶£åŒºåŸŸå’Œè§£å‰–æ ‡å¿—æ¥éšå¼æˆ–æ˜¾å¼åœ°æ•æ‰ç–¾ç—…å›¾åƒç‰¹å¼‚æ€§ã€‚å› æ­¤ï¼Œä¸ºäº†æ•è·å’Œåˆ©ç”¨ç–¾ç—…å›¾åƒçš„ç‰¹å¼‚æ€§ï¼Œç›´è§‚åœ°éœ€è¦å°†ç–¾ç—…è¯Šæ–­å’Œå›¾åƒåˆæˆæ•´åˆåˆ°ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ä¸­ï¼Œä»¥è¯Šæ–­ä¸ºå¯¼å‘çš„æ–¹å¼è¾“å…¥ç¼ºå¤±çš„ç¥ç»å›¾åƒ åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç–¾ç—…å›¾åƒç‰¹å¼‚æ€§æ·±åº¦å­¦ä¹ (DSDL)æ¡†æ¶ï¼Œç”¨äºä½¿ç”¨ä¸å®Œæ•´çš„å¤šæ¨¡æ€ç¥ç»å›¾åƒç”¨äºè”åˆç–¾ç—…è¯Šæ–­å’Œå›¾åƒåˆæˆ(è§å›¾1)ã€‚å¦‚å›¾1aå’Œ1bæ‰€ç¤ºï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸»è¦åŒ…å«ä¸¤ä¸ªå•æ¨¡æ€ç–¾ç—…å›¾åƒç‰¹å¼‚æ€§ç½‘ç»œ(DSNet)ï¼Œç”¨äºåŸºäºMRIå’Œpetçš„ç–¾ç—…è¯Šæ–­ï¼Œä»¥åŠä¸€ä¸ªç”¨äºå›¾åƒåˆæˆçš„ç‰¹å¾ä¸€è‡´æ€§ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(FGAN)ã€‚æœ¬æ–‡ä¸­ï¼ŒDSNetå¯¹åŸºäºMRIå’Œpetçš„ç‰¹å¾å›¾ä¸­çš„ç–¾ç—…å›¾åƒç‰¹å¼‚æ€§è¿›è¡Œç¼–ç ï¼Œä»¥è¾…åŠ©FGANçš„è®­ç»ƒï¼Œè€ŒFGANåˆ™å¯¹ç¼ºå¤±å›¾åƒè¿›è¡Œè¡¥å…¨ä»¥æé«˜è¯Šæ–­æ€§èƒ½ã€‚ç”±äºDSNetå’ŒFGANå¯ä»¥è”åˆè®­ç»ƒï¼Œå› æ­¤å¯ä»¥ä»¥è¯Šæ–­ä¸ºå¯¼å‘çš„æ–¹å¼åˆæˆç¼ºå¤±çš„ç¥ç»å›¾åƒã€‚ä½¿ç”¨å®Œæ•´çš„MRIå’ŒPETæ‰«æ(æ¤å…¥å)ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡æå‡ºçš„å¤šæ¨¡æ€DSNetè¿›è¡Œç–¾ç—…è¯Šæ–­(å¦‚å›¾1cæ‰€ç¤º)ã€‚åœ¨ä¸‰ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸ä»…å¯ä»¥åˆæˆåˆç†çš„MRIå’ŒPETå›¾åƒï¼Œè€Œä¸”åœ¨ADè¯†åˆ«å’ŒMCIè½¬æ¢é¢„æµ‹æ–¹é¢éƒ½å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚ ä¸æˆ‘ä»¬ä¹‹å‰çš„å·¥ä½œç›¸æ¯”ï¼Œæœ¬å·¥ä½œçš„è´¡çŒ®å¦‚ä¸‹ï¼š (1)æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„DSDLæ¡†æ¶ï¼Œç”¨äºä¸å®Œæ•´å¤šæ¨¡æ€ç¥ç»å›¾åƒçš„è”åˆå›¾åƒåˆæˆå’ŒADè¯Šæ–­ã€‚ç¼ºå¤±çš„å›¾åƒä»¥è¯Šæ–­ä¸ºå¯¼å‘çš„æ–¹å¼è¾“å…¥ï¼Œå› æ­¤ä»è¯Šæ–­çš„è§’åº¦æ¥çœ‹ï¼Œåˆæˆçš„ç¥ç»å›¾åƒä¸çœŸå®çš„ç¥ç»å›¾åƒæ›´ä¸€è‡´ã€‚ (2)è®¾è®¡äº†ç©ºé—´ä½™å¼¦æ¨¡å‹ï¼Œå¯¹å…¨è„‘MRI/PETæ‰«æçš„ç–¾ç—…å›¾åƒç‰¹å¼‚æ€§è¿›è¡Œéšå¼è‡ªåŠ¨å»ºæ¨¡ã€‚ (3)æå‡ºäº†ä¸€ç§ç‰¹å¾ä¸€è‡´æ€§çº¦æŸï¼Œå¯ä»¥å¸®åŠ©å›¾åƒåˆæˆæ¨¡å‹åœ¨æ¨¡æ€è½¬æ¢è¿‡ç¨‹ä¸­ä¿ç•™ç–¾ç—…ç›¸å…³ä¿¡æ¯ 3.æ€»ç»“ æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºä¸å®Œå…¨å¤šæ¨¡æ€æ•°æ®çš„é¢å‘ä»»åŠ¡çš„ç¥ç»å›¾åƒåˆæˆçš„ç–¾ç—…å›¾åƒç‰¹å¼‚æ€§æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå…¶ä¸­ä½¿ç”¨è¯Šæ–­ç½‘ç»œä¸ºå›¾åƒåˆæˆç½‘ç»œæä¾›ç–¾ç—…å›¾åƒç‰¹å¼‚æ€§ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªå•æ¨¡æ€ç–¾ç—…å›¾åƒç‰¹å¼‚æ€§ç½‘ç»œ(DSNet)ï¼Œå¯¹å…¨è„‘å›¾åƒè¿›è¡Œè®­ç»ƒï¼Œä»¥éšå¼æ•è·MRIå’ŒPETä¼ è¾¾çš„ç–¾ç—…ç›¸å…³ä¿¡æ¯ã€‚ç„¶åï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªç‰¹å¾ä¸€è‡´æ€§ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(FGAN)æ¥åˆæˆç¼ºå¤±çš„ç¥ç»å›¾åƒï¼Œé€šè¿‡é¼“åŠ±æ¯ä¸ªåˆæˆå›¾åƒçš„ç‰¹å¾æ˜ å°„ä¸å…¶å„è‡ªçš„çœŸå®å›¾åƒä¿æŒä¸€è‡´ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥æå‡ºäº†ä¸€ä¸ªå¤šæ¨¡æ€DSNet (mDSNet)ï¼Œç”¨äºä½¿ç”¨å®Œæ•´çš„(æ¤å…¥å)MRIå’ŒPETæ‰«æè¿›è¡Œç–¾ç—…è¯Šæ–­ã€‚åœ¨ä¸‰ä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥ç”Ÿæˆåˆç†çš„ç¥ç»å›¾åƒï¼Œå¹¶åœ¨ADè¯†åˆ«å’ŒMCIè½¬æ¢é¢„æµ‹æ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚","categories":[{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Paper-åŒ»å­¦å½±åƒ","slug":"Paper-åŒ»å­¦å½±åƒ","permalink":"http://example.com/tags/Paper-%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F/"}]},{"title":"Hello World","slug":"hello-world","date":"2023-08-30T03:04:39.444Z","updated":"2023-08-30T03:04:39.444Z","comments":true,"path":"2023/08/30/hello-world/","link":"","permalink":"http://example.com/2023/08/30/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post 1$ hexo new &quot;My New Post&quot; More info: Writing Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"ç¼–ç¨‹","slug":"ç¼–ç¨‹","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B/"},{"name":"ç¬”è®°","slug":"ç¬”è®°","permalink":"http://example.com/categories/%E7%AC%94%E8%AE%B0/"},{"name":"Paper","slug":"Paper","permalink":"http://example.com/categories/Paper/"}],"tags":[{"name":"Code-å›¾åƒå¤„ç†","slug":"Code-å›¾åƒå¤„ç†","permalink":"http://example.com/tags/Code-%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"Qt","slug":"Qt","permalink":"http://example.com/tags/Qt/"},{"name":"Code-åŸºç¡€æ¨¡å‹","slug":"Code-åŸºç¡€æ¨¡å‹","permalink":"http://example.com/tags/Code-%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B/"},{"name":"Code-ç”Ÿæˆ","slug":"Code-ç”Ÿæˆ","permalink":"http://example.com/tags/Code-%E7%94%9F%E6%88%90/"},{"name":"æ³•å¾‹","slug":"æ³•å¾‹","permalink":"http://example.com/tags/%E6%B3%95%E5%BE%8B/"},{"name":"åŒ»å­¦","slug":"åŒ»å­¦","permalink":"http://example.com/tags/%E5%8C%BB%E5%AD%A6/"},{"name":"ç¼–ç¨‹åŸºç¡€çŸ¥è¯†","slug":"ç¼–ç¨‹åŸºç¡€çŸ¥è¯†","permalink":"http://example.com/tags/%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"Code-åˆ†ç±»","slug":"Code-åˆ†ç±»","permalink":"http://example.com/tags/Code-%E5%88%86%E7%B1%BB/"},{"name":"Paper-åŒ»å­¦å½±åƒ","slug":"Paper-åŒ»å­¦å½±åƒ","permalink":"http://example.com/tags/Paper-%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F/"},{"name":"Code-æ–‡ä»¶æ“ä½œ","slug":"Code-æ–‡ä»¶æ“ä½œ","permalink":"http://example.com/tags/Code-%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/"},{"name":"Paper-ç»¼è¿°æ–‡ç« ","slug":"Paper-ç»¼è¿°æ–‡ç« ","permalink":"http://example.com/tags/Paper-%E7%BB%BC%E8%BF%B0%E6%96%87%E7%AB%A0/"}]}